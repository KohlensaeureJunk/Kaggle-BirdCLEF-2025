{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd19261b",
   "metadata": {
    "papermill": {
     "duration": 0.00461,
     "end_time": "2025-03-17T14:00:32.494653",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.490043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **BirdCLEF 2025 Training Notebook**\n",
    "\n",
    "This is a baseline training pipeline for BirdCLEF 2025 using EfficientNetB0 with PyTorch and Timm(for pretrained EffNet). You can check inference and preprocessing notebooks in the following links: \n",
    "\n",
    "- [EfficientNet B0 Pytorch [Inference] | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-inference-birdclef-25)\n",
    "\n",
    "  \n",
    "- [Transforming Audio-to-Mel Spec. | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/transforming-audio-to-mel-spec-birdclef-25)  \n",
    "\n",
    "Note that by default this notebook is in Debug Mode, so it will only train the model with 2 epochs, but the [weight](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-effnetb0-starter-weight) I used in the inference notebook was obtained after 10 epochs of training.\n",
    "\n",
    "**Features**\n",
    "* Implement with Pytorch and Timm\n",
    "* Flexible audio processing with both pre-computed and on-the-fly mel spectrograms\n",
    "* Stratified 5-fold cross-validation with ensemble capability\n",
    "* Mixup training for improved generalization\n",
    "* Spectrogram augmentations (time/frequency masking, brightness adjustment)\n",
    "* AdamW optimizer with Cosine Annealing LR scheduling\n",
    "* Debug mode for quick experimentation with smaller datasets\n",
    "\n",
    "**Pre-computed Spectrograms**\n",
    "For faster training, you can use pre-computed mel spectrograms from [this dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) by setting `LOAD_DATA = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a699fa",
   "metadata": {
    "papermill": {
     "duration": 0.003494,
     "end_time": "2025-03-17T14:00:32.502085",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.498591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ca2ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:32.510711Z",
     "iopub.status.busy": "2025-03-17T14:00:32.510382Z",
     "iopub.status.idle": "2025-03-17T14:00:46.238785Z",
     "shell.execute_reply": "2025-03-17T14:00:46.238073Z"
    },
    "papermill": {
     "duration": 13.73451,
     "end_time": "2025-03-17T14:00:46.240399",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.505889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np, pandas as pd, math, os, random, warnings, json, datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Specific imports\n",
    "import logging, gc, cv2\n",
    "\n",
    "# Audio processing imports\n",
    "import librosa\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Other ML imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timm\n",
    "\n",
    "# Custom imports\n",
    "from processing import audio2melspec, process_audio_file, generate_spectrograms\n",
    "from utilities import set_seed, collate_fn\n",
    "from training_utilities import get_optimizer, get_scheduler, get_criterion, clean_gpu_memory, calculate_auc, compile_model\n",
    "\n",
    "# Suppress warnings and set logging level\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f9c08",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-03-17T14:00:46.248317",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.244596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06591264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.256618Z",
     "iopub.status.busy": "2025-03-17T14:00:46.256366Z",
     "iopub.status.idle": "2025-03-17T14:00:46.333416Z",
     "shell.execute_reply": "2025-03-17T14:00:46.332684Z"
    },
    "papermill": {
     "duration": 0.082704,
     "end_time": "2025-03-17T14:00:46.334712",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.252008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    \n",
    "    seed = 42\n",
    "    debug = False \n",
    "    LOAD_DATA = True\n",
    "    \n",
    "    # Paths and directories\n",
    "    OUTPUT_DIR = 'output/'\n",
    "    train_datadir = 'birdclef-2025/train_audio'\n",
    "    train_csv = 'birdclef-2025/train.csv'\n",
    "    train_soundscapes = 'birdclef-2025/train_soundscapes'\n",
    "    test_soundscapes = 'birdclef-2025/test_soundscapes'\n",
    "    submission_csv = 'birdclef-2025/sample_submission.csv'\n",
    "    taxonomy_csv = 'birdclef-2025/taxonomy.csv'\n",
    "    unlabeled_sample_list = \"birdclef-2025/sample_list.csv\"\n",
    "    spectrogram_npy = 'archive/train_melspec_5_256_256.npy'\n",
    "    spectrogram_npy_unlabeled = 'archive/train_soundscapes_mel_spec_12x5_256_256.npy'\n",
    "    \n",
    "    # External pseudolabels settings\n",
    "    use_external_pseudolabels = True\n",
    "    external_pseudolabels_path = 'pseudolabels.csv'\n",
    "    pseudolabel_confidence_threshold = 0.5  # Only use predictions above this threshold\n",
    "    soundscape_metadata_path = 'archive/train_soundscapes_melspec_12x5_256_256_metadata.csv'\n",
    " \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    n_fold = 5 \n",
    "\n",
    "    # Training settings\n",
    "    epochs = 15  # Single set of epochs for training\n",
    "\n",
    "    # Mel spectrogram parameters\n",
    "    FS = 32000\n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Loss parameters\n",
    "    criterion = 'CombinedLoss'  # Options: 'BCEWithLogitsLoss', 'FocalLoss', 'CombinedLoss'\n",
    "    focal_alpha = 1.0\n",
    "    focal_gamma = 3.0\n",
    "    bce_weight = 0.5\n",
    "    focal_weight = 0.5\n",
    "\n",
    "    # optimizer and scheduler parameters\n",
    "    optimizer = 'AdamW'\n",
    "    lr = 5e-4 \n",
    "    weight_decay = 1e-5\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    min_lr = 1e-6\n",
    "    use_lr_warmup = True\n",
    "    warmup_epochs = 2\n",
    "\n",
    "    # augmentation options\n",
    "    aug_prob = 0.5  \n",
    "    spec_augment = True\n",
    "    spec_augment_params = {\n",
    "        'time_mask_param': 30,\n",
    "        'freq_mask_param': 20,\n",
    "        'num_masks': 2,\n",
    "    }\n",
    "    mixup_alpha = 0.5\n",
    "    cutmix_alpha = 1.0\n",
    "    use_cutmix = True\n",
    "    \n",
    "# Model architecture options\n",
    "    model_name = 'efficientnet_b0'  # Options: 'efficientnetv2_s', 'convnext_tiny', 'efficientnet_b0' \n",
    "    pretrained = True\n",
    "    in_channels = 1\n",
    "    dropout_rate = 0.2\n",
    "    drop_path_rate = 0.2\n",
    "    \n",
    "    # Regularization techniques\n",
    "    label_smoothing = 0.01\n",
    "    use_stochastic_depth = True\n",
    "\n",
    "    # Memory and speed optimizations\n",
    "    gradient_accumulation_steps = 2  # Increase effective batch size without more memory\n",
    "    use_amp = True                   # Use automatic mixed precision\n",
    "    pin_memory = True                # Faster data transfer to GPU\n",
    "    persistent_workers = True        # Keep workers alive between epochs\n",
    "    num_workers = 8                  # Match to number of CPU cores\n",
    "    prefetch_factor = 2              # Number of batches to prefetch (default is 2)\n",
    "    batch_size = 32                  # Effective batch size will be batch_size * gradient_accumulation_steps\n",
    "    \n",
    "    # Compiler settings\n",
    "    compile_mode = \"default\"         # Options: \"default\", \"reduce-overhead\", \"max-autotune\"\n",
    "    compile_fallback = True          # Fallback if compilation fails\n",
    "    \n",
    "    # Memory usage management\n",
    "    gc_after_epoch = True            # Force garbage collection after each epoch\n",
    "    cache_dataset = False            # Cache dataset in memory if possible\n",
    "\n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.n_fold = 1\n",
    "            self.epochs = 2\n",
    "\n",
    "    def save_config(self):\n",
    "        config_dict = {attr: getattr(self, attr) for attr in dir(self) if not attr.startswith('__') and not callable(getattr(self, attr))}\n",
    "        if self.debug:\n",
    "            filename = f\"config_{self.timestamp}_{self.model_name}_DEBUG.json\"\n",
    "        else:\n",
    "            filename = f\"config_{self.timestamp}_{self.model_name}.json\"\n",
    "        with open(os.path.join(self.OUTPUT_DIR, filename), 'w') as f:\n",
    "            json.dump(config_dict, f, indent=4, default=str)\n",
    "        print(f\"Config saved to {os.path.join(self.OUTPUT_DIR, filename)}\")\n",
    "\n",
    "cfg = CFG()\n",
    "set_seed(cfg.seed)\n",
    "cfg.update_debug_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4bc37",
   "metadata": {
    "papermill": {
     "duration": 0.003588,
     "end_time": "2025-03-17T14:00:46.367790",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.364202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-processing\n",
    "These functions handle the transformation of audio files to mel spectrograms for model input, with flexibility controlled by the `LOAD_DATA` parameter. The process involves either loading pre-computed spectrograms from this [dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) (when `LOAD_DATA=True`) or dynamically generating them (when `LOAD_DATA=False`), transforming audio data into spectrogram representations, and preparing it for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939033bf",
   "metadata": {
    "papermill": {
     "duration": 0.003549,
     "end_time": "2025-03-17T14:00:46.393394",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.389845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Preparation and Data Augmentations\n",
    "We'll convert audio to mel spectrograms and apply random augmentations with 50% probability each - including time stretching, pitch shifting, and volume adjustments. This randomized approach creates diverse training samples from the same audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b2ea48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.401415Z",
     "iopub.status.busy": "2025-03-17T14:00:46.401216Z",
     "iopub.status.idle": "2025-03-17T14:00:46.413659Z",
     "shell.execute_reply": "2025-03-17T14:00:46.412877Z"
    },
    "papermill": {
     "duration": 0.017836,
     "end_time": "2025-03-17T14:00:46.414835",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.396999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY(Dataset):\n",
    "    _cache = {}  # Class-level cache\n",
    "    \n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        \n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "\n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "        \n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "        \n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "        \n",
    "        self.use_cache = cfg.cache_dataset if hasattr(cfg, 'cache_dataset') else False\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Check if we should use the cache and if the item is in cache\n",
    "        cache_key = f\"{self.mode}_{idx}\"\n",
    "        if self.use_cache and cache_key in self.__class__._cache:\n",
    "            self.cache_hits += 1\n",
    "            return self.__class__._cache[cache_key]\n",
    "        \n",
    "        row = self.df.iloc[idx]\n",
    "        samplename = row['samplename']\n",
    "\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        elif not self.cfg.LOAD_DATA:\n",
    "            spec = process_audio_file(row['filepath'], self.cfg)\n",
    "        else: spec = None\n",
    "\n",
    "        if spec is None:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":  # Only print warning during training\n",
    "                print(f\"Warning: Spectrogram for {samplename} not found and could not be generated\")\n",
    "\n",
    "        spec = torch.from_numpy(spec).float().unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "        \n",
    "        target = self.encode_label(row['primary_label'])\n",
    "        \n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            \n",
    "            for label in secondary_labels:\n",
    "                idx = self.label_to_idx.get(label)\n",
    "                if idx is not None:\n",
    "                    target[idx] = 1.0\n",
    "        \n",
    "        item = {\n",
    "            'melspec': spec, \n",
    "            'target': torch.from_numpy(target).float(),\n",
    "            'filename': row['filename']\n",
    "        }\n",
    "        \n",
    "        # Cache the item if caching is enabled\n",
    "        if self.use_cache:\n",
    "            self.cache_misses += 1\n",
    "            self.__class__._cache[cache_key] = item\n",
    "            \n",
    "            # Print cache stats occasionally \n",
    "            if (self.cache_hits + self.cache_misses) % 1000 == 0:\n",
    "                hit_rate = self.cache_hits / (self.cache_hits + self.cache_misses)\n",
    "                print(f\"Cache hit rate: {hit_rate:.2%}, hits: {self.cache_hits}, misses: {self.cache_misses}\")\n",
    "                \n",
    "        return item\n",
    "    \n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        \"\"\"Apply augmentations to spectrogram\"\"\"\n",
    "        \n",
    "        # Original time/frequency masking\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "        \n",
    "        # Random brightness/contrast adjustment\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "        \n",
    "        # NEW: Gaussian noise for robustness\n",
    "        if random.random() < 0.3:\n",
    "            noise = torch.randn_like(spec) * random.uniform(0.001, 0.005)\n",
    "            spec = spec + noise\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "            \n",
    "        # NEW: Random time/frequency shifts\n",
    "        if random.random() < 0.3:\n",
    "            shift_x = random.randint(-4, 4)\n",
    "            shift_y = random.randint(-4, 4)\n",
    "            spec = torch.roll(spec, shifts=(shift_y, shift_x), dims=(1, 2))\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        \"\"\"Encode label to one-hot vector\"\"\"\n",
    "        target = np.zeros(self.num_classes)\n",
    "        idx = self.label_to_idx.get(label)\n",
    "        if idx is not None:\n",
    "            target[idx] = 1.0\n",
    "        return target\n",
    "    \n",
    "    def extend(self, new_samples):\n",
    "        \"\"\"Extend the dataset with new samples, supporting secondary labels.\"\"\"\n",
    "        print(f\"Adding {len(new_samples)} new samples to the train dataset.\")\n",
    "        \n",
    "        new_rows = []\n",
    "        new_specs = {}\n",
    "\n",
    "        for sample in new_samples:\n",
    "            filename = sample['filename']\n",
    "            samplename = filename.split('/')[0] + '-' + filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "            # Ensure target is a proper one-hot encoded vector\n",
    "            target_array = sample['target'].numpy() if isinstance(sample['target'], torch.Tensor) else sample['target']\n",
    "            if target_array.ndim > 1 or target_array.sum() > 1.5:\n",
    "                # If multi-label vector, pick primary label as the one with highest score\n",
    "                primary_label_idx = target_array.argmax()\n",
    "            else:\n",
    "                # If already one-hot\n",
    "                primary_label_idx = target_array.argmax()\n",
    "\n",
    "            primary_label = self.species_ids[primary_label_idx]\n",
    "\n",
    "            # Optional: If you want to save secondary labels (everything else non-zero except the primary)\n",
    "            secondary_label_indices = [i for i, val in enumerate(target_array) if val > 0 and i != primary_label_idx]\n",
    "            secondary_labels = [self.species_ids[i] for i in secondary_label_indices] if secondary_label_indices else ['']\n",
    "\n",
    "            new_row = {\n",
    "                'filename': filename,\n",
    "                'samplename': samplename,\n",
    "                'primary_label': primary_label,\n",
    "                'secondary_labels': str(secondary_labels),  # store as string for compatibility\n",
    "                'filepath': self.cfg.test_soundscapes + '/' + filename  # comes from test_soundscapes!\n",
    "            }\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "            # Store the melspec separately\n",
    "            new_specs[samplename] = sample['melspec'].squeeze(0).numpy()  # remove channel dim for consistency\n",
    "\n",
    "        # Append to df\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        self.df = pd.concat([self.df, new_df], ignore_index=True)\n",
    "\n",
    "        # Update spectrograms dictionary if available\n",
    "        if self.spectrograms is not None:\n",
    "            self.spectrograms.update(new_specs)\n",
    "        else:\n",
    "            self.spectrograms = new_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f1c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundscapeDatasetFromNPY(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        \n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "        df[\"primary_label\"] = None\n",
    "        self.primary_label = [None] * len(self.df)\n",
    "        df[\"filename\"] = df[\"samplename\"].apply(lambda x: x+\".ogg\")\n",
    "        \n",
    "        # First apply external labels and filter by confidence\n",
    "        self.external_labels = None\n",
    "        if hasattr(cfg, 'use_external_pseudolabels') and cfg.use_external_pseudolabels:\n",
    "            print(f\"Loading external pseudolabels from {cfg.external_pseudolabels_path}\")\n",
    "            self.external_labels = pd.read_csv(cfg.external_pseudolabels_path)\n",
    "            print(f\"Loaded {len(self.external_labels)} external pseudolabels\")\n",
    "            \n",
    "            # Get high-confidence samples before loading any spectrograms\n",
    "            self.high_confidence_samples = self._get_high_confidence_samples()\n",
    "            print(f\"Found {len(self.high_confidence_samples)} samples with confidence >= {cfg.pseudolabel_confidence_threshold}\")\n",
    "            \n",
    "            # Filter dataframe to only include high-confidence samples\n",
    "            if mode == \"train\":\n",
    "                self.df = self.df[self.df['samplename'].isin(self.high_confidence_samples.keys())].reset_index(drop=True)\n",
    "                print(f\"Filtered dataset to {len(self.df)} high-confidence samples\")\n",
    "                self._apply_external_labels()\n",
    "        \n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "    \n",
    "    def _get_high_confidence_samples(self):\n",
    "        \"\"\"Return dictionary of sample_ids with high-confidence predictions and their labels\"\"\"\n",
    "        threshold = getattr(self.cfg, 'pseudolabel_confidence_threshold', 0.5)\n",
    "        print(f\"Filtering pseudolabels with confidence threshold: {threshold}\")\n",
    "        \n",
    "        high_confidence_dict = {}  # {sample_id: (label, confidence)}\n",
    "        label_cols = self.external_labels.columns[1:]  # Skip row_id column\n",
    "        \n",
    "        # Process each row in the external labels file\n",
    "        for _, row in self.external_labels.iterrows():\n",
    "            samplename = row['row_id']\n",
    "            label_values = {col: row[col] for col in label_cols}\n",
    "            \n",
    "            # Find max probability and corresponding label\n",
    "            max_label = max(label_values, key=label_values.get)\n",
    "            max_prob = label_values[max_label]\n",
    "            \n",
    "            # Only keep predictions above threshold\n",
    "            if max_prob >= threshold:\n",
    "                high_confidence_dict[samplename] = (max_label, max_prob)\n",
    "        \n",
    "        return high_confidence_dict\n",
    "    \n",
    "    def _apply_external_labels(self):\n",
    "        \"\"\"Apply the previously filtered high-confidence labels to the dataset\"\"\"\n",
    "        samples_with_labels = 0\n",
    "        \n",
    "        for i, row in self.df.iterrows():\n",
    "            samplename = row['samplename']\n",
    "            if samplename in self.high_confidence_samples:\n",
    "                label, _ = self.high_confidence_samples[samplename]\n",
    "                self.df.at[i, 'primary_label'] = label\n",
    "                self.primary_label[i] = label\n",
    "                samples_with_labels += 1\n",
    "        \n",
    "        print(f\"Applied pseudolabels to {samples_with_labels} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        samplename = row['samplename']\n",
    "        spec = None\n",
    "\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        elif not self.cfg.LOAD_DATA:\n",
    "            spec = process_audio_file(row['filepath'], self.cfg)\n",
    "\n",
    "        if spec is None:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":  # Only print warning during training\n",
    "                print(f\"Warning: Spectrogram for {samplename} not found and could not be generated\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        target = self.encode_label(row['primary_label'])\n",
    "\n",
    "        return {\n",
    "            'melspec': spec, \n",
    "            'target': torch.tensor(target, dtype=torch.float32) if target is not None else None,\n",
    "            'filename': row['filename'],\n",
    "            'index': idx\n",
    "        }\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        \"\"\"Encode label to one-hot vector\"\"\"\n",
    "        target = np.zeros(self.num_classes)\n",
    "        if label in self.label_to_idx:\n",
    "            target[self.label_to_idx[label]] = 1.0\n",
    "        elif label is None:\n",
    "            return None\n",
    "        return target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb84a1",
   "metadata": {
    "papermill": {
     "duration": 0.003491,
     "end_time": "2025-03-17T14:00:46.436543",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.433052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741451ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.444643Z",
     "iopub.status.busy": "2025-03-17T14:00:46.444412Z",
     "iopub.status.idle": "2025-03-17T14:00:46.452684Z",
     "shell.execute_reply": "2025-03-17T14:00:46.452070Z"
    },
    "papermill": {
     "duration": 0.013532,
     "end_time": "2025-03-17T14:00:46.453738",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.440206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "        cfg.num_classes = len(taxonomy_df)\n",
    "        \n",
    "        # Support for different model architectures\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=cfg.dropout_rate,\n",
    "            drop_path_rate=cfg.drop_path_rate if hasattr(cfg, 'drop_path_rate') else 0.2\n",
    "        )\n",
    "        \n",
    "        # Extract feature dimension based on model type\n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'convnext' in cfg.model_name:\n",
    "            backbone_out = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        # Add an additional projection layer for better feature representation\n",
    "        if hasattr(cfg, 'projection_dim') and cfg.projection_dim > 0:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Linear(backbone_out, cfg.projection_dim),\n",
    "                nn.BatchNorm1d(cfg.projection_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(cfg.projection_dim, cfg.num_classes)\n",
    "            )\n",
    "            self.classifier = self.projection\n",
    "        else:\n",
    "            self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        \n",
    "        # Mixup and CutMix support\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        self.cutmix_enabled = hasattr(cfg, 'use_cutmix') and cfg.use_cutmix and hasattr(cfg, 'cutmix_alpha') and cfg.cutmix_alpha > 0\n",
    "        \n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "        if self.cutmix_enabled:\n",
    "            self.cutmix_alpha = cfg.cutmix_alpha\n",
    "    \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "        indices = torch.randperm(batch_size).to(x.device, non_blocking=True)\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    def cutmix_data(self, x, targets):\n",
    "        batch_size = x.size(0)\n",
    "        lam = np.random.beta(self.cutmix_alpha, self.cutmix_alpha)\n",
    "        \n",
    "        # Get random indices for mixing\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "        \n",
    "        # Get random box coordinates\n",
    "        W, H = x.size(2), x.size(3)\n",
    "        cut_ratio = np.sqrt(1. - lam)\n",
    "        cut_w = np.int_(W * cut_ratio)\n",
    "        cut_h = np.int_(H * cut_ratio)\n",
    "        \n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        \n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        \n",
    "        # Apply cutmix\n",
    "        x_mixed = x.clone()\n",
    "        x_mixed[:, :, bbx1:bbx2, bby1:bby2] = x[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "        \n",
    "        # Adjust lambda to actual area ratio\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "        \n",
    "        return x_mixed, targets, targets[indices], lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa08772",
   "metadata": {
    "papermill": {
     "duration": 0.003637,
     "end_time": "2025-03-17T14:00:46.461097",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.457460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Utilities\n",
    "We are configuring our optimization strategy with the AdamW optimizer, cosine scheduling, and the BCEWithLogitsLoss criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd70fd",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2025-03-17T14:00:46.483348",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.479834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d944f8ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.491507Z",
     "iopub.status.busy": "2025-03-17T14:00:46.491314Z",
     "iopub.status.idle": "2025-03-17T14:00:46.504038Z",
     "shell.execute_reply": "2025-03-17T14:00:46.503466Z"
    },
    "papermill": {
     "duration": 0.018173,
     "end_time": "2025-03-17T14:00:46.505200",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.487027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, scheduler=None, use_amp=True, grad_accum_steps=1):\n",
    "    model.train()\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Use lists to accumulate batches, but don't keep all outputs in memory\n",
    "    batch_count = 0\n",
    "    running_loss = 0\n",
    "    outputs_for_metrics = []\n",
    "    targets_for_metrics = []  # Fixed missing equal sign\n",
    "    metric_collection_interval = min(100, len(loader) // 10 or 1)  # Collect metrics every N batches\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "    \n",
    "    for step, batch in pbar:\n",
    "        # Move to device with non_blocking for potential speedup\n",
    "        inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "        targets = batch['target'].to(device, non_blocking=True)\n",
    "        \n",
    "        with autocast(enabled=use_amp, device_type=device):\n",
    "            # Handle model outputs with mixup/cutmix\n",
    "            if (model.mixup_enabled or model.cutmix_enabled) and model.training:\n",
    "                if model.mixup_enabled and model.cutmix_enabled:\n",
    "                    # Randomly choose between mixup and cutmix\n",
    "                    if random.random() < 0.5:\n",
    "                        mixed_x, targets_a, targets_b, lam = model.mixup_data(inputs, targets)\n",
    "                    else:\n",
    "                        mixed_x, targets_a, targets_b, lam = model.cutmix_data(inputs, targets)\n",
    "                elif model.mixup_enabled:\n",
    "                    mixed_x, targets_a, targets_b, lam = model.mixup_data(inputs, targets)\n",
    "                else:\n",
    "                    mixed_x, targets_a, targets_b, lam = model.cutmix_data(inputs, targets)\n",
    "                    \n",
    "                outputs = model(mixed_x)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Normalize loss for gradient accumulation\n",
    "        loss = loss / grad_accum_steps\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        batch_count += 1\n",
    "        running_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "        # Only collect some batches for metrics to save memory\n",
    "        if step % metric_collection_interval == 0:\n",
    "            outputs_for_metrics.append(outputs.detach().cpu())\n",
    "            targets_for_metrics.append(targets.detach().cpu())\n",
    "        \n",
    "        # Step optimizer after accumulating gradients\n",
    "        if batch_count % grad_accum_steps == 0 or step == len(loader) - 1:\n",
    "            # Unscale before possible gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            \n",
    "            # Optional gradient clipping\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "        # Update progress bar with running loss\n",
    "        pbar.set_postfix({\n",
    "            'train_loss': running_loss / (step + 1),\n",
    "            'lr': optimizer.param_groups[0]['lr'],\n",
    "            'batch': f\"{batch_count}/{grad_accum_steps}\"\n",
    "        })\n",
    "        \n",
    "        # Free memory explicitly\n",
    "        del inputs, outputs\n",
    "        if step % 10 == 0:  # Periodically clear CUDA cache\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Calculate metrics on the subset of data we collected\n",
    "    if outputs_for_metrics:\n",
    "        all_outputs = torch.cat(outputs_for_metrics)\n",
    "        all_targets = torch.cat(targets_for_metrics)\n",
    "        auc = calculate_auc(all_targets.numpy(), all_outputs)\n",
    "    else:\n",
    "        auc = 0.0\n",
    "        \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    \n",
    "    # Clean up\n",
    "    del outputs_for_metrics, targets_for_metrics\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "# Update the validation function with batch processing for large validation sets\n",
    "def validate(model, loader, criterion, device, use_amp=True):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Process predictions in chunks to save memory\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    max_batches_in_memory = 50  # Adjust based on your memory constraints\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(loader, desc=\"Validation\")):\n",
    "            inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "            targets = batch['target'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast(enabled=use_amp, device_type=device):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Convert to probabilities and store\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            targets_np = targets.cpu().numpy()\n",
    "            \n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets_np)\n",
    "            \n",
    "            # Clear memory periodically\n",
    "            del inputs, outputs, targets\n",
    "            if batch_idx % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Process predictions in chunks to avoid memory issues\n",
    "            if len(all_probs) >= max_batches_in_memory:\n",
    "                # Calculate partial metrics\n",
    "                probs_array = np.vstack(all_probs)\n",
    "                targets_array = np.vstack(all_targets)\n",
    "                \n",
    "                # Clear the lists to free memory\n",
    "                all_probs = []\n",
    "                all_targets = []\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Process any remaining predictions\n",
    "    if all_probs:\n",
    "        probs_array = np.vstack(all_probs) if len(all_probs) > 1 else all_probs[0]\n",
    "        targets_array = np.vstack(all_targets) if len(all_targets) > 1 else all_targets[0]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = calculate_auc(targets_array, probs_array)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    \n",
    "    # Final cleanup\n",
    "    del all_probs, all_targets, probs_array, targets_array\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de76a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.520217Z",
     "iopub.status.busy": "2025-03-17T14:00:46.520008Z",
     "iopub.status.idle": "2025-03-17T14:00:46.531337Z",
     "shell.execute_reply": "2025-03-17T14:00:46.530758Z"
    },
    "papermill": {
     "duration": 0.016548,
     "end_time": "2025-03-17T14:00:46.532461",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.515913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(df, cfg, soundscape_df=None):\n",
    "    \"\"\"Single-phase training function using external pseudolabels if enabled\"\"\"\n",
    "\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    species_ids = taxonomy_df['primary_label'].tolist()\n",
    "    cfg.num_classes = len(species_ids)\n",
    "    if cfg.debug: cfg.update_debug_settings()\n",
    "\n",
    "    # Load pre-computed spectrograms for the labeled data\n",
    "    spectrograms = None\n",
    "    if cfg.LOAD_DATA:\n",
    "        try:\n",
    "            spectrograms = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "            print(f\"Loaded {len(spectrograms)} pre-computed mel spectrograms for labeled data\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pre-computed spectrograms: {e}\")\n",
    "            print(\"Will generate spectrograms on-the-fly instead.\")\n",
    "            cfg.LOAD_DATA = False\n",
    "    \n",
    "    if not cfg.LOAD_DATA:\n",
    "        print(\"Will generate spectrograms on-the-fly during training.\")\n",
    "        if 'filepath' not in df.columns:\n",
    "            df['filepath'] = cfg.train_datadir + '/' + df.filename\n",
    "        if 'samplename' not in df.columns:\n",
    "            df['samplename'] = df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "    # Create cross-validation folds\n",
    "    if cfg.n_fold > 1:\n",
    "        skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n",
    "        folds = skf.split(df, df['primary_label'])\n",
    "    else:\n",
    "        folds = [(np.arange(len(df)), np.arange(len(df)))]\n",
    "\n",
    "    # Prepare pseudolabeled data ONCE before the fold loop    \n",
    "    pseudolabeled_dataset = None\n",
    "    \n",
    "    # Initialize these as None - we'll load them only if we need them\n",
    "    soundscape_dataset = None\n",
    "    soundscape_spectrograms = None\n",
    "\n",
    "    if cfg.use_external_pseudolabels and soundscape_df is not None:\n",
    "        print(\"\\nInitializing soundscape dataset with external pseudolabels...\")\n",
    "        \n",
    "        # First create the dataset without loading spectrograms to filter samples\n",
    "        # This will identify which samples have high confidence pseudolabels\n",
    "        temp_soundscape_dataset = SoundscapeDatasetFromNPY(\n",
    "            soundscape_df.copy(), \n",
    "            cfg, \n",
    "            spectrograms=None,  # Don't load spectrograms yet\n",
    "            mode='train',\n",
    "        )\n",
    "        \n",
    "        # Now we know which samples we need, so let's load only those spectrograms\n",
    "        if cfg.LOAD_DATA and hasattr(cfg, 'soundscape_metadata_path') and os.path.exists(cfg.soundscape_metadata_path):\n",
    "            print(\"Loading soundscape metadata to selectively load spectrograms...\")\n",
    "            # Load the metadata file\n",
    "            metadata_df = pd.read_csv(cfg.soundscape_metadata_path)\n",
    "            \n",
    "            # Filter to only the samples we need\n",
    "            filtered_samplenames = set(temp_soundscape_dataset.df['samplename'].values)\n",
    "            print(f\"Will load {len(filtered_samplenames)} spectrograms based on high-confidence pseudolabels\")\n",
    "            \n",
    "            # Load spectrograms selectively\n",
    "            if os.path.exists(cfg.spectrogram_npy_unlabeled):\n",
    "                print(f\"Loading spectrograms from {cfg.spectrogram_npy_unlabeled} selectively...\")\n",
    "                # Approach 1: Load all but use only what we need\n",
    "                all_soundscape_spectrograms = np.load(cfg.spectrogram_npy_unlabeled, allow_pickle=True).item()\n",
    "                \n",
    "                # Extract only the spectrograms we need\n",
    "                soundscape_spectrograms = {k: v for k, v in all_soundscape_spectrograms.items() \n",
    "                                        if k in filtered_samplenames}\n",
    "                \n",
    "                # Free memory\n",
    "                del all_soundscape_spectrograms\n",
    "                \n",
    "                print(f\"Loaded {len(soundscape_spectrograms)} soundscape spectrograms out of total available\")\n",
    "                \n",
    "                # Now create the actual dataset with the filtered spectrograms\n",
    "                soundscape_dataset = SoundscapeDatasetFromNPY(\n",
    "                    temp_soundscape_dataset.df,  # Already filtered dataframe\n",
    "                    cfg, \n",
    "                    spectrograms=soundscape_spectrograms, \n",
    "                    mode='train',\n",
    "                )\n",
    "                \n",
    "                pseudolabeled_dataset = soundscape_dataset\n",
    "                print(f\"Created pseudolabeled dataset with {len(pseudolabeled_dataset)} samples\")\n",
    "            else:\n",
    "                print(f\"Warning: Spectrogram file {cfg.spectrogram_npy_unlabeled} not found. Cannot use pseudolabels.\")\n",
    "        else:\n",
    "            print(\"Not loading soundscape spectrograms due to configuration or missing metadata file.\")\n",
    "            \n",
    "        # Clean up temporary dataset\n",
    "        del temp_soundscape_dataset\n",
    "\n",
    "    best_scores = []\n",
    "            \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "        print(f'\\n{\"=\"*30} Fold {fold} {\"=\"*30}')\n",
    "        \n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        print(f'Training set: {len(train_df)} samples')\n",
    "        print(f'Validation set: {len(val_df)} samples')\n",
    "\n",
    "        # Prepare datasets\n",
    "        train_dataset = BirdCLEFDatasetFromNPY(train_df, cfg, spectrograms=spectrograms, mode='train')\n",
    "        val_dataset = BirdCLEFDatasetFromNPY(val_df, cfg, spectrograms=spectrograms, mode='valid')\n",
    "        \n",
    "        # Use original training set by default\n",
    "        final_train_dataset = train_dataset\n",
    "        \n",
    "        # Combine with pseudolabels if available\n",
    "        if pseudolabeled_dataset is not None and len(pseudolabeled_dataset) > 0:\n",
    "            print(f\"Adding pseudolabeled data to fold {fold} training set\")\n",
    "            final_train_dataset = ConcatDataset([train_dataset, pseudolabeled_dataset])\n",
    "            print(f\"Training with combined dataset: {len(train_dataset)} original + {len(pseudolabeled_dataset)} pseudolabeled = {len(final_train_dataset)} total samples\")\n",
    "        \n",
    "        # Prepare data loaders\n",
    "        train_loader = DataLoader(\n",
    "            final_train_dataset, \n",
    "            batch_size=cfg.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=cfg.num_workers,\n",
    "            pin_memory=cfg.pin_memory,\n",
    "            persistent_workers=cfg.persistent_workers if cfg.num_workers > 0 else False,\n",
    "            prefetch_factor=cfg.prefetch_factor if cfg.num_workers > 0 else None,\n",
    "            collate_fn=collate_fn,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=cfg.batch_size * 2,  # Can use larger batch size for validation\n",
    "            shuffle=False, \n",
    "            num_workers=cfg.num_workers,\n",
    "            pin_memory=cfg.pin_memory,\n",
    "            persistent_workers=cfg.persistent_workers if cfg.num_workers > 0 else False,\n",
    "            prefetch_factor=cfg.prefetch_factor if cfg.num_workers > 0 else None,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        print(f\"\\n{'-'*20} Training Model {'-'*20}\")\n",
    "        model = BirdCLEFModel(cfg).to(cfg.device, non_blocking=True)\n",
    "        model = compile_model(model, cfg)\n",
    "        optimizer = get_optimizer(model, cfg)\n",
    "        criterion = get_criterion(cfg)\n",
    "\n",
    "        # Configure scheduler\n",
    "        if cfg.scheduler == 'CosineAnnealingLR':\n",
    "            cfg.T_max = cfg.epochs\n",
    "        scheduler = get_scheduler(optimizer, cfg, len(train_loader))\n",
    "        \n",
    "        best_auc, best_epoch = 0, 0\n",
    "        \n",
    "        for epoch in range(cfg.epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "            \n",
    "            train_loss, train_auc = train_one_epoch(\n",
    "                model, train_loader, optimizer, criterion, cfg.device,\n",
    "                scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None,\n",
    "                use_amp=cfg.use_amp,\n",
    "                grad_accum_steps=cfg.gradient_accumulation_steps\n",
    "                )\n",
    "            \n",
    "            val_loss, val_auc = validate(model, val_loader, criterion, cfg.device, use_amp=cfg.use_amp)\n",
    "            \n",
    "            if scheduler is not None and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(val_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "            \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_epoch = epoch + 1\n",
    "                print(f\"New best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "                \n",
    "                # Save best model\n",
    "                model_path = f\"{cfg.OUTPUT_DIR}/model_{cfg.timestamp}_{cfg.model_name}_fold{fold}.pth\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                    'epoch': epoch,\n",
    "                    'val_auc': val_auc,\n",
    "                    'train_auc': train_auc,\n",
    "                    'cfg': cfg\n",
    "                }, model_path)\n",
    "        \n",
    "        # Record best score for this fold\n",
    "        best_scores.append(best_auc)\n",
    "        print(f\"\\nTraining complete for fold {fold}. Best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "        \n",
    "        # Memory cleanup\n",
    "        del model, optimizer, scheduler\n",
    "        del train_loader, val_loader\n",
    "        del train_dataset, val_dataset, final_train_dataset\n",
    "        clean_gpu_memory()\n",
    "    \n",
    "    # Clean up pseudolabeled dataset\n",
    "    if pseudolabeled_dataset is not None:\n",
    "        del pseudolabeled_dataset\n",
    "        clean_gpu_memory()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    for fold, score in enumerate(best_scores):\n",
    "        print(f\"Fold {fold}: {score:.4f}\")\n",
    "    print(f\"Mean AUC: {np.mean(best_scores):.4f}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0e6b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.540675Z",
     "iopub.status.busy": "2025-03-17T14:00:46.540437Z",
     "iopub.status.idle": "2025-03-17T14:02:12.293026Z",
     "shell.execute_reply": "2025-03-17T14:02:12.292000Z"
    },
    "papermill": {
     "duration": 85.763673,
     "end_time": "2025-03-17T14:02:12.299868",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.536195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "Loaded soundscape sample list with 9726 training samples\n",
      "Will use external pseudolabels from: pseudolabels.csv\n",
      "LOAD_DATA is set to True\n",
      "Loaded 28578 pre-computed mel spectrograms for labeled data\n",
      "\n",
      "Initializing soundscape dataset with external pseudolabels...\n",
      "Loading external pseudolabels from pseudolabels.csv\n",
      "Loaded 28578 pre-computed mel spectrograms for labeled data\n",
      "\n",
      "Initializing soundscape dataset with external pseudolabels...\n",
      "Loading external pseudolabels from pseudolabels.csv\n",
      "Loaded 116712 external pseudolabels\n",
      "Filtering pseudolabels with confidence threshold: 0.5\n",
      "Loaded 116712 external pseudolabels\n",
      "Filtering pseudolabels with confidence threshold: 0.5\n",
      "Found 7562 samples with confidence >= 0.5\n",
      "Filtered dataset to 0 high-confidence samples\n",
      "Applied pseudolabels to 0 samples\n",
      "Loading soundscape metadata to selectively load spectrograms...\n",
      "Will load 0 spectrograms based on high-confidence pseudolabels\n",
      "Loading spectrograms from archive/train_soundscapes_mel_spec_12x5_256_256.npy selectively...\n",
      "Found 7562 samples with confidence >= 0.5\n",
      "Filtered dataset to 0 high-confidence samples\n",
      "Applied pseudolabels to 0 samples\n",
      "Loading soundscape metadata to selectively load spectrograms...\n",
      "Will load 0 spectrograms based on high-confidence pseudolabels\n",
      "Loading spectrograms from archive/train_soundscapes_mel_spec_12x5_256_256.npy selectively...\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEOFError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m#print(\"\\nStarting training...\")\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLOAD_DATA is set to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.LOAD_DATA\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoundscape_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43msoundscape_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m cfg.save_config()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(df, cfg, soundscape_df)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLoading spectrograms from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.spectrogram_npy_unlabeled\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m selectively...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Approach 1: Load all but use only what we need\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m all_soundscape_spectrograms = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspectrogram_npy_unlabeled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.item()\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Extract only the spectrograms we need\u001b[39;00m\n\u001b[32m     70\u001b[39m soundscape_spectrograms = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m all_soundscape_spectrograms.items() \n\u001b[32m     71\u001b[39m                         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m filtered_samplenames}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/numpy/lib/_npyio_impl.py:480\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    477\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    478\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    484\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/numpy/lib/format.py:820\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    818\u001b[39m     pickle_kwargs = {}\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     array = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    822\u001b[39m     \u001b[38;5;66;03m# Friendlier error message\u001b[39;00m\n\u001b[32m    823\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnpickling a python object failed: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    824\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mYou may need to pass the encoding= option \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    825\u001b[39m                        \u001b[33m\"\u001b[39m\u001b[33mto numpy.load\u001b[39m\u001b[33m\"\u001b[39m % (err,)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mEOFError\u001b[39m: Ran out of input"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "\n",
    "    # Load soundscape data if external pseudolabels are enabled\n",
    "    soundscape_df = None\n",
    "    if cfg.use_external_pseudolabels:\n",
    "        soundscape_df = pd.read_csv(cfg.unlabeled_sample_list)\n",
    "        print(f\"Loaded soundscape sample list with {len(soundscape_df)} training samples\")\n",
    "        print(f\"Will use external pseudolabels from: {cfg.external_pseudolabels_path}\")\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    print(f\"LOAD_DATA is set to {cfg.LOAD_DATA}\")\n",
    "\n",
    "    run_training(train_df, cfg, soundscape_df=soundscape_df)\n",
    "    print(\"\\nTraining complete!\")\n",
    "    cfg.save_config()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 6886569,
     "sourceId": 11053663,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".birdclef_env (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.861675,
   "end_time": "2025-03-17T14:02:15.686871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-17T14:00:29.825196",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fa836ee22b04b368008c3690b558e46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "114dd08c70bd4b1c9eca37e27bf08897": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1300468cac164026a61e5e60b05b005d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "158d32467f5247c983eb8907b6f5436f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad27b2a5cded4c23a3f72be3cee7c158",
        "IPY_MODEL_2d82fd9a33be40a19b68a6b37ee2375c",
        "IPY_MODEL_8720627fe38240cb88edd61a2fa45481"
       ],
       "layout": "IPY_MODEL_8eca206926bb44e9b42a5170bf4b1492",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1ad6a9d60ae24934ae355801b4992850": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1be8903e7c5d424abe30c82905dfa291",
        "IPY_MODEL_beceebaa8bef4939a3027e1756c820ca",
        "IPY_MODEL_65c613e48ff14d02b91adbeae536f703"
       ],
       "layout": "IPY_MODEL_7d38c7c32ff24563ae51248957aac76a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1be8903e7c5d424abe30c82905dfa291": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fbd77392c5e94748a19ab6adc204c0f0",
       "placeholder": "",
       "style": "IPY_MODEL_5c8f99997b3d447cb7664e6c8213d5af",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation:100%"
      }
     },
     "1e6784d317664982818c369ec64d4375": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b325002c114fb6801da1f6f7e2a2eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b951c7b2c847bbaf9c066b7f932c12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f808eb60489b4ef2bc76b055d5c477ff",
       "placeholder": "",
       "style": "IPY_MODEL_ed26d5cb2ff3426a9449e0166b68afbf",
       "tabbable": null,
       "tooltip": null,
       "value": "31/31[00:05&lt;00:00,5.70it/s,train_loss=0.0308,lr=0.000488]"
      }
     },
     "2b7b0d3f79504d87a8dbfb2f7893399a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_527982470da345c590c47f26ce1f9ccf",
       "max": 31,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ddf272308e664d24820c9ca6e917e456",
       "tabbable": null,
       "tooltip": null,
       "value": 31
      }
     },
     "2d82fd9a33be40a19b68a6b37ee2375c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4cc700caf0949c5bf39d8f7539ba2d2",
       "max": 21355344,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_925afd9abcc74142bd88971863bb345b",
       "tabbable": null,
       "tooltip": null,
       "value": 21355344
      }
     },
     "35b20f9b2e8746c68e234fcb6d29f047": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_23b325002c114fb6801da1f6f7e2a2eb",
       "max": 31,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_926aa065fa4f40b4b623fd079ba7cd0f",
       "tabbable": null,
       "tooltip": null,
       "value": 31
      }
     },
     "527982470da345c590c47f26ce1f9ccf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "546a352a5f6d48bd9769e2dff67a1419": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "577df72f0ce349d8988b16f4429c3116": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6314d51e57944ca399dd8819d2c5c214",
       "placeholder": "",
       "style": "IPY_MODEL_c4ccd0e9a85348d4a50bda1dc66d9658",
       "tabbable": null,
       "tooltip": null,
       "value": "Training:100%"
      }
     },
     "5c8f99997b3d447cb7664e6c8213d5af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "60623af9dc82439fbac9dce1bb4a9d90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6314d51e57944ca399dd8819d2c5c214": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65c613e48ff14d02b91adbeae536f703": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_114dd08c70bd4b1c9eca37e27bf08897",
       "placeholder": "",
       "style": "IPY_MODEL_f8e3ad286a374d558e61627ba3a67d26",
       "tabbable": null,
       "tooltip": null,
       "value": "32/32[00:02&lt;00:00,22.08it/s]"
      }
     },
     "66d95ea040244824b4f188b4985e8cb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "690250bf83464a7f91cd587a5f56d48e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7036c511c9b34e76837009a371c58be9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1300468cac164026a61e5e60b05b005d",
       "placeholder": "",
       "style": "IPY_MODEL_690250bf83464a7f91cd587a5f56d48e",
       "tabbable": null,
       "tooltip": null,
       "value": "32/32[00:01&lt;00:00,22.00it/s]"
      }
     },
     "74c1cd7782554123a2d89d46d13808b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d995347d83ec40e2b0c1db58a78e3dde",
        "IPY_MODEL_dcdaa701c23b4a1697b18ae319e036f6",
        "IPY_MODEL_7036c511c9b34e76837009a371c58be9"
       ],
       "layout": "IPY_MODEL_dc55c130999847b6a7460d8d68f31668",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7d38c7c32ff24563ae51248957aac76a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "871d479608024b77bb2db8278e3f659d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8720627fe38240cb88edd61a2fa45481": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_934ed224b7fd4de3ab54a89a789f0e3a",
       "placeholder": "",
       "style": "IPY_MODEL_a42ef4d205e74949b7fb2dee1039c2d8",
       "tabbable": null,
       "tooltip": null,
       "value": "21.4M/21.4M[00:00&lt;00:00,86.8MB/s]"
      }
     },
     "8e978a7645e7420fb2e452a3e2e7f69d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab2f0fc298124ff685860a158b2ec252",
       "placeholder": "",
       "style": "IPY_MODEL_9366d6929e0c44408fb54456fff6c241",
       "tabbable": null,
       "tooltip": null,
       "value": "31/31[00:06&lt;00:00,5.75it/s,train_loss=0.0344,lr=0.0005]"
      }
     },
     "8eca206926bb44e9b42a5170bf4b1492": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9193f88c4b9842c4a73d33b86e2a79b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "925afd9abcc74142bd88971863bb345b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "926aa065fa4f40b4b623fd079ba7cd0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "934ed224b7fd4de3ab54a89a789f0e3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9366d6929e0c44408fb54456fff6c241": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "93a38cd64b7e457082b679b1aace02df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a17d437eca184c35ae51d6ddf160ad00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b3d1cca7cebb47ee9a5fb1281ffa00bb",
       "placeholder": "",
       "style": "IPY_MODEL_546a352a5f6d48bd9769e2dff67a1419",
       "tabbable": null,
       "tooltip": null,
       "value": "Training:100%"
      }
     },
     "a337ff0d214a41d1a7314a4ca229bfd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a42ef4d205e74949b7fb2dee1039c2d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab2f0fc298124ff685860a158b2ec252": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac1a06c6ab024f11a1a52431788f6823": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad27b2a5cded4c23a3f72be3cee7c158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_93a38cd64b7e457082b679b1aace02df",
       "placeholder": "",
       "style": "IPY_MODEL_fb003526535b4cba8efa507d3f92a66b",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "b3d1cca7cebb47ee9a5fb1281ffa00bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beceebaa8bef4939a3027e1756c820ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac1a06c6ab024f11a1a52431788f6823",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0fa836ee22b04b368008c3690b558e46",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "c4ccd0e9a85348d4a50bda1dc66d9658": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cafb1e5ee8af47dc9a8813cdb7dad1b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_577df72f0ce349d8988b16f4429c3116",
        "IPY_MODEL_2b7b0d3f79504d87a8dbfb2f7893399a",
        "IPY_MODEL_23b951c7b2c847bbaf9c066b7f932c12"
       ],
       "layout": "IPY_MODEL_a337ff0d214a41d1a7314a4ca229bfd3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d995347d83ec40e2b0c1db58a78e3dde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e6784d317664982818c369ec64d4375",
       "placeholder": "",
       "style": "IPY_MODEL_66d95ea040244824b4f188b4985e8cb2",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation:100%"
      }
     },
     "dc55c130999847b6a7460d8d68f31668": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcdaa701c23b4a1697b18ae319e036f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_871d479608024b77bb2db8278e3f659d",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60623af9dc82439fbac9dce1bb4a9d90",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "ddf272308e664d24820c9ca6e917e456": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e80cbc93209642a8bbe28877b257eab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a17d437eca184c35ae51d6ddf160ad00",
        "IPY_MODEL_35b20f9b2e8746c68e234fcb6d29f047",
        "IPY_MODEL_8e978a7645e7420fb2e452a3e2e7f69d"
       ],
       "layout": "IPY_MODEL_9193f88c4b9842c4a73d33b86e2a79b8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ed26d5cb2ff3426a9449e0166b68afbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f4cc700caf0949c5bf39d8f7539ba2d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f808eb60489b4ef2bc76b055d5c477ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8e3ad286a374d558e61627ba3a67d26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fb003526535b4cba8efa507d3f92a66b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fbd77392c5e94748a19ab6adc204c0f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
