{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd19261b",
   "metadata": {
    "papermill": {
     "duration": 0.00461,
     "end_time": "2025-03-17T14:00:32.494653",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.490043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **BirdCLEF 2025 Training Notebook**\n",
    "\n",
    "This is a baseline training pipeline for BirdCLEF 2025 using EfficientNetB0 with PyTorch and Timm(for pretrained EffNet). You can check inference and preprocessing notebooks in the following links: \n",
    "\n",
    "- [EfficientNet B0 Pytorch [Inference] | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-inference-birdclef-25)\n",
    "\n",
    "  \n",
    "- [Transforming Audio-to-Mel Spec. | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/transforming-audio-to-mel-spec-birdclef-25)  \n",
    "\n",
    "Note that by default this notebook is in Debug Mode, so it will only train the model with 2 epochs, but the [weight](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-effnetb0-starter-weight) I used in the inference notebook was obtained after 10 epochs of training.\n",
    "\n",
    "**Features**\n",
    "* Implement with Pytorch and Timm\n",
    "* Flexible audio processing with both pre-computed and on-the-fly mel spectrograms\n",
    "* Stratified 5-fold cross-validation with ensemble capability\n",
    "* Mixup training for improved generalization\n",
    "* Spectrogram augmentations (time/frequency masking, brightness adjustment)\n",
    "* AdamW optimizer with Cosine Annealing LR scheduling\n",
    "* Debug mode for quick experimentation with smaller datasets\n",
    "\n",
    "**Pre-computed Spectrograms**\n",
    "For faster training, you can use pre-computed mel spectrograms from [this dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) by setting `LOAD_DATA = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a699fa",
   "metadata": {
    "papermill": {
     "duration": 0.003494,
     "end_time": "2025-03-17T14:00:32.502085",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.498591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ca2ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:32.510711Z",
     "iopub.status.busy": "2025-03-17T14:00:32.510382Z",
     "iopub.status.idle": "2025-03-17T14:00:46.238785Z",
     "shell.execute_reply": "2025-03-17T14:00:46.238073Z"
    },
    "papermill": {
     "duration": 13.73451,
     "end_time": "2025-03-17T14:00:46.240399",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.505889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np, pandas as pd, math, os, random, warnings, json, datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Specific imports\n",
    "import logging, gc, time, cv2\n",
    "\n",
    "# Audio processing imports\n",
    "import librosa\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Other ML imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timm\n",
    "\n",
    "# Custom imports\n",
    "from processing import audio2melspec, process_audio_file, generate_spectrograms\n",
    "from utilities import set_seed, collate_fn\n",
    "from training_utilities import get_optimizer, get_scheduler, get_criterion\n",
    "\n",
    "# Suppress warnings and set logging level\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f9c08",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-03-17T14:00:46.248317",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.244596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06591264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.256618Z",
     "iopub.status.busy": "2025-03-17T14:00:46.256366Z",
     "iopub.status.idle": "2025-03-17T14:00:46.333416Z",
     "shell.execute_reply": "2025-03-17T14:00:46.332684Z"
    },
    "papermill": {
     "duration": 0.082704,
     "end_time": "2025-03-17T14:00:46.334712",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.252008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    \n",
    "    seed = 42\n",
    "    debug = False  \n",
    "    num_workers = 4\n",
    "    \n",
    "    OUTPUT_DIR = 'output/'\n",
    "    train_datadir = 'birdclef-2025/train_audio'\n",
    "    train_csv = 'birdclef-2025/train.csv'\n",
    "    train_soundscapes = 'birdclef-2025/train_soundscapes'\n",
    "    test_soundscapes = 'birdclef-2025/test_soundscapes'\n",
    "    submission_csv = 'birdclef-2025/sample_submission.csv'\n",
    "    taxonomy_csv = 'birdclef-2025/taxonomy.csv'\n",
    "    unlabeled_sample_list = \"birdclef-2025/sample_list.csv\"\n",
    "\n",
    "    spectrogram_npy = 'archive/birdclef2025_melspec_5sec_256_256.npy'\n",
    "    spectrogram_npy_unlabeled = 'archive/train_soundscapes_mel_spec_5_256_256.npy'\n",
    " \n",
    "    model_name = 'efficientnet_b0'\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    pretrained = True\n",
    "    in_channels = 1\n",
    "\n",
    "    use_soundscapes = True\n",
    "    pseudo_update_threshold = 0.95\n",
    "    start_pseudo_epoch = 1\n",
    "    remove_pseudo = True\n",
    "\n",
    "    LOAD_DATA = True  \n",
    "    FS = 32000\n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)\n",
    "    \n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "    criterion = 'CombinedLoss'  # Options: 'BCEWithLogitsLoss', 'FocalLoss', 'CombinedLoss'\n",
    "    \n",
    "    # Focal Loss parameters\n",
    "    focal_alpha = 1.0\n",
    "    focal_gamma = 3.0\n",
    "    \n",
    "    # Combined Loss weights\n",
    "    bce_weight = 0.5\n",
    "    focal_weight = 0.5\n",
    "\n",
    "    n_fold = 1\n",
    "\n",
    "    optimizer = 'AdamW'\n",
    "    lr = 5e-4 \n",
    "    weight_decay = 1e-5\n",
    "  \n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    min_lr = 1e-6\n",
    "    T_max = epochs\n",
    "\n",
    "    aug_prob = 0.5  \n",
    "    mixup_alpha = 0.5  \n",
    "    \n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.epochs = 2\n",
    "            self.start_pseudo_epoch = 1\n",
    "\n",
    "    def save_config(self):\n",
    "        config_dict = {attr: getattr(self, attr) for attr in dir(self) if not attr.startswith('__') and not callable(getattr(self, attr))}\n",
    "        filename = f\"config_{self.timestamp}_{self.model_name}.json\"\n",
    "        with open(os.path.join(self.OUTPUT_DIR, filename), 'w') as f:\n",
    "            json.dump(config_dict, f, indent=4, default=str)\n",
    "        print(f\"Config saved to {os.path.join(self.OUTPUT_DIR, filename)}\")\n",
    "\n",
    "cfg = CFG()\n",
    "set_seed(cfg.seed)\n",
    "cfg.update_debug_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4bc37",
   "metadata": {
    "papermill": {
     "duration": 0.003588,
     "end_time": "2025-03-17T14:00:46.367790",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.364202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-processing\n",
    "These functions handle the transformation of audio files to mel spectrograms for model input, with flexibility controlled by the `LOAD_DATA` parameter. The process involves either loading pre-computed spectrograms from this [dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) (when `LOAD_DATA=True`) or dynamically generating them (when `LOAD_DATA=False`), transforming audio data into spectrogram representations, and preparing it for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939033bf",
   "metadata": {
    "papermill": {
     "duration": 0.003549,
     "end_time": "2025-03-17T14:00:46.393394",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.389845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Preparation and Data Augmentations\n",
    "We'll convert audio to mel spectrograms and apply random augmentations with 50% probability each - including time stretching, pitch shifting, and volume adjustments. This randomized approach creates diverse training samples from the same audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6b2ea48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.401415Z",
     "iopub.status.busy": "2025-03-17T14:00:46.401216Z",
     "iopub.status.idle": "2025-03-17T14:00:46.413659Z",
     "shell.execute_reply": "2025-03-17T14:00:46.412877Z"
    },
    "papermill": {
     "duration": 0.017836,
     "end_time": "2025-03-17T14:00:46.414835",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.396999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        \n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "\n",
    "        if 'filepath' not in self.df.columns:\n",
    "            self.df['filepath'] = self.cfg.train_datadir + '/' + self.df.filename\n",
    "        \n",
    "        if 'samplename' not in self.df.columns:\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "        if self.spectrograms:\n",
    "            sample_names = set(self.df['samplename'])\n",
    "            found_samples = sum(1 for name in sample_names if name in self.spectrograms)\n",
    "            print(f\"Found {found_samples} matching spectrograms for {mode} dataset out of {len(self.df)} samples\")\n",
    "        \n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        samplename = row['samplename']\n",
    "\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        elif not self.cfg.LOAD_DATA:\n",
    "            spec = process_audio_file(row['filepath'], self.cfg)\n",
    "        else: spec = None\n",
    "\n",
    "        if spec is None:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":  # Only print warning during training\n",
    "                print(f\"Warning: Spectrogram for {samplename} not found and could not be generated\")\n",
    "\n",
    "        spec = torch.from_numpy(spec).float().unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "        \n",
    "        target = self.encode_label(row['primary_label'])\n",
    "        \n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            \n",
    "            for label in secondary_labels:\n",
    "                idx = self.label_to_idx.get(label)\n",
    "                if idx is not None:\n",
    "                    target[idx] = 1.0\n",
    "        \n",
    "        return {\n",
    "            'melspec': spec, \n",
    "            'target': torch.from_numpy(target).float(),\n",
    "            'filename': row['filename']\n",
    "        }\n",
    "    \n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        \"\"\"Apply augmentations to spectrogram\"\"\"\n",
    "    \n",
    "        # Time masking (horizontal stripes)\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "        \n",
    "        # Frequency masking (vertical stripes)\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "        \n",
    "        # Random brightness/contrast\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1) \n",
    "            \n",
    "        return spec\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        \"\"\"Encode label to one-hot vector\"\"\"\n",
    "        target = np.zeros(self.num_classes)\n",
    "        idx = self.label_to_idx.get(label)\n",
    "        if idx is not None:\n",
    "            target[idx] = 1.0\n",
    "        return target\n",
    "    \n",
    "    def extend(self, new_samples):\n",
    "        \"\"\"Extend the dataset with new samples, supporting secondary labels.\"\"\"\n",
    "        print(f\"Adding {len(new_samples)} new samples to the train dataset.\")\n",
    "        \n",
    "        new_rows = []\n",
    "        new_specs = {}\n",
    "\n",
    "        for sample in new_samples:\n",
    "            filename = sample['filename']\n",
    "            samplename = filename.split('/')[0] + '-' + filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "            # Ensure target is a proper one-hot encoded vector\n",
    "            target_array = sample['target'].numpy() if isinstance(sample['target'], torch.Tensor) else sample['target']\n",
    "            if target_array.ndim > 1 or target_array.sum() > 1.5:\n",
    "                # If multi-label vector, pick primary label as the one with highest score\n",
    "                primary_label_idx = target_array.argmax()\n",
    "            else:\n",
    "                # If already one-hot\n",
    "                primary_label_idx = target_array.argmax()\n",
    "\n",
    "            primary_label = self.species_ids[primary_label_idx]\n",
    "\n",
    "            # Optional: If you want to save secondary labels (everything else non-zero except the primary)\n",
    "            secondary_label_indices = [i for i, val in enumerate(target_array) if val > 0 and i != primary_label_idx]\n",
    "            secondary_labels = [self.species_ids[i] for i in secondary_label_indices] if secondary_label_indices else ['']\n",
    "\n",
    "            new_row = {\n",
    "                'filename': filename,\n",
    "                'samplename': samplename,\n",
    "                'primary_label': primary_label,\n",
    "                'secondary_labels': str(secondary_labels),  # store as string for compatibility\n",
    "                'filepath': self.cfg.test_soundscapes + '/' + filename  # comes from test_soundscapes!\n",
    "            }\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "            # Store the melspec separately\n",
    "            new_specs[samplename] = sample['melspec'].squeeze(0).numpy()  # remove channel dim for consistency\n",
    "\n",
    "        # Append to df\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        self.df = pd.concat([self.df, new_df], ignore_index=True)\n",
    "\n",
    "        # Update spectrograms dictionary if available\n",
    "        if self.spectrograms is not None:\n",
    "            self.spectrograms.update(new_specs)\n",
    "        else:\n",
    "            self.spectrograms = new_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f1c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundscapeDatasetFromNPY(Dataset):\n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\"):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        \n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "        df[\"primary_label\"] = None\n",
    "        self.primary_label = [None] * len(self.df)\n",
    "        df[\"filename\"] = df[\"samplename\"].apply(lambda x: x+\".ogg\")\n",
    "\n",
    "        # Count number of samples\n",
    "        sample_names = set(self.df['samplename'])\n",
    "        if self.spectrograms:\n",
    "            found_samples = sum(1 for name in sample_names if name in self.spectrograms)\n",
    "            print(f\"Found {found_samples} matching spectrograms for {mode} dataset out of {len(self.df)} samples\")\n",
    "        \n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        samplename = row['samplename']\n",
    "        spec = None\n",
    "\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        elif not self.cfg.LOAD_DATA:\n",
    "            spec = process_audio_file(row['filepath'], self.cfg)\n",
    "\n",
    "        if spec is None:\n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            if self.mode == \"train\":  # Only print warning during training\n",
    "                print(f\"Warning: Spectrogram for {samplename} not found and could not be generated\")\n",
    "\n",
    "        spec = torch.tensor(spec, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        target = self.encode_label(row['primary_label'])\n",
    "\n",
    "        return {\n",
    "            'melspec': spec, \n",
    "            'target': target,\n",
    "            'filename': row['filename'],\n",
    "            'index': idx\n",
    "        }\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        \"\"\"Encode label to one-hot vector\"\"\"\n",
    "        target = np.zeros(self.num_classes)\n",
    "        if label in self.label_to_idx:\n",
    "            target[self.label_to_idx[label]] = 1.0\n",
    "        elif label is None:\n",
    "            return None\n",
    "        return target\n",
    "    \n",
    "    def remove_indices(self, indices_to_remove):\n",
    "        \"\"\"Remove samples by their indices.\"\"\"\n",
    "        print(f\"Removing {len(indices_to_remove)} samples from pseudo dataset.\")\n",
    "        self.df = self.df.drop(indices_to_remove).reset_index(drop=True)\n",
    "        if hasattr(self, 'primary_label'):\n",
    "            self.primary_label = [self.primary_label[i] for i in range(len(self.primary_label)) if i not in indices_to_remove]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb84a1",
   "metadata": {
    "papermill": {
     "duration": 0.003491,
     "end_time": "2025-03-17T14:00:46.436543",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.433052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741451ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.444643Z",
     "iopub.status.busy": "2025-03-17T14:00:46.444412Z",
     "iopub.status.idle": "2025-03-17T14:00:46.452684Z",
     "shell.execute_reply": "2025-03-17T14:00:46.452070Z"
    },
    "papermill": {
     "duration": 0.013532,
     "end_time": "2025-03-17T14:00:46.453738",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.440206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "        cfg.num_classes = len(taxonomy_df)\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=0.2,\n",
    "            drop_path_rate=0.2\n",
    "        )\n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        \n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "            \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "        indices = torch.randperm(batch_size).to(x.device, non_blocking=True)\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa08772",
   "metadata": {
    "papermill": {
     "duration": 0.003637,
     "end_time": "2025-03-17T14:00:46.461097",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.457460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Utilities\n",
    "We are configuring our optimization strategy with the AdamW optimizer, cosine scheduling, and the BCEWithLogitsLoss criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd70fd",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2025-03-17T14:00:46.483348",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.479834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d944f8ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.491507Z",
     "iopub.status.busy": "2025-03-17T14:00:46.491314Z",
     "iopub.status.idle": "2025-03-17T14:00:46.504038Z",
     "shell.execute_reply": "2025-03-17T14:00:46.503466Z"
    },
    "papermill": {
     "duration": 0.018173,
     "end_time": "2025-03-17T14:00:46.505200",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.487027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, scheduler=None, pseudo_loader=None, pseudo_dataset=None, use_amp=True):\n",
    "    model.train()\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "    total_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "\n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "    \n",
    "    for step, batch in pbar:\n",
    "            \n",
    "        inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "        targets = batch['target'].to(device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(enabled=use_amp, device_type=cfg.device):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        all_outputs.append(outputs.detach().cpu())\n",
    "        all_targets.append(targets.detach().cpu())\n",
    "        pbar.set_postfix({'train_loss': total_loss / len(all_outputs),'lr': optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    auc = calculate_auc(all_targets.numpy(), all_outputs)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "def update_pseudo_labels(model, pseudo_loader, pseudo_dataset, train_dataset, device, threshold=0.9, remove_pseudo=True):\n",
    "    model.eval()\n",
    "    to_remove = []\n",
    "    new_samples = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(pseudo_loader, desc=\"Updating pseudo-labels\"):\n",
    "            inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "            indices = batch['index']\n",
    "            filenames = batch['filename']\n",
    "            outputs = model(inputs)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            probs = probs.cpu().numpy()\n",
    "            inputs = inputs.cpu()\n",
    "\n",
    "            for i, prob in enumerate(probs):\n",
    "                top_class = np.argmax(prob)\n",
    "                top_confidence = prob[top_class]\n",
    "\n",
    "                if top_confidence > threshold:\n",
    "                    target = np.zeros_like(prob)\n",
    "                    target[top_class] = 1.0\n",
    "\n",
    "                    new_samples.append({'melspec': inputs[i], 'target': torch.tensor(target, dtype=torch.float32), 'filename': filenames[i]})\n",
    "                    to_remove.append(indices[i])\n",
    "\n",
    "    train_dataset.extend(new_samples)\n",
    "\n",
    "    if remove_pseudo and to_remove:\n",
    "        pseudo_dataset.remove_indices(to_remove)\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_outputs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validation\"):\n",
    "            inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "            targets = batch['target'].to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(outputs.detach().cpu())\n",
    "            all_targets.append(targets.detach().cpu())\n",
    "    \n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    \n",
    "    auc = calculate_auc(all_targets, all_outputs)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "def calculate_auc(targets: np.array , outputs: torch.Tensor) -> float:\n",
    "  \n",
    "    aucs = []\n",
    "    probs = torch.sigmoid(outputs).numpy()\n",
    "    \n",
    "    for i in range(targets.shape[1]):\n",
    "        if np.sum(targets[:, i]) > 0:\n",
    "            class_auc = roc_auc_score(targets[:, i], probs[:, i])\n",
    "            aucs.append(class_auc)\n",
    "    \n",
    "    return np.mean(aucs) if aucs else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b760d60e",
   "metadata": {
    "papermill": {
     "duration": 0.00344,
     "end_time": "2025-03-17T14:00:46.512303",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.508863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de76a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.520217Z",
     "iopub.status.busy": "2025-03-17T14:00:46.520008Z",
     "iopub.status.idle": "2025-03-17T14:00:46.531337Z",
     "shell.execute_reply": "2025-03-17T14:00:46.530758Z"
    },
    "papermill": {
     "duration": 0.016548,
     "end_time": "2025-03-17T14:00:46.532461",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.515913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(df, cfg, soundscape_df=None):\n",
    "    \"\"\"Training function that can either use pre-computed spectrograms or generate them on-the-fly\"\"\"\n",
    "\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    species_ids = taxonomy_df['primary_label'].tolist()\n",
    "    cfg.num_classes = len(species_ids)\n",
    "    \n",
    "    if cfg.debug: cfg.update_debug_settings()\n",
    "\n",
    "    spectrograms = None\n",
    "    if cfg.LOAD_DATA:\n",
    "        print(\"Loading pre-computed mel spectrograms from NPY file...\")\n",
    "        try:\n",
    "            spectrograms = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "            soundscape_spectrograms = np.load(cfg.spectrogram_npy_unlabeled, allow_pickle=True).item()\n",
    "            print(f\"Loaded {len(spectrograms)} pre-computed mel spectrograms\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading pre-computed spectrograms: {e}\")\n",
    "            print(\"Will generate spectrograms on-the-fly instead.\")\n",
    "            cfg.LOAD_DATA = False\n",
    "    \n",
    "    if not cfg.LOAD_DATA:\n",
    "        print(\"Will generate spectrograms on-the-fly during training.\")\n",
    "        if 'filepath' not in df.columns:\n",
    "            df['filepath'] = cfg.train_datadir + '/' + df.filename\n",
    "        if 'samplename' not in df.columns:\n",
    "            df['samplename'] = df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "\n",
    "    if cfg.n_fold > 1:\n",
    "        skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n",
    "        folds = skf.split(df, df['primary_label'])\n",
    "    else:\n",
    "        folds = [(np.arange(len(df)), np.arange(len(df)))]\n",
    "\n",
    "    best_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "            \n",
    "        print(f'\\n{\"=\"*30} Fold {fold} {\"=\"*30}')\n",
    "        \n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        print(f'Training set: {len(train_df)} samples')\n",
    "        print(f'Validation set: {len(val_df)} samples')\n",
    "        \n",
    "        train_dataset = BirdCLEFDatasetFromNPY(train_df, cfg, spectrograms=spectrograms, mode='train')\n",
    "        val_dataset = BirdCLEFDatasetFromNPY(val_df, cfg, spectrograms=spectrograms, mode='valid')\n",
    "        soundscape_dataset = SoundscapeDatasetFromNPY(soundscape_df, cfg, spectrograms=soundscape_spectrograms, mode='train')\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers,pin_memory=True,collate_fn=collate_fn,drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers,pin_memory=True,collate_fn=collate_fn)\n",
    "        soundscape_loader = DataLoader(soundscape_dataset,batch_size=cfg.batch_size,shuffle=True,num_workers=cfg.num_workers,pin_memory=True,collate_fn=collate_fn,drop_last=True)\n",
    "        \n",
    "        model = BirdCLEFModel(cfg).to(cfg.device, non_blocking=True)\n",
    "        model = torch.compile(model, backend=\"inductor\")\n",
    "        optimizer = get_optimizer(model, cfg)\n",
    "        criterion = get_criterion(cfg)\n",
    "        scheduler = get_scheduler(optimizer, cfg, len(train_loader))\n",
    "        \n",
    "        best_auc, best_epoch = 0, 0\n",
    "        \n",
    "        for epoch in range(cfg.epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "            use_pseduo_labels = cfg.use_soundscapes and (epoch+1) >= cfg.start_pseudo_epoch\n",
    "\n",
    "            train_loss, train_auc = train_one_epoch(model, train_loader, optimizer, criterion, cfg.device,\n",
    "                scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None,\n",
    "                pseudo_loader=soundscape_loader if use_pseduo_labels else None,\n",
    "                pseudo_dataset=soundscape_dataset if use_pseduo_labels else None\n",
    "            )\n",
    "                        \n",
    "            if use_pseduo_labels:\n",
    "                update_pseudo_labels(model, soundscape_loader, soundscape_dataset, train_dataset, cfg.device, threshold=cfg.pseudo_update_threshold, remove_pseudo=cfg.remove_pseudo)\n",
    "            \n",
    "            val_loss, val_auc = validate(model, val_loader, criterion, cfg.device)\n",
    "\n",
    "            if scheduler is not None and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(val_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "            \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_epoch = epoch + 1\n",
    "                print(f\"New best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                    'epoch': epoch,\n",
    "                    'val_auc': val_auc,\n",
    "                    'train_auc': train_auc,\n",
    "                    'cfg': cfg\n",
    "                }, f\"{cfg.OUTPUT_DIR}/model_{cfg.timestamp}_{cfg.model_name}_fold{fold}.pth\")\n",
    "        \n",
    "        best_scores.append(best_auc)\n",
    "        print(f\"\\nBest AUC for fold {fold}: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "        \n",
    "        # Clear memory\n",
    "        del model, optimizer, scheduler, train_loader, val_loader, soundscape_loader\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    for fold, score in enumerate(best_scores):\n",
    "        print(f\"Fold {fold}: {score:.4f}\")\n",
    "    print(f\"Mean AUC: {np.mean(best_scores):.4f}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0e6b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.540675Z",
     "iopub.status.busy": "2025-03-17T14:00:46.540437Z",
     "iopub.status.idle": "2025-03-17T14:02:12.293026Z",
     "shell.execute_reply": "2025-03-17T14:02:12.292000Z"
    },
    "papermill": {
     "duration": 85.763673,
     "end_time": "2025-03-17T14:02:12.299868",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.536195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "\n",
      "Starting training...\n",
      "LOAD_DATA is set to True\n",
      "Using pre-computed mel spectrograms from NPY file\n",
      "Loading pre-computed mel spectrograms from NPY file...\n",
      "Loaded 28564 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 28564 samples\n",
      "Validation set: 28564 samples\n",
      "Found 28564 matching spectrograms for train dataset out of 28564 samples\n",
      "Found 28564 matching spectrograms for valid dataset out of 28564 samples\n",
      "Found 9726 matching spectrograms for train dataset out of 9726 samples\n",
      "Loaded 28564 pre-computed mel spectrograms\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 28564 samples\n",
      "Validation set: 28564 samples\n",
      "Found 28564 matching spectrograms for train dataset out of 28564 samples\n",
      "Found 28564 matching spectrograms for valid dataset out of 28564 samples\n",
      "Found 9726 matching spectrograms for train dataset out of 9726 samples\n",
      "\n",
      "Epoch 1/10\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6738bccb941e4d76ac20cfb1520ada74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0511 12:41:38.372000 1439 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWill generate spectrograms on-the-fly during training\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoundscape_df\u001b[49m\u001b[43m=\u001b[49m\u001b[43msoundscape_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining complete!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m cfg.save_config()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(df, cfg, soundscape_df)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg.epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m use_pseduo_labels = cfg.use_soundscapes \u001b[38;5;129;01mand\u001b[39;00m (epoch+\u001b[32m1\u001b[39m) >= cfg.start_pseudo_epoch\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m train_loss, train_auc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOneCycleLR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpseudo_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43msoundscape_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_pseduo_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpseudo_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msoundscape_dataset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_pseduo_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     71\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_pseduo_labels:\n\u001b[32m     74\u001b[39m     update_pseudo_labels(model, soundscape_loader, soundscape_dataset, train_dataset, cfg.device, threshold=cfg.pseudo_update_threshold, remove_pseudo=cfg.remove_pseudo)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, optimizer, criterion, device, scheduler, pseudo_loader, pseudo_dataset, use_amp)\u001b[39m\n\u001b[32m     14\u001b[39m optimizer.zero_grad()\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled=use_amp, device_type=cfg.device):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     loss = criterion(outputs, targets)\n\u001b[32m     20\u001b[39m scaler.scale(loss).backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:574\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    570\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    571\u001b[39m )\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m574\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    576\u001b[39m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[32m    577\u001b[39m     torch._C._functorch.pop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[32m    578\u001b[39m         saved_dynamic_layer_stack_depth\n\u001b[32m    579\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1380\u001b[39m, in \u001b[36mCatchErrorsWrapper.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, frame_state)\u001b[39m\n\u001b[32m   1374\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[32m   1375\u001b[39m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m.hooks, frame_state\n\u001b[32m   1376\u001b[39m             )\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[32m   1379\u001b[39m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:1164\u001b[39m, in \u001b[36mConvertFrame.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m   1162\u001b[39m counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     counters[\u001b[33m\"\u001b[39m\u001b[33mframes\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m   1168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:547\u001b[39m, in \u001b[36mConvertFrameAssert.__call__\u001b[39m\u001b[34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[39m\n\u001b[32m    544\u001b[39m     dynamo_tls.traced_frame_infos.append(info)\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    559\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    560\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    561\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:986\u001b[39m, in \u001b[36m_compile\u001b[39m\u001b[34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[39m\n\u001b[32m    984\u001b[39m guarded_code = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     guarded_code = \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[32m    989\u001b[39m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[32m    996\u001b[39m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[32m    997\u001b[39m     put_code_state()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:715\u001b[39m, in \u001b[36m_compile.<locals>.compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    713\u001b[39m     stack.enter_context(torch._dynamo.callback_handler.install_callbacks())\n\u001b[32m    714\u001b[39m     stack.enter_context(CompileTimeInstructionCounter.record())\n\u001b[32m--> \u001b[39m\u001b[32m715\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_utils_internal.py:95\u001b[39m, in \u001b[36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mskip\u001b[39m\u001b[33m\"\u001b[39m] = skip + \u001b[32m1\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler.enabled:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler.profile_compile_time(\n\u001b[32m     98\u001b[39m     function, phase_name, *args, **kwargs\n\u001b[32m     99\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:750\u001b[39m, in \u001b[36m_compile.<locals>._compile_inner\u001b[39m\u001b[34m(code, one_graph, hooks, transform)\u001b[39m\n\u001b[32m    748\u001b[39m CompileContext.get().attempt = attempt\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     out_code = \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.RestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/bytecode_transformation.py:1361\u001b[39m, in \u001b[36mtransform_code_object\u001b[39m\u001b[34m(code, transformations, safe)\u001b[39m\n\u001b[32m   1358\u001b[39m instructions = cleaned_instructions(code, safe)\n\u001b[32m   1359\u001b[39m propagate_line_nums(instructions)\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:231\u001b[39m, in \u001b[36mpreserve_global_state.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m exit_stack.enter_context(torch_function_mode_stack_state_mgr)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    233\u001b[39m     cleanup.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/convert_frame.py:662\u001b[39m, in \u001b[36m_compile.<locals>.transform\u001b[39m\u001b[34m(instructions, code_options)\u001b[39m\n\u001b[32m    660\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    661\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer.output.tracing_context), tracer.set_current_tx():\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m         \u001b[43mtracer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exc.UnspecializeRestartAnalysis:\n\u001b[32m    664\u001b[39m     speculation_log.clear()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:2868\u001b[39m, in \u001b[36mInstructionTranslator.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2867\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2868\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:1052\u001b[39m, in \u001b[36mInstructionTranslatorBase.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1050\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1051\u001b[39m     \u001b[38;5;28mself\u001b[39m.output.push_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1053\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:962\u001b[39m, in \u001b[36mInstructionTranslatorBase.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28mself\u001b[39m.update_block_stack(inst)\n\u001b[32m    961\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output.should_exit\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3048\u001b[39m, in \u001b[36mInstructionTranslator.RETURN_VALUE\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3047\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[32m-> \u001b[39m\u001b[32m3048\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/symbolic_convert.py:3033\u001b[39m, in \u001b[36mInstructionTranslator._return\u001b[39m\u001b[34m(self, inst)\u001b[39m\n\u001b[32m   3028\u001b[39m _step_logger()(\n\u001b[32m   3029\u001b[39m     logging.INFO,\n\u001b[32m   3030\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.f_code.co_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst.opname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   3031\u001b[39m )\n\u001b[32m   3032\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m triggered compile\u001b[39m\u001b[33m\"\u001b[39m, inst.opname)\n\u001b[32m-> \u001b[39m\u001b[32m3033\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3034\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3035\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3036\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreturn_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   3037\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3038\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3039\u001b[39m return_inst = (\n\u001b[32m   3040\u001b[39m     create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3041\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inst.opname == \u001b[33m\"\u001b[39m\u001b[33mRETURN_VALUE\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m create_instruction(\u001b[33m\"\u001b[39m\u001b[33mRETURN_CONST\u001b[39m\u001b[33m\"\u001b[39m, argval=inst.argval)\n\u001b[32m   3043\u001b[39m )\n\u001b[32m   3044\u001b[39m \u001b[38;5;28mself\u001b[39m.output.add_output_instructions([return_inst])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1101\u001b[39m, in \u001b[36mOutputGraph.compile_subgraph\u001b[39m\u001b[34m(self, tx, partial_convert, reason)\u001b[39m\n\u001b[32m   1098\u001b[39m append_prefix_insts()\n\u001b[32m   1099\u001b[39m \u001b[38;5;66;03m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[32m   1100\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m-> \u001b[39m\u001b[32m1101\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_replacements\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     + [create_instruction(\u001b[33m\"\u001b[39m\u001b[33mUNPACK_SEQUENCE\u001b[39m\u001b[33m\"\u001b[39m, arg=\u001b[38;5;28mlen\u001b[39m(stack_values))]\n\u001b[32m   1105\u001b[39m )\n\u001b[32m   1106\u001b[39m \u001b[38;5;66;03m# restore all the live local vars\u001b[39;00m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28mself\u001b[39m.add_output_instructions(\n\u001b[32m   1108\u001b[39m     [\n\u001b[32m   1109\u001b[39m         PyCodegen(tx, overridden_sources=overridden_sources).create_store(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1113\u001b[39m     ]\n\u001b[32m   1114\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1382\u001b[39m, in \u001b[36mOutputGraph.compile_and_call_fx_graph\u001b[39m\u001b[34m(self, tx, rv, root, replaced_outputs)\u001b[39m\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m.tracing_context.fake_mode = backend_fake_mode\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.restore_global_state():\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     compiled_fn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_lazy_graph_module\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[32m   1386\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1387\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[33m\"\u001b[39m\u001b[33m__self__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[32m   1388\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn.\u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m_lazy_forward\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1392\u001b[39m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[32m   1393\u001b[39m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1432\u001b[39m, in \u001b[36mOutputGraph.call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_user_compiler\u001b[39m(\u001b[38;5;28mself\u001b[39m, gm: fx.GraphModule) -> CompiledFn:\n\u001b[32m   1426\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   1427\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOutputGraph.call_user_compiler\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1428\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mbackend_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1429\u001b[39m         log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   1430\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33maot_autograd_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1431\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/output_graph.py:1462\u001b[39m, in \u001b[36mOutputGraph._call_user_compiler\u001b[39m\u001b[34m(self, gm)\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config.verify_correctness:\n\u001b[32m   1461\u001b[39m     compiler_fn = WrapperBackend(compiler_fn)\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1463\u001b[39m _step_logger()(logging.INFO, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1464\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[33m\"\u001b[39m\u001b[33mcompiler_fn did not return callable\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/repro/after_dynamo.py:130\u001b[39m, in \u001b[36mWrapBackendDebug.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     compiled_gm = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/__init__.py:2340\u001b[39m, in \u001b[36m_TorchCompileInductorWrapper.__call__\u001b[39m\u001b[34m(self, model_, inputs_)\u001b[39m\n\u001b[32m   2337\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[32m   2338\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompile_fx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[32m-> \u001b[39m\u001b[32m2340\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1863\u001b[39m, in \u001b[36mcompile_fx\u001b[39m\u001b[34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[39m\n\u001b[32m   1856\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m V.set_fake_mode(fake_mode), torch._guards.tracing(\n\u001b[32m   1859\u001b[39m     tracing_context\n\u001b[32m   1860\u001b[39m ), compiled_autograd._disable(), functorch_config.patch(\n\u001b[32m   1861\u001b[39m     unlift_effect_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1862\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1863\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1864\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1866\u001b[39m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m=\u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1870\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1871\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/backends/common.py:83\u001b[39m, in \u001b[36mAotAutograd.__call__\u001b[39m\u001b[34m(self, gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     81\u001b[39m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m         cg = \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m         counters[\u001b[33m\"\u001b[39m\u001b[33maot_autograd\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m] += \u001b[32m1\u001b[39m\n\u001b[32m     85\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1155\u001b[39m, in \u001b[36maot_module_simplified\u001b[39m\u001b[34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001b[39m\n\u001b[32m   1145\u001b[39m     compiled_fn = AOTAutogradCache.load(\n\u001b[32m   1146\u001b[39m         dispatch_and_compile,\n\u001b[32m   1147\u001b[39m         mod,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1152\u001b[39m         remote,\n\u001b[32m   1153\u001b[39m     )\n\u001b[32m   1154\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1155\u001b[39m     compiled_fn = \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch._dynamo.utils.GmWrapper):\n\u001b[32m   1158\u001b[39m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[32m   1159\u001b[39m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[32m   1160\u001b[39m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[32m   1161\u001b[39m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n\u001b[32m   1162\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mboxed_forward\u001b[39m(runtime_args: List[Any]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1131\u001b[39m, in \u001b[36maot_module_simplified.<locals>.dispatch_and_compile\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1129\u001b[39m functional_call = create_functional_call(mod, params_spec, params_len)\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd._disable():\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     compiled_fn, _ = \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:580\u001b[39m, in \u001b[36mcreate_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_aot_dispatcher_function\u001b[39m(\n\u001b[32m    573\u001b[39m     flat_fn,\n\u001b[32m    574\u001b[39m     fake_flat_args: FakifiedFlatArgs,\n\u001b[32m   (...)\u001b[39m\u001b[32m    577\u001b[39m     shape_env: Optional[ShapeEnv],\n\u001b[32m    578\u001b[39m ) -> Tuple[Callable, ViewAndMutationMeta]:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mcreate_aot_dispatcher_function\u001b[39m\u001b[33m\"\u001b[39m, log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m580\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:830\u001b[39m, in \u001b[36m_create_aot_dispatcher_function\u001b[39m\u001b[34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[39m\n\u001b[32m    826\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m aot_dispatch_base\n\u001b[32m    828\u001b[39m compiler_fn = choose_dispatcher(needs_autograd, aot_config)\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m compiled_fn, fw_metadata = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:678\u001b[39m, in \u001b[36maot_dispatch_autograd\u001b[39m\u001b[34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[39m\n\u001b[32m    675\u001b[39m     tracing_context.fw_metadata = inner_meta\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext.report_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     compiled_fw_func = \u001b[43maot_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjusted_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fw_func, \u001b[33m\"\u001b[39m\u001b[33m_boxed_call\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    681\u001b[39m     compiled_fw_func = make_boxed_func(compiled_fw_func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:489\u001b[39m, in \u001b[36mSerializableAOTDispatchCompiler.__call__\u001b[39m\u001b[34m(self, gm, example_inputs)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    485\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    486\u001b[39m     gm: torch.fx.GraphModule,\n\u001b[32m    487\u001b[39m     example_inputs: Sequence[InputType],\n\u001b[32m    488\u001b[39m ) -> OutputCode:\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1741\u001b[39m, in \u001b[36mcompile_fx.<locals>.fw_compiler_base\u001b[39m\u001b[34m(gm, example_inputs, is_inference)\u001b[39m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1739\u001b[39m     model_outputs_node.meta[\u001b[33m\"\u001b[39m\u001b[33muser_visible_output_idxs\u001b[39m\u001b[33m\"\u001b[39m] = []\n\u001b[32m-> \u001b[39m\u001b[32m1741\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1749\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:569\u001b[39m, in \u001b[36mcompile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m stack.enter_context(DebugContext())\n\u001b[32m    564\u001b[39m get_chromium_event_logger().add_event_data(\n\u001b[32m    565\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minductor_compile\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    566\u001b[39m     is_backward=kwargs[\u001b[33m\"\u001b[39m\u001b[33mis_backward\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    567\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minductor\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    571\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_dynamo/repro/after_aot.py:102\u001b[39m, in \u001b[36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[39m\u001b[34m(gm, example_inputs, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m config.repro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mdynamo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m102\u001b[39m     inner_compiled_fn = \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.repro_after == \u001b[33m\"\u001b[39m\u001b[33maot\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:685\u001b[39m, in \u001b[36m_compile_fx_inner\u001b[39m\u001b[34m(gm, example_inputs, **graph_kwargs)\u001b[39m\n\u001b[32m    683\u001b[39m TritonBundler.begin_compile()\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     mb_compiled_graph = \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    689\u001b[39m     mb_compiled_graph._time_taken_ns = time.time_ns() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1129\u001b[39m, in \u001b[36mfx_codegen_and_compile\u001b[39m\u001b[34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[39m\n\u001b[32m   1119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfx_codegen_and_compile\u001b[39m(\n\u001b[32m   1120\u001b[39m     gm: GraphModule,\n\u001b[32m   1121\u001b[39m     example_inputs: Sequence[InputType],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1125\u001b[39m     **graph_kwargs: Unpack[_CompileFxKwargs],\n\u001b[32m   1126\u001b[39m ) -> OutputCode:\n\u001b[32m   1127\u001b[39m     scheme: FxCompile = _InProcessFxCompile()\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:1044\u001b[39m, in \u001b[36m_InProcessFxCompile.codegen_and_compile\u001b[39m\u001b[34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[39m\n\u001b[32m   1036\u001b[39m             compiled_fn = AotCodeCompiler.compile(\n\u001b[32m   1037\u001b[39m                 graph,\n\u001b[32m   1038\u001b[39m                 code,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1041\u001b[39m                 additional_files=additional_files,\n\u001b[32m   1042\u001b[39m             )\n\u001b[32m   1043\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         compiled_fn = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.call\n\u001b[32m   1046\u001b[39m num_bytes, nodes_num_elem, node_runtimes = graph.count_bytes()\n\u001b[32m   1047\u001b[39m metrics.num_bytes_accessed += num_bytes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/graph.py:2027\u001b[39m, in \u001b[36mGraphLowering.compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2020\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ModuleType:\n\u001b[32m   2021\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[32m   2022\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraphLowering.compile_to_module\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2023\u001b[39m         phase_name=\u001b[33m\"\u001b[39m\u001b[33mcode_gen\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2024\u001b[39m         log_pt2_compile_event=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   2025\u001b[39m         dynamo_compile_column_us=\u001b[33m\"\u001b[39m\u001b[33minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2026\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m2027\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/graph.py:2033\u001b[39m, in \u001b[36mGraphLowering._compile_to_module\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2029\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_compile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ModuleType:\n\u001b[32m   2030\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcodecache\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyCodeCache\n\u001b[32m   2032\u001b[39m     code, linemap = (\n\u001b[32m-> \u001b[39m\u001b[32m2033\u001b[39m         \u001b[38;5;28mself\u001b[39m.codegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2034\u001b[39m     )\n\u001b[32m   2035\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.triton.autotune_at_compile_time:\n\u001b[32m   2036\u001b[39m         tuning_code = (\n\u001b[32m   2037\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   2038\u001b[39m             + \u001b[33m\"\u001b[39m\u001b[33mCompile-time auto-tuning block: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2041\u001b[39m             + \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   2042\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/graph.py:1968\u001b[39m, in \u001b[36mGraphLowering.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1965\u001b[39m V.debug.draw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m.orig_gm, \u001b[38;5;28mself\u001b[39m.scheduler.nodes)\n\u001b[32m   1967\u001b[39m \u001b[38;5;28mself\u001b[39m.wrapper_code.push_codegened_graph(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1968\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1970\u001b[39m log.debug(\n\u001b[32m   1971\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mFinished codegen for all nodes. The list of kernel names available: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m   1972\u001b[39m     V.graph.all_codegen_kernel_names,\n\u001b[32m   1973\u001b[39m )\n\u001b[32m   1975\u001b[39m result = \u001b[38;5;28mself\u001b[39m.wrapper_code.generate(\u001b[38;5;28mself\u001b[39m.is_inference)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/scheduler.py:3477\u001b[39m, in \u001b[36mScheduler.codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3475\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcodegen\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3476\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[33m\"\u001b[39m\u001b[33mScheduler.codegen\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3477\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_codegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/scheduler.py:3554\u001b[39m, in \u001b[36mScheduler._codegen\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3552\u001b[39m     backend.codegen_combo_kernel(node)\n\u001b[32m   3553\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (FusedSchedulerNode, SchedulerNode)):\n\u001b[32m-> \u001b[39m\u001b[32m3554\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3555\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3556\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, NopKernelSchedulerNode)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/codegen/cuda_combined_scheduling.py:80\u001b[39m, in \u001b[36mCUDACombinedScheduling.codegen_node\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcodegen_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, node: Union[FusedSchedulerNode, SchedulerNode]):\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_triton_scheduling\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/codegen/simd.py:1219\u001b[39m, in \u001b[36mSIMDScheduling.codegen_node\u001b[39m\u001b[34m(self, node)\u001b[39m\n\u001b[32m   1216\u001b[39m node_schedule = \u001b[38;5;28mself\u001b[39m.generate_node_schedule(nodes, numel, rnumel)\n\u001b[32m   1217\u001b[39m schedule_log.debug(\u001b[33m\"\u001b[39m\u001b[33mSchedule:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, node_schedule)\n\u001b[32m-> \u001b[39m\u001b[32m1219\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen_node_schedule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mSIMDKernelFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnumel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/codegen/simd.py:1259\u001b[39m, in \u001b[36mSIMDScheduling.codegen_node_schedule\u001b[39m\u001b[34m(self, kernel_features)\u001b[39m\n\u001b[32m   1255\u001b[39m kernels = \u001b[38;5;28mself\u001b[39m.create_kernel_choices(\n\u001b[32m   1256\u001b[39m     kernel_features, [tiling], {\u001b[33m\"\u001b[39m\u001b[33mfeatures\u001b[39m\u001b[33m\"\u001b[39m: kernel_features}\n\u001b[32m   1257\u001b[39m )\n\u001b[32m   1258\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kernel \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcodegen_node_schedule_with_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1260\u001b[39m MultiKernel.merge_workspaces_inplace(kernels)\n\u001b[32m   1261\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kernel \u001b[38;5;129;01min\u001b[39;00m kernels:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/codegen/simd.py:1354\u001b[39m, in \u001b[36mSIMDScheduling.codegen_node_schedule_with_kernel\u001b[39m\u001b[34m(self, node_schedule, kernel)\u001b[39m\n\u001b[32m   1352\u001b[39m indexing_dtype_strength_reduction(node._body)\n\u001b[32m   1353\u001b[39m index_vars = kernel.split_and_set_ranges(node.get_ranges())\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/scheduler.py:1057\u001b[39m, in \u001b[36mSchedulerNode.codegen\u001b[39m\u001b[34m(self, index_vars)\u001b[39m\n\u001b[32m   1053\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1054\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m V.set_ops_handler(\n\u001b[32m   1055\u001b[39m         SimplifyIndexing(V.get_ops_handler(), var_ranges)\n\u001b[32m   1056\u001b[39m     ), V.kernel.set_current_node(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mindex_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1059\u001b[39m     log.fatal(\u001b[33m\"\u001b[39m\u001b[33mError in codegen for \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.node)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/loop_body.py:404\u001b[39m, in \u001b[36mLoopBody.__call__\u001b[39m\u001b[34m(self, *indices)\u001b[39m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *indices):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28mself\u001b[39m.indexing = \u001b[38;5;28mself\u001b[39m.indexing_from_args(indices)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28mself\u001b[39m.indexing = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/loop_body.py:638\u001b[39m, in \u001b[36mLoopBodyBlock.__call__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    635\u001b[39m graph = \u001b[38;5;28mself\u001b[39m.graph\n\u001b[32m    636\u001b[39m submodules = \u001b[38;5;28mself\u001b[39m.body.submodules\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInterpreterShim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmodules\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_ops_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/loop_body.py:60\u001b[39m, in \u001b[36mInterpreterShim.run\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m V.set_interpreter_handler(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/fx/interpreter.py:167\u001b[39m, in \u001b[36mInterpreter.run\u001b[39m\u001b[34m(self, initial_env, enable_io_processing, *args)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28mself\u001b[39m.env[node] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.extra_traceback:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/loop_body.py:56\u001b[39m, in \u001b[36mInterpreterShim.run_node\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, n: torch.fx.Node) -> Any:\n\u001b[32m     55\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_node = n\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/fx/interpreter.py:230\u001b[39m, in \u001b[36mInterpreter.run_node\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/fx/interpreter.py:334\u001b[39m, in \u001b[36mInterpreter.call_method\u001b[39m\u001b[34m(self, target, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;66;03m# Execute the method and return the result\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mself_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_tail\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/codegen/common.py:1807\u001b[39m, in \u001b[36mKernel.__enter__.<locals>.CSEProxy.__getattr__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1804\u001b[39m bounds = CSEProxy._bound_variable(name, *args, **kwargs)\n\u001b[32m   1806\u001b[39m value = \u001b[38;5;28mgetattr\u001b[39m(parent_handler, name)(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1807\u001b[39m dtype_handler = \u001b[43mDtypePropagationOpsHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1809\u001b[39m output_idx = \u001b[32m0\u001b[39m\n\u001b[32m   1811\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_cse\u001b[39m(v):\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# cpp backend doesnt set current device - TODO: fix\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Kaggle-BirdCLEF-2025/.birdclef_env/lib/python3.11/site-packages/torch/_inductor/dtype_propagation.py:149\u001b[39m, in \u001b[36mDtypePropagationOpsHandler.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops_handler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpsHandler\n\u001b[32m    148\u001b[39m ops_set = {s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(OpsHandler) \u001b[38;5;28;01mif\u001b[39;00m s[\u001b[32m0\u001b[39m] != \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m unimplemented_ops = ops_set - \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28;43mdir\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    150\u001b[39m torch._check(\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mlen\u001b[39m(unimplemented_ops) == \u001b[32m0\u001b[39m,\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnimplemented dtype rule for ops: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munimplemented_ops\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    153\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    soundscape_df = pd.read_csv(cfg.unlabeled_sample_list)\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    print(f\"LOAD_DATA is set to {cfg.LOAD_DATA}\")\n",
    "    if cfg.LOAD_DATA:\n",
    "        print(\"Using pre-computed mel spectrograms from NPY file\")\n",
    "    else:\n",
    "        print(\"Will generate spectrograms on-the-fly during training\")\n",
    "\n",
    "    run_training(train_df, cfg, soundscape_df=soundscape_df)\n",
    "    print(\"\\nTraining complete!\")\n",
    "    cfg.save_config()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 6886569,
     "sourceId": 11053663,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".birdclef_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.861675,
   "end_time": "2025-03-17T14:02:15.686871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-17T14:00:29.825196",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fa836ee22b04b368008c3690b558e46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "114dd08c70bd4b1c9eca37e27bf08897": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1300468cac164026a61e5e60b05b005d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "158d32467f5247c983eb8907b6f5436f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad27b2a5cded4c23a3f72be3cee7c158",
        "IPY_MODEL_2d82fd9a33be40a19b68a6b37ee2375c",
        "IPY_MODEL_8720627fe38240cb88edd61a2fa45481"
       ],
       "layout": "IPY_MODEL_8eca206926bb44e9b42a5170bf4b1492",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1ad6a9d60ae24934ae355801b4992850": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1be8903e7c5d424abe30c82905dfa291",
        "IPY_MODEL_beceebaa8bef4939a3027e1756c820ca",
        "IPY_MODEL_65c613e48ff14d02b91adbeae536f703"
       ],
       "layout": "IPY_MODEL_7d38c7c32ff24563ae51248957aac76a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1be8903e7c5d424abe30c82905dfa291": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fbd77392c5e94748a19ab6adc204c0f0",
       "placeholder": "",
       "style": "IPY_MODEL_5c8f99997b3d447cb7664e6c8213d5af",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation:100%"
      }
     },
     "1e6784d317664982818c369ec64d4375": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b325002c114fb6801da1f6f7e2a2eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b951c7b2c847bbaf9c066b7f932c12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f808eb60489b4ef2bc76b055d5c477ff",
       "placeholder": "",
       "style": "IPY_MODEL_ed26d5cb2ff3426a9449e0166b68afbf",
       "tabbable": null,
       "tooltip": null,
       "value": "31/31[00:05&lt;00:00,5.70it/s,train_loss=0.0308,lr=0.000488]"
      }
     },
     "2b7b0d3f79504d87a8dbfb2f7893399a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_527982470da345c590c47f26ce1f9ccf",
       "max": 31,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ddf272308e664d24820c9ca6e917e456",
       "tabbable": null,
       "tooltip": null,
       "value": 31
      }
     },
     "2d82fd9a33be40a19b68a6b37ee2375c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4cc700caf0949c5bf39d8f7539ba2d2",
       "max": 21355344,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_925afd9abcc74142bd88971863bb345b",
       "tabbable": null,
       "tooltip": null,
       "value": 21355344
      }
     },
     "35b20f9b2e8746c68e234fcb6d29f047": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_23b325002c114fb6801da1f6f7e2a2eb",
       "max": 31,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_926aa065fa4f40b4b623fd079ba7cd0f",
       "tabbable": null,
       "tooltip": null,
       "value": 31
      }
     },
     "527982470da345c590c47f26ce1f9ccf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "546a352a5f6d48bd9769e2dff67a1419": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "577df72f0ce349d8988b16f4429c3116": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6314d51e57944ca399dd8819d2c5c214",
       "placeholder": "",
       "style": "IPY_MODEL_c4ccd0e9a85348d4a50bda1dc66d9658",
       "tabbable": null,
       "tooltip": null,
       "value": "Training:100%"
      }
     },
     "5c8f99997b3d447cb7664e6c8213d5af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "60623af9dc82439fbac9dce1bb4a9d90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6314d51e57944ca399dd8819d2c5c214": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65c613e48ff14d02b91adbeae536f703": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_114dd08c70bd4b1c9eca37e27bf08897",
       "placeholder": "",
       "style": "IPY_MODEL_f8e3ad286a374d558e61627ba3a67d26",
       "tabbable": null,
       "tooltip": null,
       "value": "32/32[00:02&lt;00:00,22.08it/s]"
      }
     },
     "66d95ea040244824b4f188b4985e8cb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "690250bf83464a7f91cd587a5f56d48e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7036c511c9b34e76837009a371c58be9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1300468cac164026a61e5e60b05b005d",
       "placeholder": "",
       "style": "IPY_MODEL_690250bf83464a7f91cd587a5f56d48e",
       "tabbable": null,
       "tooltip": null,
       "value": "32/32[00:01&lt;00:00,22.00it/s]"
      }
     },
     "74c1cd7782554123a2d89d46d13808b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d995347d83ec40e2b0c1db58a78e3dde",
        "IPY_MODEL_dcdaa701c23b4a1697b18ae319e036f6",
        "IPY_MODEL_7036c511c9b34e76837009a371c58be9"
       ],
       "layout": "IPY_MODEL_dc55c130999847b6a7460d8d68f31668",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7d38c7c32ff24563ae51248957aac76a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "871d479608024b77bb2db8278e3f659d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8720627fe38240cb88edd61a2fa45481": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_934ed224b7fd4de3ab54a89a789f0e3a",
       "placeholder": "",
       "style": "IPY_MODEL_a42ef4d205e74949b7fb2dee1039c2d8",
       "tabbable": null,
       "tooltip": null,
       "value": "21.4M/21.4M[00:00&lt;00:00,86.8MB/s]"
      }
     },
     "8e978a7645e7420fb2e452a3e2e7f69d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab2f0fc298124ff685860a158b2ec252",
       "placeholder": "",
       "style": "IPY_MODEL_9366d6929e0c44408fb54456fff6c241",
       "tabbable": null,
       "tooltip": null,
       "value": "31/31[00:06&lt;00:00,5.75it/s,train_loss=0.0344,lr=0.0005]"
      }
     },
     "8eca206926bb44e9b42a5170bf4b1492": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9193f88c4b9842c4a73d33b86e2a79b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "925afd9abcc74142bd88971863bb345b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "926aa065fa4f40b4b623fd079ba7cd0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "934ed224b7fd4de3ab54a89a789f0e3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9366d6929e0c44408fb54456fff6c241": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "93a38cd64b7e457082b679b1aace02df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a17d437eca184c35ae51d6ddf160ad00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b3d1cca7cebb47ee9a5fb1281ffa00bb",
       "placeholder": "",
       "style": "IPY_MODEL_546a352a5f6d48bd9769e2dff67a1419",
       "tabbable": null,
       "tooltip": null,
       "value": "Training:100%"
      }
     },
     "a337ff0d214a41d1a7314a4ca229bfd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a42ef4d205e74949b7fb2dee1039c2d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab2f0fc298124ff685860a158b2ec252": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac1a06c6ab024f11a1a52431788f6823": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad27b2a5cded4c23a3f72be3cee7c158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_93a38cd64b7e457082b679b1aace02df",
       "placeholder": "",
       "style": "IPY_MODEL_fb003526535b4cba8efa507d3f92a66b",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:100%"
      }
     },
     "b3d1cca7cebb47ee9a5fb1281ffa00bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beceebaa8bef4939a3027e1756c820ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac1a06c6ab024f11a1a52431788f6823",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0fa836ee22b04b368008c3690b558e46",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "c4ccd0e9a85348d4a50bda1dc66d9658": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cafb1e5ee8af47dc9a8813cdb7dad1b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_577df72f0ce349d8988b16f4429c3116",
        "IPY_MODEL_2b7b0d3f79504d87a8dbfb2f7893399a",
        "IPY_MODEL_23b951c7b2c847bbaf9c066b7f932c12"
       ],
       "layout": "IPY_MODEL_a337ff0d214a41d1a7314a4ca229bfd3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d995347d83ec40e2b0c1db58a78e3dde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e6784d317664982818c369ec64d4375",
       "placeholder": "",
       "style": "IPY_MODEL_66d95ea040244824b4f188b4985e8cb2",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation:100%"
      }
     },
     "dc55c130999847b6a7460d8d68f31668": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcdaa701c23b4a1697b18ae319e036f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_871d479608024b77bb2db8278e3f659d",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60623af9dc82439fbac9dce1bb4a9d90",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "ddf272308e664d24820c9ca6e917e456": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e80cbc93209642a8bbe28877b257eab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a17d437eca184c35ae51d6ddf160ad00",
        "IPY_MODEL_35b20f9b2e8746c68e234fcb6d29f047",
        "IPY_MODEL_8e978a7645e7420fb2e452a3e2e7f69d"
       ],
       "layout": "IPY_MODEL_9193f88c4b9842c4a73d33b86e2a79b8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ed26d5cb2ff3426a9449e0166b68afbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f4cc700caf0949c5bf39d8f7539ba2d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f808eb60489b4ef2bc76b055d5c477ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8e3ad286a374d558e61627ba3a67d26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fb003526535b4cba8efa507d3f92a66b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fbd77392c5e94748a19ab6adc204c0f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
