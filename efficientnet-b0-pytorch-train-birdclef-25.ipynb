{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd19261b",
   "metadata": {
    "papermill": {
     "duration": 0.00461,
     "end_time": "2025-03-17T14:00:32.494653",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.490043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **BirdCLEF 2025 Training Notebook**\n",
    "\n",
    "This is a baseline training pipeline for BirdCLEF 2025 using EfficientNetB0 with PyTorch and Timm(for pretrained EffNet). You can check inference and preprocessing notebooks in the following links: \n",
    "\n",
    "- [EfficientNet B0 Pytorch [Inference] | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/efficientnet-b0-pytorch-inference-birdclef-25)\n",
    "\n",
    "  \n",
    "- [Transforming Audio-to-Mel Spec. | BirdCLEF'25](https://www.kaggle.com/code/kadircandrisolu/transforming-audio-to-mel-spec-birdclef-25)  \n",
    "\n",
    "Note that by default this notebook is in Debug Mode, so it will only train the model with 2 epochs, but the [weight](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-effnetb0-starter-weight) I used in the inference notebook was obtained after 10 epochs of training.\n",
    "\n",
    "**Features**\n",
    "* Implement with Pytorch and Timm\n",
    "* Flexible audio processing with both pre-computed and on-the-fly mel spectrograms\n",
    "* Stratified 5-fold cross-validation with ensemble capability\n",
    "* Mixup training for improved generalization\n",
    "* Spectrogram augmentations (time/frequency masking, brightness adjustment)\n",
    "* AdamW optimizer with Cosine Annealing LR scheduling\n",
    "* Debug mode for quick experimentation with smaller datasets\n",
    "\n",
    "**Pre-computed Spectrograms**\n",
    "For faster training, you can use pre-computed mel spectrograms from [this dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) by setting `LOAD_DATA = True`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a699fa",
   "metadata": {
    "papermill": {
     "duration": 0.003494,
     "end_time": "2025-03-17T14:00:32.502085",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.498591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ca2ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:32.510711Z",
     "iopub.status.busy": "2025-03-17T14:00:32.510382Z",
     "iopub.status.idle": "2025-03-17T14:00:46.238785Z",
     "shell.execute_reply": "2025-03-17T14:00:46.238073Z"
    },
    "papermill": {
     "duration": 13.73451,
     "end_time": "2025-03-17T14:00:46.240399",
     "exception": false,
     "start_time": "2025-03-17T14:00:32.505889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np, pandas as pd, math, os, random, warnings, json, datetime\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Specific imports\n",
    "import logging, gc, cv2\n",
    "\n",
    "# Audio processing imports\n",
    "import librosa\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Other ML imports\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import timm\n",
    "\n",
    "# Custom imports\n",
    "from processing import audio2melspec, process_audio_file, generate_spectrograms\n",
    "from utilities import set_seed, collate_fn\n",
    "from training_utilities import get_optimizer, get_scheduler, get_criterion, clean_gpu_memory, calculate_auc, compile_model\n",
    "\n",
    "# Suppress warnings and set logging level\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f9c08",
   "metadata": {
    "papermill": {
     "duration": 0.003721,
     "end_time": "2025-03-17T14:00:46.248317",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.244596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06591264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.256618Z",
     "iopub.status.busy": "2025-03-17T14:00:46.256366Z",
     "iopub.status.idle": "2025-03-17T14:00:46.333416Z",
     "shell.execute_reply": "2025-03-17T14:00:46.332684Z"
    },
    "papermill": {
     "duration": 0.082704,
     "end_time": "2025-03-17T14:00:46.334712",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.252008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    \n",
    "    seed = 42\n",
    "    debug = False \n",
    "    LOAD_DATA = True\n",
    "    \n",
    "    # Paths and directories\n",
    "    OUTPUT_DIR = 'output/'\n",
    "    train_datadir = 'birdclef-2025/train_audio'\n",
    "    train_csv = 'birdclef-2025/train.csv'\n",
    "    train_soundscapes = 'birdclef-2025/train_soundscapes'\n",
    "    test_soundscapes = 'birdclef-2025/test_soundscapes'\n",
    "    submission_csv = 'birdclef-2025/sample_submission.csv'\n",
    "    taxonomy_csv = 'birdclef-2025/taxonomy.csv'\n",
    "    spectrogram_npy = 'archive/train_melspec_5_256_256.npy'\n",
    "    train_soundscapes_spectrograms = 'archive/train_soundscapes_melspec_12x5_256_256/'\n",
    "    \n",
    "    # External pseudolabels settings\n",
    "    use_external_pseudolabels = True\n",
    "    external_pseudolabels = 'pseudolabels_better.csv'\n",
    "    pseudolabel_confidence_threshold = 0.1  # Only use predictions above this threshold\n",
    "    max_pseudolabels = 10000  # Maximum number of pseudolabeled samples to use\n",
    "    stratified_pseudolabels = False  # Use stratified sampling for pseudolabels\n",
    " \n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Training settings\n",
    "    epochs = 15\n",
    "    n_fold = 5 \n",
    "\n",
    "    # Mel spectrogram parameters\n",
    "    FS = 32000\n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Loss parameters\n",
    "    criterion = 'CombinedLoss'  # Options: 'BCEWithLogitsLoss', 'FocalLoss', 'CombinedLoss'\n",
    "    focal_alpha = 1.0\n",
    "    focal_gamma = 3.0\n",
    "    bce_weight = 0.5\n",
    "    focal_weight = 0.5\n",
    "\n",
    "    # optimizer and scheduler parameters\n",
    "    optimizer = 'AdamW'\n",
    "    lr = 5e-4 \n",
    "    weight_decay = 1e-5\n",
    "    scheduler = 'CosineAnnealingLR'\n",
    "    min_lr = 1e-6\n",
    "    use_lr_warmup = True\n",
    "    warmup_epochs = 2\n",
    "\n",
    "    # augmentation options\n",
    "    aug_prob = 0.5  \n",
    "    spec_augment = True\n",
    "    spec_augment_params = {\n",
    "        'time_mask_param': 30,\n",
    "        'freq_mask_param': 20,\n",
    "        'num_masks': 2,\n",
    "    }\n",
    "    mixup_alpha = 0.5\n",
    "    cutmix_alpha = 1.0\n",
    "    use_cutmix = True\n",
    "    \n",
    "    # Model architecture options\n",
    "    model_name = 'efficientnet_b0'  # Options: 'efficientnetv2_s', 'convnext_tiny', 'efficientnet_b0' \n",
    "    pretrained = True\n",
    "    in_channels = 1\n",
    "    dropout_rate = 0.2\n",
    "    drop_path_rate = 0.2\n",
    "    \n",
    "    # Regularization techniques\n",
    "    label_smoothing = 0.01\n",
    "    use_stochastic_depth = True\n",
    "\n",
    "    # Memory and speed optimizations\n",
    "    gradient_accumulation_steps = 4  # Increase effective batch size without more memory\n",
    "    use_amp = True                   # Use automatic mixed precision\n",
    "    pin_memory = True                # Faster data transfer to GPU\n",
    "    persistent_workers = True        # Keep workers alive between epochs\n",
    "    num_workers = 0                  # Match to number of CPU cores\n",
    "    prefetch_factor = 4              # Number of batches to prefetch (default is 2)\n",
    "    batch_size = 32                  # Effective batch size will be batch_size * gradient_accumulation_steps\n",
    "    \n",
    "    # Compiler settings\n",
    "    compile_backend = \"eager\"        # Options: \"eager\", \"torchscript\", \"onnx\", \"inductor\"\n",
    "    compile_mode = \"default\"         # Options: \"default\", \"reduce-overhead\", \"max-autotune\"\n",
    "    \n",
    "    # Memory usage management\n",
    "    gc_after_epoch = True            # Force garbage collection after each epoch\n",
    "    cache_dataset = False            # Cache dataset in memory if possible\n",
    "\n",
    "    def update_debug_settings(self):\n",
    "        if self.debug:\n",
    "            self.n_fold = 1\n",
    "            self.epochs = 2\n",
    "\n",
    "    def save_config(self):\n",
    "        config_dict = {attr: getattr(self, attr) for attr in dir(self) if not attr.startswith('__') and not callable(getattr(self, attr))}\n",
    "        if self.debug:\n",
    "            filename = f\"config_{self.timestamp}_{self.model_name}_DEBUG.json\"\n",
    "        else:\n",
    "            filename = f\"config_{self.timestamp}_{self.model_name}.json\"\n",
    "        with open(os.path.join(self.OUTPUT_DIR, filename), 'w') as f:\n",
    "            json.dump(config_dict, f, indent=4, default=str)\n",
    "        print(f\"Config saved to {os.path.join(self.OUTPUT_DIR, filename)}\")\n",
    "\n",
    "cfg = CFG()\n",
    "set_seed(cfg.seed)\n",
    "cfg.update_debug_settings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c4bc37",
   "metadata": {
    "papermill": {
     "duration": 0.003588,
     "end_time": "2025-03-17T14:00:46.367790",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.364202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-processing\n",
    "These functions handle the transformation of audio files to mel spectrograms for model input, with flexibility controlled by the `LOAD_DATA` parameter. The process involves either loading pre-computed spectrograms from this [dataset](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms) (when `LOAD_DATA=True`) or dynamically generating them (when `LOAD_DATA=False`), transforming audio data into spectrogram representations, and preparing it for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939033bf",
   "metadata": {
    "papermill": {
     "duration": 0.003549,
     "end_time": "2025-03-17T14:00:46.393394",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.389845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Preparation and Data Augmentations\n",
    "We'll convert audio to mel spectrograms and apply random augmentations with 50% probability each - including time stretching, pitch shifting, and volume adjustments. This randomized approach creates diverse training samples from the same audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6b2ea48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.401415Z",
     "iopub.status.busy": "2025-03-17T14:00:46.401216Z",
     "iopub.status.idle": "2025-03-17T14:00:46.413659Z",
     "shell.execute_reply": "2025-03-17T14:00:46.412877Z"
    },
    "papermill": {
     "duration": 0.017836,
     "end_time": "2025-03-17T14:00:46.414835",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.396999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFDatasetFromNPY(Dataset):\n",
    "    _cache = {}  # Class-level cache\n",
    "    \n",
    "    def __init__(self, df, cfg, spectrograms=None, mode=\"train\", label_dict=None, soundscape_loading=False):\n",
    "        self.df = df\n",
    "        self.cfg = cfg\n",
    "        self.mode = mode\n",
    "        self.spectrograms = spectrograms\n",
    "        self.label_dict = label_dict\n",
    "        self.soundscape_loading = soundscape_loading\n",
    "        \n",
    "        taxonomy_df = pd.read_csv(self.cfg.taxonomy_csv)\n",
    "        self.species_ids = taxonomy_df['primary_label'].tolist()\n",
    "        self.num_classes = len(self.species_ids)\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(self.species_ids)}\n",
    "        self.data_dir = cfg.train_datadir if not soundscape_loading else cfg.train_soundscapes\n",
    "\n",
    "        if self.soundscape_loading:\n",
    "            self.df.rename(columns={\"row_id\": \"samplename\"}, inplace=True)\n",
    "            self.df['filename'] = self.df['samplename'].apply(lambda x: \"_\".join(x.split('_')[:3])+\".ogg\")\n",
    "            self.df['timestamp'] = self.df['samplename'].apply(lambda x: int(x.split('_')[3]))\n",
    "            self.df['filepath'] = self.df['filename'].apply(lambda x: os.path.join(self.data_dir, x))\n",
    "            self.df['primary_label'] = self.df['samplename'].apply(lambda x: self.label_dict.get(x, [])[0])\n",
    "            self.df['secondary_labels'] = self.df['samplename'].apply(lambda x: self.label_dict.get(x, [])[1:])\n",
    "        else:\n",
    "            self.df['filepath'] = self.data_dir + '/' + self.df.filename\n",
    "            self.df['samplename'] = self.df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "        \n",
    "        if cfg.debug:\n",
    "            self.df = self.df.sample(min(1000, len(self.df)), random_state=cfg.seed).reset_index(drop=True)\n",
    "        \n",
    "        self.use_cache = cfg.cache_dataset if hasattr(cfg, 'cache_dataset') else False\n",
    "        self.cache_hits = 0\n",
    "        self.cache_misses = 0\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Check if we should use the cache and if the item is in cache\n",
    "        cache_key = f\"{self.mode}_{idx}\"\n",
    "        if self.use_cache and cache_key in self.__class__._cache:\n",
    "            self.cache_hits += 1\n",
    "            return self.__class__._cache[cache_key]\n",
    "        \n",
    "        row = self.df.iloc[idx]  # Fixed: Using square brackets instead of parentheses\n",
    "        samplename = row['samplename']\n",
    "\n",
    "        if self.spectrograms and samplename in self.spectrograms:\n",
    "            spec = self.spectrograms[samplename]\n",
    "        elif not self.cfg.LOAD_DATA:\n",
    "            spec = process_audio_file(row['filepath'], self.cfg)\n",
    "        else: \n",
    "            spec = np.zeros(self.cfg.TARGET_SHAPE, dtype=np.float32)\n",
    "            print(f\"Warning: Spectrogram for {samplename} not found and could not be generated\")    \n",
    "\n",
    "        spec = torch.from_numpy(spec).float().unsqueeze(0)  # Add channel dimension\n",
    "\n",
    "        if self.mode == \"train\" and random.random() < self.cfg.aug_prob:\n",
    "            spec = self.apply_spec_augmentations(spec)\n",
    "        \n",
    "        target = self.encode_label(row['primary_label'])\n",
    "        \n",
    "        if 'secondary_labels' in row and row['secondary_labels'] not in [[''], None, np.nan, []]:\n",
    "            if isinstance(row['secondary_labels'], str):\n",
    "                secondary_labels = eval(row['secondary_labels'])\n",
    "            else:\n",
    "                secondary_labels = row['secondary_labels']\n",
    "            \n",
    "            for label in secondary_labels:\n",
    "                idx = self.label_to_idx.get(label)\n",
    "                if idx is not None:\n",
    "                    target[idx] = 1.0\n",
    "        \n",
    "        item = {\n",
    "            'melspec': spec, \n",
    "            'target': torch.from_numpy(target).float(),\n",
    "        }\n",
    "        \n",
    "        # Cache the item if caching is enabled\n",
    "        if self.use_cache:\n",
    "            self.cache_misses += 1\n",
    "            self.__class__._cache[cache_key] = item\n",
    "            \n",
    "            # Print cache stats occasionally \n",
    "            if (self.cache_hits + self.cache_misses) % 1000 == 0:\n",
    "                hit_rate = self.cache_hits / (self.cache_hits + self.cache_misses)\n",
    "                print(f\"Cache hit rate: {hit_rate:.2%}, hits: {self.cache_hits}, misses: {self.cache_misses}\")\n",
    "                \n",
    "        return item\n",
    "    \n",
    "    def apply_spec_augmentations(self, spec):\n",
    "        \"\"\"Apply augmentations to spectrogram\"\"\"\n",
    "        \n",
    "        # Time/frequency masking\n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                width = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[2] - width)\n",
    "                spec[0, :, start:start+width] = 0\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            for _ in range(random.randint(1, 3)):\n",
    "                height = random.randint(5, 20)\n",
    "                start = random.randint(0, spec.shape[1] - height)\n",
    "                spec[0, start:start+height, :] = 0\n",
    "        \n",
    "        # Random brightness/contrast adjustment\n",
    "        if random.random() < 0.5:\n",
    "            gain = random.uniform(0.8, 1.2)\n",
    "            bias = random.uniform(-0.1, 0.1)\n",
    "            spec = spec * gain + bias\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "        \n",
    "        # Gaussian noise for robustness\n",
    "        if random.random() < 0.3:\n",
    "            noise = torch.randn_like(spec) * random.uniform(0.001, 0.005)\n",
    "            spec = spec + noise\n",
    "            spec = torch.clamp(spec, 0, 1)\n",
    "            \n",
    "        # Random time/frequency shifts\n",
    "        if random.random() < 0.3:\n",
    "            shift_x = random.randint(-4, 4)\n",
    "            shift_y = random.randint(-4, 4)\n",
    "            spec = torch.roll(spec, shifts=(shift_y, shift_x), dims=(1, 2))\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "    def encode_label(self, label):\n",
    "        \"\"\"Encode label to one-hot vector\"\"\"\n",
    "        target = np.zeros(self.num_classes)\n",
    "        idx = self.label_to_idx.get(label)\n",
    "        if idx is not None:\n",
    "            target[idx] = 1.0\n",
    "        return target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbb84a1",
   "metadata": {
    "papermill": {
     "duration": 0.003491,
     "end_time": "2025-03-17T14:00:46.436543",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.433052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741451ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.444643Z",
     "iopub.status.busy": "2025-03-17T14:00:46.444412Z",
     "iopub.status.idle": "2025-03-17T14:00:46.452684Z",
     "shell.execute_reply": "2025-03-17T14:00:46.452070Z"
    },
    "papermill": {
     "duration": 0.013532,
     "end_time": "2025-03-17T14:00:46.453738",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.440206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BirdCLEFModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "        cfg.num_classes = len(taxonomy_df)\n",
    "        \n",
    "        # Support for different model architectures\n",
    "        self.backbone = timm.create_model(\n",
    "            cfg.model_name,\n",
    "            pretrained=cfg.pretrained,\n",
    "            in_chans=cfg.in_channels,\n",
    "            drop_rate=cfg.dropout_rate,\n",
    "            drop_path_rate=cfg.drop_path_rate if hasattr(cfg, 'drop_path_rate') else 0.2\n",
    "        )\n",
    "        \n",
    "        # Extract feature dimension based on model type\n",
    "        if 'efficientnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "        elif 'convnext' in cfg.model_name:\n",
    "            backbone_out = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "        elif 'resnet' in cfg.model_name:\n",
    "            backbone_out = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "        else:\n",
    "            backbone_out = self.backbone.get_classifier().in_features\n",
    "            self.backbone.reset_classifier(0, '')\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.feat_dim = backbone_out\n",
    "        \n",
    "        # Add an additional projection layer for better feature representation\n",
    "        if hasattr(cfg, 'projection_dim') and cfg.projection_dim > 0:\n",
    "            self.projection = nn.Sequential(\n",
    "                nn.Linear(backbone_out, cfg.projection_dim),\n",
    "                nn.BatchNorm1d(cfg.projection_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(cfg.projection_dim, cfg.num_classes)\n",
    "            )\n",
    "            self.classifier = self.projection\n",
    "        else:\n",
    "            self.classifier = nn.Linear(backbone_out, cfg.num_classes)\n",
    "        \n",
    "        # Mixup and CutMix support\n",
    "        self.mixup_enabled = hasattr(cfg, 'mixup_alpha') and cfg.mixup_alpha > 0\n",
    "        self.cutmix_enabled = hasattr(cfg, 'use_cutmix') and cfg.use_cutmix and hasattr(cfg, 'cutmix_alpha') and cfg.cutmix_alpha > 0\n",
    "        \n",
    "        if self.mixup_enabled:\n",
    "            self.mixup_alpha = cfg.mixup_alpha\n",
    "        if self.cutmix_enabled:\n",
    "            self.cutmix_alpha = cfg.cutmix_alpha\n",
    "    \n",
    "    def forward(self, x, targets=None):\n",
    "    \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            mixed_x, targets_a, targets_b, lam = self.mixup_data(x, targets)\n",
    "            x = mixed_x\n",
    "        else:\n",
    "            targets_a, targets_b, lam = None, None, None\n",
    "        \n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        if isinstance(features, dict):\n",
    "            features = features['features']\n",
    "            \n",
    "        if len(features.shape) == 4:\n",
    "            features = self.pooling(features)\n",
    "            features = features.view(features.size(0), -1)\n",
    "        \n",
    "        logits = self.classifier(features)\n",
    "        \n",
    "        if self.training and self.mixup_enabled and targets is not None:\n",
    "            loss = self.mixup_criterion(F.binary_cross_entropy_with_logits, logits, targets_a, targets_b, lam)\n",
    "            return logits, loss\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def mixup_data(self, x, targets):\n",
    "        \"\"\"Applies mixup to the data batch\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        lam = np.random.beta(self.mixup_alpha, self.mixup_alpha)\n",
    "        indices = torch.randperm(batch_size).to(x.device, non_blocking=True)\n",
    "        mixed_x = lam * x + (1 - lam) * x[indices]\n",
    "        \n",
    "        return mixed_x, targets, targets[indices], lam\n",
    "    \n",
    "    def mixup_criterion(self, criterion, pred, y_a, y_b, lam):\n",
    "        \"\"\"Applies mixup to the loss function\"\"\"\n",
    "        return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "    \n",
    "    def cutmix_data(self, x, targets):\n",
    "        batch_size = x.size(0)\n",
    "        lam = np.random.beta(self.cutmix_alpha, self.cutmix_alpha)\n",
    "        \n",
    "        # Get random indices for mixing\n",
    "        indices = torch.randperm(batch_size).to(x.device)\n",
    "        \n",
    "        # Get random box coordinates\n",
    "        W, H = x.size(2), x.size(3)\n",
    "        cut_ratio = np.sqrt(1. - lam)\n",
    "        cut_w = np.int_(W * cut_ratio)\n",
    "        cut_h = np.int_(H * cut_ratio)\n",
    "        \n",
    "        cx = np.random.randint(W)\n",
    "        cy = np.random.randint(H)\n",
    "        \n",
    "        bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "        bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "        bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "        bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "        \n",
    "        # Apply cutmix\n",
    "        x_mixed = x.clone()\n",
    "        x_mixed[:, :, bbx1:bbx2, bby1:bby2] = x[indices, :, bbx1:bbx2, bby1:bby2]\n",
    "        \n",
    "        # Adjust lambda to actual area ratio\n",
    "        lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (W * H))\n",
    "        \n",
    "        return x_mixed, targets, targets[indices], lam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa08772",
   "metadata": {
    "papermill": {
     "duration": 0.003637,
     "end_time": "2025-03-17T14:00:46.461097",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.457460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Utilities\n",
    "We are configuring our optimization strategy with the AdamW optimizer, cosine scheduling, and the BCEWithLogitsLoss criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fd70fd",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2025-03-17T14:00:46.483348",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.479834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d944f8ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.491507Z",
     "iopub.status.busy": "2025-03-17T14:00:46.491314Z",
     "iopub.status.idle": "2025-03-17T14:00:46.504038Z",
     "shell.execute_reply": "2025-03-17T14:00:46.503466Z"
    },
    "papermill": {
     "duration": 0.018173,
     "end_time": "2025-03-17T14:00:46.505200",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.487027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion, device, scheduler=None, use_amp=True, grad_accum_steps=1):\n",
    "    model.train()\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "    \n",
    "    # Use lists to accumulate batches, but don't keep all outputs in memory\n",
    "    batch_count = 0\n",
    "    num_batches = len(loader)\n",
    "    running_loss = 0\n",
    "    outputs_for_metrics = []\n",
    "    targets_for_metrics = []  # Fixed missing equal sign\n",
    "    metric_collection_interval = min(100, len(loader) // 10 or 1)  # Collect metrics every N batches\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)  # More efficient than zero_grad()\n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\")\n",
    "    \n",
    "    for step, batch in pbar:\n",
    "        # Move to device with non_blocking for potential speedup\n",
    "        inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "        targets = batch['target'].to(device, non_blocking=True)\n",
    "        \n",
    "        with autocast(enabled=use_amp, device_type=device):\n",
    "            # Handle model outputs with mixup/cutmix\n",
    "            if (model.mixup_enabled or model.cutmix_enabled) and model.training:\n",
    "                if model.mixup_enabled and model.cutmix_enabled:\n",
    "                    # Randomly choose between mixup and cutmix\n",
    "                    if random.random() < 0.5:\n",
    "                        mixed_x, targets_a, targets_b, lam = model.mixup_data(inputs, targets)\n",
    "                    else:\n",
    "                        mixed_x, targets_a, targets_b, lam = model.cutmix_data(inputs, targets)\n",
    "                elif model.mixup_enabled:\n",
    "                    mixed_x, targets_a, targets_b, lam = model.mixup_data(inputs, targets)\n",
    "                else:\n",
    "                    mixed_x, targets_a, targets_b, lam = model.cutmix_data(inputs, targets)\n",
    "                    \n",
    "                outputs = model(mixed_x)\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Normalize loss for gradient accumulation\n",
    "        loss = loss / grad_accum_steps\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        batch_count += 1\n",
    "        running_loss += loss.item() * grad_accum_steps\n",
    "        \n",
    "        # Only collect some batches for metrics to save memory\n",
    "        if step % metric_collection_interval == 0:\n",
    "            outputs_for_metrics.append(outputs.detach().cpu())\n",
    "            targets_for_metrics.append(targets.detach().cpu())\n",
    "        \n",
    "        # Step optimizer after accumulating gradients\n",
    "        if batch_count % grad_accum_steps == 0 or step == len(loader) - 1:\n",
    "            # Unscale before possible gradient clipping\n",
    "            scaler.unscale_(optimizer)\n",
    "            \n",
    "            # Optional gradient clipping\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            if scheduler and isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                scheduler.step()\n",
    "\n",
    "        # Update progress bar with running loss\n",
    "        pbar.set_postfix({\n",
    "            'it/s/bs' : pbar.n / pbar.format_dict['elapsed'] / cfg.batch_size,\n",
    "            'train_loss': running_loss / (step + 1),\n",
    "            'lr': optimizer.param_groups[0]['lr'],\n",
    "        })\n",
    "        \n",
    "        # Free memory explicitly\n",
    "        del inputs, outputs\n",
    "        if step % 10 == 0:  # Periodically clear CUDA cache\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Calculate metrics on the subset of data we collected\n",
    "    if outputs_for_metrics:\n",
    "        all_outputs = torch.cat(outputs_for_metrics)\n",
    "        all_targets = torch.cat(targets_for_metrics)\n",
    "        auc = calculate_auc(all_targets.numpy(), all_outputs)\n",
    "    else:\n",
    "        auc = 0.0\n",
    "        \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    \n",
    "    # Clean up\n",
    "    del outputs_for_metrics, targets_for_metrics\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, auc\n",
    "\n",
    "# Update the validation function with batch processing for large validation sets\n",
    "def validate(model, loader, criterion, device, use_amp=True):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Process predictions in chunks to save memory\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    max_batches_in_memory = 50  # Adjust based on your memory constraints\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(loader, desc=\"Validation\")):\n",
    "            inputs = batch['melspec'].to(device, non_blocking=True)\n",
    "            targets = batch['target'].to(device, non_blocking=True)\n",
    "\n",
    "            with autocast(enabled=use_amp, device_type=device):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Convert to probabilities and store\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
    "            targets_np = targets.cpu().numpy()\n",
    "            \n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(targets_np)\n",
    "            \n",
    "            # Clear memory periodically\n",
    "            del inputs, outputs, targets\n",
    "            if batch_idx % 10 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Process predictions in chunks to avoid memory issues\n",
    "            if len(all_probs) >= max_batches_in_memory:\n",
    "                # Calculate partial metrics\n",
    "                probs_array = np.vstack(all_probs)\n",
    "                targets_array = np.vstack(all_targets)\n",
    "                \n",
    "                # Clear the lists to free memory\n",
    "                all_probs = []\n",
    "                all_targets = []\n",
    "                torch.cuda.empty_cache()\n",
    "    \n",
    "    # Process any remaining predictions\n",
    "    if all_probs:\n",
    "        probs_array = np.vstack(all_probs) if len(all_probs) > 1 else all_probs[0]\n",
    "        targets_array = np.vstack(all_targets) if len(all_targets) > 1 else all_targets[0]\n",
    "    \n",
    "    # Calculate AUC\n",
    "    auc = calculate_auc(targets_array, probs_array)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    \n",
    "    # Final cleanup\n",
    "    del all_probs, all_targets, probs_array, targets_array\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return avg_loss, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a41dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pseudolabels(soundscape_df, cfg, fold_seed=None):\n",
    "    \"\"\"\n",
    "    Load pseudolabels and sample to ensure balanced class representation.\n",
    "    Returns a maximum of cfg.max_pseudolabels samples with balanced label distribution.\n",
    "    \"\"\"\n",
    "    random_seed = fold_seed if fold_seed is not None else cfg.seed\n",
    "    \n",
    "    # Step 1: Filter to high-confidence samples first\n",
    "    high_confidence_dict = {}  # {sample_id: [labels]}\n",
    "    label_cols = soundscape_df.columns[1:]  # Skip row_id column\n",
    "    for _, row in soundscape_df.iterrows():\n",
    "        samplename = row['row_id']\n",
    "        row_sum = row[label_cols].sum()\n",
    "        if row_sum>0:\n",
    "            # normalize probabilities to [0, 1]\n",
    "            row[label_cols] = row[label_cols] / row[label_cols].sum()\n",
    "            label_values = {col: row[col] for col in label_cols}\n",
    "            high_conf_labels = [col for col, prob in label_values.items() if prob >= cfg.pseudolabel_confidence_threshold]\n",
    "            if high_conf_labels:\n",
    "                high_confidence_dict[samplename] = sorted(high_conf_labels, key=lambda x: label_values[x], reverse=True)\n",
    "    print(f\"Found {len(high_confidence_dict)} samples with confidence > {cfg.pseudolabel_confidence_threshold}\")\n",
    "\n",
    "    if cfg.stratified_pseudolabels:    \n",
    "        print(\"Stratified sampling of pseudolabels\")\n",
    "        # Step 2: Create a label-to-samples mapping to track which samples have each label\n",
    "        label_to_samples = {}\n",
    "        for samplename, labels in high_confidence_dict.items():\n",
    "            for label in labels:\n",
    "                if label not in label_to_samples:\n",
    "                    label_to_samples[label] = []\n",
    "                label_to_samples[label].append(samplename)\n",
    "        \n",
    "        # Step 3: Determine target count per label for balanced sampling\n",
    "        num_unique_labels = len(label_to_samples)\n",
    "        target_per_label = max(1, int(cfg.max_pseudolabels / num_unique_labels))\n",
    "        print(f\"Found {num_unique_labels} unique bird species in pseudolabels\")\n",
    "        print(f\"Target ~{target_per_label} samples per species to stay under {cfg.max_pseudolabels} total\")\n",
    "        \n",
    "        # Shuffle labels to ensure different folds get different priority\n",
    "        shuffled_labels = list(label_to_samples.keys())\n",
    "        random.seed(random_seed)\n",
    "        random.shuffle(shuffled_labels)\n",
    "\n",
    "        # Step 4: Sample entries for each label\n",
    "        selected_samples = set()\n",
    "        label_counts = {}\n",
    "        \n",
    "        for label in shuffled_labels:\n",
    "            samples = label_to_samples[label]\n",
    "            # Shuffle samples for this label\n",
    "            random.seed(random_seed + hash(label) % 10000)  # Different seed for each label\n",
    "            random.shuffle(samples)\n",
    "            \n",
    "            samples_needed = min(target_per_label, len(samples))\n",
    "            samples_added = 0\n",
    "            \n",
    "            for sample in samples:\n",
    "                if samples_added >= samples_needed:\n",
    "                    break\n",
    "                    \n",
    "                selected_samples.add(sample)\n",
    "                samples_added += 1\n",
    "                \n",
    "                # Keep track of how many times we've sampled each label\n",
    "                for label_in_sample in high_confidence_dict[sample]:\n",
    "                    label_counts[label_in_sample] = label_counts.get(label_in_sample, 0) + 1\n",
    "    \n",
    "        # Step 5: Create final filtered dict and dataframe with only selected samples\n",
    "        filtered_dict = {k: v for k, v in high_confidence_dict.items() if k in selected_samples}\n",
    "        filtered_df = soundscape_df[soundscape_df['row_id'].isin(selected_samples)].reset_index(drop=True)\n",
    "    \n",
    "         # Report statistics\n",
    "        print(f\"Sampled {len(filtered_dict)} pseudolabeled samples\")\n",
    "    \n",
    "        return filtered_df, filtered_dict\n",
    "    \n",
    "    else:\n",
    "        filtered_df = soundscape_df[soundscape_df['row_id'].isin(high_confidence_dict.keys())].reset_index(drop=True)\n",
    "        filtered_df = filtered_df.sample(frac=1, random_state=fold_seed).reset_index(drop=True)\n",
    "        print(f\"Loaded all pseudolabels that pass confidence threshold\")\n",
    "        return filtered_df, high_confidence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de76a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.520217Z",
     "iopub.status.busy": "2025-03-17T14:00:46.520008Z",
     "iopub.status.idle": "2025-03-17T14:00:46.531337Z",
     "shell.execute_reply": "2025-03-17T14:00:46.530758Z"
    },
    "papermill": {
     "duration": 0.016548,
     "end_time": "2025-03-17T14:00:46.532461",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.515913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(df, cfg, soundscape_df=None):\n",
    "\n",
    "    taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "    species_ids = taxonomy_df['primary_label'].tolist()\n",
    "    cfg.num_classes = len(species_ids)\n",
    "\n",
    "    if cfg.LOAD_DATA:\n",
    "        spectrograms = np.load(cfg.spectrogram_npy, allow_pickle=True).item()\n",
    "        print(f\"Loaded {len(spectrograms)} pre-computed mel spectrograms for labeled data\")\n",
    "    else:   \n",
    "        spectrograms = None\n",
    "        print(\"Will generate spectrograms on-the-fly during training.\")\n",
    "\n",
    "    # Create cross-validation folds\n",
    "    if cfg.n_fold > 1:\n",
    "        skf = StratifiedKFold(n_splits=cfg.n_fold, shuffle=True, random_state=cfg.seed)\n",
    "        folds = skf.split(df, df['primary_label'])\n",
    "    else:\n",
    "        folds = [(np.arange(len(df)), np.arange(len(df)))]\n",
    "\n",
    "    best_scores = []\n",
    "            \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds):\n",
    "        print(f'\\n{\"=\"*30} Fold {fold} {\"=\"*30}')\n",
    "        \n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        print(f'Training set: {len(train_df)} samples')\n",
    "        print(f'Validation set: {len(val_df)} samples')\n",
    "\n",
    "        # Prepare datasets\n",
    "        train_dataset = BirdCLEFDatasetFromNPY(train_df, cfg, spectrograms=spectrograms, mode='train')\n",
    "        val_dataset = BirdCLEFDatasetFromNPY(val_df, cfg, spectrograms=spectrograms, mode='valid')\n",
    "        pseudolabeled_dataset = None\n",
    "\n",
    "        if cfg.use_external_pseudolabels and soundscape_df is not None:\n",
    "            print(\"\\nInitializing soundscape dataset with external pseudolabels...\")\n",
    "            # Get stratified samples from soundscape_df\n",
    "            filtered_soundscape_df, high_confidence_dict = load_pseudolabels(soundscape_df, cfg, fold_seed=cfg.seed+fold*1337)\n",
    "            soundscape_spectrograms = None\n",
    "            if cfg.LOAD_DATA:\n",
    "                soundscape_spectrograms = {}\n",
    "                for samplename in high_confidence_dict.keys():\n",
    "                    samplepath = os.path.join(cfg.train_soundscapes_spectrograms, samplename + \".npy\")\n",
    "                    if os.path.exists(samplepath):\n",
    "                        soundscape_spectrograms[samplename] = np.load(samplepath, allow_pickle=True)\n",
    "                    else:\n",
    "                        print(f\"Warning: Spectrogram for {samplename} not found in soundscapes directory\")\n",
    "\n",
    "            pseudolabeled_dataset = BirdCLEFDatasetFromNPY(\n",
    "                filtered_soundscape_df, \n",
    "                cfg, \n",
    "                spectrograms=soundscape_spectrograms,\n",
    "                mode='train',\n",
    "                label_dict=high_confidence_dict,\n",
    "                soundscape_loading=True\n",
    "            )\n",
    "        \n",
    "        # Use original training set by default\n",
    "        final_train_dataset = train_dataset\n",
    "        \n",
    "        # Combine with pseudolabels if available\n",
    "        if pseudolabeled_dataset is not None and len(pseudolabeled_dataset) > 0:\n",
    "            final_train_dataset = ConcatDataset([train_dataset, pseudolabeled_dataset])\n",
    "            print(f\"Training with combined dataset: {len(train_dataset)} original + {len(pseudolabeled_dataset)} pseudolabeled = {len(final_train_dataset)} total samples\")\n",
    "        \n",
    "        # Prepare data loaders\n",
    "        train_loader = DataLoader(\n",
    "            final_train_dataset, \n",
    "            batch_size=cfg.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=cfg.num_workers,\n",
    "            pin_memory=cfg.pin_memory,\n",
    "            persistent_workers=cfg.persistent_workers if cfg.num_workers > 0 else False,\n",
    "            prefetch_factor=cfg.prefetch_factor if cfg.num_workers > 0 else None,\n",
    "            collate_fn=collate_fn,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=cfg.batch_size * 2,  # Can use larger batch size for validation\n",
    "            shuffle=False, \n",
    "            num_workers=cfg.num_workers,\n",
    "            pin_memory=cfg.pin_memory,\n",
    "            persistent_workers=cfg.persistent_workers if cfg.num_workers > 0 else False,\n",
    "            prefetch_factor=cfg.prefetch_factor if cfg.num_workers > 0 else None,\n",
    "            collate_fn=collate_fn\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        print(f\"\\n{'-'*20} Training Model {'-'*20}\")\n",
    "        model = BirdCLEFModel(cfg).to(cfg.device, non_blocking=True)\n",
    "        model = compile_model(model, cfg)\n",
    "        optimizer = get_optimizer(model, cfg)\n",
    "        criterion = get_criterion(cfg)\n",
    "\n",
    "        # Configure scheduler\n",
    "        if cfg.scheduler == 'CosineAnnealingLR':\n",
    "            cfg.T_max = cfg.epochs\n",
    "        scheduler = get_scheduler(optimizer, cfg, len(train_loader))\n",
    "        \n",
    "        best_auc, best_epoch = 0, 0\n",
    "        \n",
    "        for epoch in range(cfg.epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "            \n",
    "            train_loss, train_auc = train_one_epoch(\n",
    "                model, train_loader, optimizer, criterion, cfg.device,\n",
    "                scheduler if isinstance(scheduler, lr_scheduler.OneCycleLR) else None,\n",
    "                use_amp=cfg.use_amp,\n",
    "                grad_accum_steps=cfg.gradient_accumulation_steps\n",
    "                )\n",
    "            \n",
    "            val_loss, val_auc = validate(model, val_loader, criterion, cfg.device, use_amp=cfg.use_amp)\n",
    "            \n",
    "            if scheduler is not None and not isinstance(scheduler, lr_scheduler.OneCycleLR):\n",
    "                if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                    scheduler.step(val_loss)\n",
    "                else:\n",
    "                    scheduler.step()\n",
    "            \n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}\")\n",
    "            print(f\"Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
    "            \n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_epoch = epoch + 1\n",
    "                print(f\"New best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "                \n",
    "                # Save best model\n",
    "                model_path = f\"{cfg.OUTPUT_DIR}/model_{cfg.timestamp}_{cfg.model_name}_fold{fold}.pth\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
    "                    'epoch': epoch,\n",
    "                    'val_auc': val_auc,\n",
    "                    'train_auc': train_auc,\n",
    "                    'cfg': cfg\n",
    "                }, model_path)\n",
    "        \n",
    "        # Record best score for this fold\n",
    "        best_scores.append(best_auc)\n",
    "        print(f\"\\nTraining complete for fold {fold}. Best AUC: {best_auc:.4f} at epoch {best_epoch}\")\n",
    "        \n",
    "        # Memory cleanup\n",
    "        del model, optimizer, scheduler\n",
    "        del train_loader, val_loader\n",
    "        del train_dataset, val_dataset, final_train_dataset, pseudolabeled_dataset\n",
    "        del filtered_soundscape_df, high_confidence_dict, soundscape_spectrograms\n",
    "\n",
    "        clean_gpu_memory()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Cross-Validation Results:\")\n",
    "    for fold, score in enumerate(best_scores):\n",
    "        print(f\"Fold {fold}: {score:.4f}\")\n",
    "    print(f\"Mean AUC: {np.mean(best_scores):.4f}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c0e6b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T14:00:46.540675Z",
     "iopub.status.busy": "2025-03-17T14:00:46.540437Z",
     "iopub.status.idle": "2025-03-17T14:02:12.293026Z",
     "shell.execute_reply": "2025-03-17T14:02:12.292000Z"
    },
    "papermill": {
     "duration": 85.763673,
     "end_time": "2025-03-17T14:02:12.299868",
     "exception": false,
     "start_time": "2025-03-17T14:00:46.536195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading training data...\n",
      "Will use external pseudolabels from: pseudolabels_better.csv\n",
      "\n",
      "Starting training...\n",
      "LOAD_DATA is set to True\n",
      "Loaded 28579 pre-computed mel spectrograms for labeled data\n",
      "\n",
      "============================== Fold 0 ==============================\n",
      "Training set: 22863 samples\n",
      "Validation set: 5716 samples\n",
      "\n",
      "Initializing soundscape dataset with external pseudolabels...\n",
      "Found 6637 samples with confidence > 0.1\n",
      "Loaded all pseudolabels that pass confidence threshold\n",
      "Training with combined dataset: 22863 original + 6637 pseudolabeled = 29500 total samples\n",
      "\n",
      "-------------------- Training Model --------------------\n",
      "Model compiled successfully with backend 'inductor', mode 'default'\n",
      "\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51cdcc821074cc2a312dd3799d5c3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0519 22:07:09.337000 9600 torch\\_inductor\\utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
     ]
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "backend='inductor' raised:\nCalledProcessError: Command '['C:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\MYSYS2\\\\ucrt64\\\\bin\\\\gcc.EXE', 'C:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Temp\\\\tmpp4mqv5lq\\\\main.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', 'C:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Temp\\\\tmpp4mqv5lq\\\\cuda_utils.cp311-win_amd64.pyd', '-lcuda', '-LC:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\triton\\\\backends\\\\nvidia\\\\lib', '-LC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\lib\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-IC:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\triton\\\\backends\\\\nvidia\\\\include', '-IC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\include', '-IC:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Temp\\\\tmpp4mqv5lq', '-IC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Include', '-IC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.26100.0\\\\shared', '-IC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.26100.0\\\\ucrt', '-IC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.26100.0\\\\um']' returned non-zero exit status 1.\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBackendCompilerFailed\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOAD_DATA is set to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mLOAD_DATA\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msoundscape_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msoundscape_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m cfg\u001b[38;5;241m.\u001b[39msave_config()\n",
      "Cell \u001b[1;32mIn[8], line 109\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(df, cfg, soundscape_df)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 109\u001b[0m     train_loss, train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneCycleLR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_amp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_amp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_accum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m     val_loss, val_auc \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion, cfg\u001b[38;5;241m.\u001b[39mdevice, use_amp\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_amp)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m scheduler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scheduler, lr_scheduler\u001b[38;5;241m.\u001b[39mOneCycleLR):\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, loader, optimizer, criterion, device, scheduler, use_amp, grad_accum_steps)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m         mixed_x, targets_a, targets_b, lam \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcutmix_data(inputs, targets)\n\u001b[1;32m---> 35\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmixed_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m lam \u001b[38;5;241m*\u001b[39m criterion(outputs, targets_a) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m lam) \u001b[38;5;241m*\u001b[39m criterion(outputs, targets_b)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\eval_frame.py:574\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    570\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[0;32m    577\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[0;32m    578\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[0;32m    579\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:1380\u001b[0m, in \u001b[0;36mCatchErrorsWrapper.__call__\u001b[1;34m(self, frame, cache_entry, frame_state)\u001b[0m\n\u001b[0;32m   1374\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(\n\u001b[0;32m   1375\u001b[0m                 frame, cache_entry, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks, frame_state\n\u001b[0;32m   1376\u001b[0m             )\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock, _disable_current_modes():\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;66;03m# skip=1: skip this frame\u001b[39;00m\n\u001b[1;32m-> 1380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:1164\u001b[0m, in \u001b[0;36mConvertFrame.__call__\u001b[1;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[0;32m   1162\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1164\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_convert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:547\u001b[0m, in \u001b[0;36mConvertFrameAssert.__call__\u001b[1;34m(self, frame, cache_entry, hooks, frame_state, skip)\u001b[0m\n\u001b[0;32m    544\u001b[0m     dynamo_tls\u001b[38;5;241m.\u001b[39mtraced_frame_infos\u001b[38;5;241m.\u001b[39mappend(info)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_context(CompileContext(compile_id)):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_torchdynamo_orig_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_export_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframe_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompile_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:986\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(code, globals, locals, builtins, closure, compiler_fn, one_graph, export, export_constraints, hooks, cache_entry, cache_size, frame, frame_state, compile_id, skip)\u001b[0m\n\u001b[0;32m    984\u001b[0m guarded_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 986\u001b[0m     guarded_code \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;66;03m# NB: We only put_code_state in success case.  Success case here\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;66;03m# does include graph breaks; specifically, if a graph break still\u001b[39;00m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;66;03m# resulted in a partially compiled graph, we WILL return here.  An\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;66;03m# to upload for graph break though, because this can prevent\u001b[39;00m\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;66;03m# extra graph break compilations.)\u001b[39;00m\n\u001b[0;32m    997\u001b[0m     put_code_state()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:715\u001b[0m, in \u001b[0;36m_compile.<locals>.compile_inner\u001b[1;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[0;32m    713\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39minstall_callbacks())\n\u001b[0;32m    714\u001b[0m     stack\u001b[38;5;241m.\u001b[39menter_context(CompileTimeInstructionCounter\u001b[38;5;241m.\u001b[39mrecord())\n\u001b[1;32m--> 715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils_internal.py:95\u001b[0m, in \u001b[0;36mcompile_time_strobelight_meta.<locals>.compile_time_strobelight_meta_inner.<locals>.wrapper_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m skip \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StrobelightCompileTimeProfiler\u001b[38;5;241m.\u001b[39mprofile_compile_time(\n\u001b[0;32m     98\u001b[0m     function, phase_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     99\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:750\u001b[0m, in \u001b[0;36m_compile.<locals>._compile_inner\u001b[1;34m(code, one_graph, hooks, transform)\u001b[0m\n\u001b[0;32m    748\u001b[0m CompileContext\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mattempt \u001b[38;5;241m=\u001b[39m attempt\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 750\u001b[0m     out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mRestartAnalysis \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\bytecode_transformation.py:1361\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[1;34m(code, transformations, safe)\u001b[0m\n\u001b[0;32m   1358\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[0;32m   1359\u001b[0m propagate_line_nums(instructions)\n\u001b[1;32m-> 1361\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:231\u001b[0m, in \u001b[0;36mpreserve_global_state.<locals>._fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    229\u001b[0m exit_stack\u001b[38;5;241m.\u001b[39menter_context(torch_function_mode_stack_state_mgr)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     cleanup\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\convert_frame.py:662\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[1;34m(instructions, code_options)\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tracing(tracer\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mtracing_context), tracer\u001b[38;5;241m.\u001b[39mset_current_tx():\n\u001b[1;32m--> 662\u001b[0m         \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mUnspecializeRestartAnalysis:\n\u001b[0;32m    664\u001b[0m     speculation_log\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\symbolic_convert.py:2868\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2867\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m-> 2868\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\symbolic_convert.py:1052\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1052\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1053\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\symbolic_convert.py:962\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_block_stack(inst)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 962\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopcode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m    964\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m TensorifyScalarRestartAnalysis:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\symbolic_convert.py:3048\u001b[0m, in \u001b[0;36mInstructionTranslator.RETURN_VALUE\u001b[1;34m(self, inst)\u001b[0m\n\u001b[0;32m   3047\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRETURN_VALUE\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst):\n\u001b[1;32m-> 3048\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\symbolic_convert.py:3033\u001b[0m, in \u001b[0;36mInstructionTranslator._return\u001b[1;34m(self, inst)\u001b[0m\n\u001b[0;32m   3028\u001b[0m _step_logger()(\n\u001b[0;32m   3029\u001b[0m     logging\u001b[38;5;241m.\u001b[39mINFO,\n\u001b[0;32m   3030\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo done tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   3031\u001b[0m )\n\u001b[0;32m   3032\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m triggered compile\u001b[39m\u001b[38;5;124m\"\u001b[39m, inst\u001b[38;5;241m.\u001b[39mopname)\n\u001b[1;32m-> 3033\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3034\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGraphCompileReason\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3036\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreturn_value\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mframe_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_break\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   3037\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3038\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3039\u001b[0m return_inst \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3040\u001b[0m     create_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m create_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_CONST\u001b[39m\u001b[38;5;124m\"\u001b[39m, argval\u001b[38;5;241m=\u001b[39minst\u001b[38;5;241m.\u001b[39margval)\n\u001b[0;32m   3043\u001b[0m )\n\u001b[0;32m   3044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39madd_output_instructions([return_inst])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\output_graph.py:1101\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[1;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[0;32m   1098\u001b[0m append_prefix_insts()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# optimization to generate better code in a common case\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_output_instructions(\n\u001b[1;32m-> 1101\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mreversed\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_values\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_replacements\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;241m+\u001b[39m [create_instruction(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUNPACK_SEQUENCE\u001b[39m\u001b[38;5;124m\"\u001b[39m, arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(stack_values))]\n\u001b[0;32m   1105\u001b[0m )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# restore all the live local vars\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_output_instructions(\n\u001b[0;32m   1108\u001b[0m     [\n\u001b[0;32m   1109\u001b[0m         PyCodegen(tx, overridden_sources\u001b[38;5;241m=\u001b[39moverridden_sources)\u001b[38;5;241m.\u001b[39mcreate_store(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     ]\n\u001b[0;32m   1114\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\output_graph.py:1382\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[1;34m(self, tx, rv, root, replaced_outputs)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracing_context\u001b[38;5;241m.\u001b[39mfake_mode \u001b[38;5;241m=\u001b[39m backend_fake_mode\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_global_state():\n\u001b[1;32m-> 1382\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lazy_graph_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LazyGraphModule\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(compiled_fn, _LazyGraphModule) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(compiled_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), _LazyGraphModule)\n\u001b[0;32m   1388\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m compiled_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_lazy_forward\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[38;5;66;03m# this is a _LazyGraphModule. This makes it easier for dynamo to\u001b[39;00m\n\u001b[0;32m   1393\u001b[0m     \u001b[38;5;66;03m# optimize a _LazyGraphModule.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\output_graph.py:1432\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[1;34m(self, gm)\u001b[0m\n\u001b[0;32m   1425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_user_compiler\u001b[39m(\u001b[38;5;28mself\u001b[39m, gm: fx\u001b[38;5;241m.\u001b[39mGraphModule) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CompiledFn:\n\u001b[0;32m   1426\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[0;32m   1427\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputGraph.call_user_compiler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1428\u001b[0m         phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1429\u001b[0m         log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1430\u001b[0m         dynamo_compile_column_us\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd_cumulative_compile_time_us\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1431\u001b[0m     ):\n\u001b[1;32m-> 1432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\output_graph.py:1483\u001b[0m, in \u001b[0;36mOutputGraph._call_user_compiler\u001b[1;34m(self, gm)\u001b[0m\n\u001b[0;32m   1481\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiler_fn, e)\u001b[38;5;241m.\u001b[39mwith_traceback(\n\u001b[0;32m   1484\u001b[0m         e\u001b[38;5;241m.\u001b[39m__traceback__\n\u001b[0;32m   1485\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1487\u001b[0m signpost_event(\n\u001b[0;32m   1488\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputGraph.call_user_compiler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1495\u001b[0m     },\n\u001b[0;32m   1496\u001b[0m )\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\output_graph.py:1462\u001b[0m, in \u001b[0;36mOutputGraph._call_user_compiler\u001b[1;34m(self, gm)\u001b[0m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mverify_correctness:\n\u001b[0;32m   1461\u001b[0m     compiler_fn \u001b[38;5;241m=\u001b[39m WrapperBackend(compiler_fn)\n\u001b[1;32m-> 1462\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexample_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1463\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(compiled_fn), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiler_fn did not return callable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py:130\u001b[0m, in \u001b[0;36mWrapBackendDebug.__call__\u001b[1;34m(self, gm, example_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     compiled_gm \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\__init__.py:2340\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[1;34m(self, model_, inputs_)\u001b[0m\n\u001b[0;32m   2337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_, inputs_):\n\u001b[0;32m   2338\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[1;32m-> 2340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\compile_fx.py:1863\u001b[0m, in \u001b[0;36mcompile_fx\u001b[1;34m(model_, example_inputs_, inner_compile, config_patches, decompositions)\u001b[0m\n\u001b[0;32m   1856\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m inference_compiler(unlifted_gm, example_inputs_)\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_fake_mode(fake_mode), torch\u001b[38;5;241m.\u001b[39m_guards\u001b[38;5;241m.\u001b[39mtracing(\n\u001b[0;32m   1859\u001b[0m     tracing_context\n\u001b[0;32m   1860\u001b[0m ), compiled_autograd\u001b[38;5;241m.\u001b[39m_disable(), functorch_config\u001b[38;5;241m.\u001b[39mpatch(\n\u001b[0;32m   1861\u001b[0m     unlift_effect_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m ):\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecompositions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\backends\\common.py:83\u001b[0m, in \u001b[0;36mAotAutograd.__call__\u001b[1;34m(self, gm, example_inputs, **kwargs)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# NB: NOT cloned!\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging(), patch_config:\n\u001b[1;32m---> 83\u001b[0m         cg \u001b[38;5;241m=\u001b[39m \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m         counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m disable(cg)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\aot_autograd.py:1155\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[1;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, keep_inference_input_mutations, inference_compiler, cudagraphs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m AOTAutogradCache\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m   1146\u001b[0m         dispatch_and_compile,\n\u001b[0;32m   1147\u001b[0m         mod,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1152\u001b[0m         remote,\n\u001b[0;32m   1153\u001b[0m     )\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1155\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mod, torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mGmWrapper):\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;66;03m# This function is called by the flatten_graph_inputs wrapper, which boxes\u001b[39;00m\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;66;03m# the inputs so that they can be freed before the end of this scope.\u001b[39;00m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;66;03m# For overhead reasons, this is not the default wrapper, see comment:\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/122535/files#r1560096481\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboxed_forward\u001b[39m(runtime_args: List[Any]):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\aot_autograd.py:1131\u001b[0m, in \u001b[0;36maot_module_simplified.<locals>.dispatch_and_compile\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1129\u001b[0m functional_call \u001b[38;5;241m=\u001b[39m create_functional_call(mod, params_spec, params_len)\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compiled_autograd\u001b[38;5;241m.\u001b[39m_disable():\n\u001b[1;32m-> 1131\u001b[0m     compiled_fn, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\aot_autograd.py:580\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[1;34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_aot_dispatcher_function\u001b[39m(\n\u001b[0;32m    573\u001b[0m     flat_fn,\n\u001b[0;32m    574\u001b[0m     fake_flat_args: FakifiedFlatArgs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m     shape_env: Optional[ShapeEnv],\n\u001b[0;32m    578\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Callable, ViewAndMutationMeta]:\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_aot_dispatcher_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 580\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_create_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m            \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape_env\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\aot_autograd.py:830\u001b[0m, in \u001b[0;36m_create_aot_dispatcher_function\u001b[1;34m(flat_fn, fake_flat_args, aot_config, fake_mode, shape_env)\u001b[0m\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m aot_dispatch_base\n\u001b[0;32m    828\u001b[0m compiler_fn \u001b[38;5;241m=\u001b[39m choose_dispatcher(needs_autograd, aot_config)\n\u001b[1;32m--> 830\u001b[0m compiled_fn, fw_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_dup_fake_script_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfw_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn, fw_metadata\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py:678\u001b[0m, in \u001b[0;36maot_dispatch_autograd\u001b[1;34m(flat_fn, flat_args, aot_config, fw_metadata)\u001b[0m\n\u001b[0;32m    675\u001b[0m     tracing_context\u001b[38;5;241m.\u001b[39mfw_metadata \u001b[38;5;241m=\u001b[39m inner_meta\n\u001b[0;32m    677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TracingContext\u001b[38;5;241m.\u001b[39mreport_output_strides() \u001b[38;5;28;01mas\u001b[39;00m fwd_output_strides:\n\u001b[1;32m--> 678\u001b[0m     compiled_fw_func \u001b[38;5;241m=\u001b[39m \u001b[43maot_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madjusted_flat_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fw_func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    681\u001b[0m     compiled_fw_func \u001b[38;5;241m=\u001b[39m make_boxed_func(compiled_fw_func)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_functorch\\aot_autograd.py:489\u001b[0m, in \u001b[0;36mSerializableAOTDispatchCompiler.__call__\u001b[1;34m(self, gm, example_inputs)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    486\u001b[0m     gm: torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mGraphModule,\n\u001b[0;32m    487\u001b[0m     example_inputs: Sequence[InputType],\n\u001b[0;32m    488\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutputCode:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\compile_fx.py:1741\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler_base\u001b[1;34m(gm, example_inputs, is_inference)\u001b[0m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1739\u001b[0m     model_outputs_node\u001b[38;5;241m.\u001b[39mmeta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_visible_output_idxs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatic_input_idxs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_static_input_idxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfixed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_inference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_inference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mboxed_forward_device_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforward_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\compile_fx.py:569\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[1;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m stack\u001b[38;5;241m.\u001b[39menter_context(DebugContext())\n\u001b[0;32m    564\u001b[0m get_chromium_event_logger()\u001b[38;5;241m.\u001b[39madd_event_data(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor_compile\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    566\u001b[0m     is_backward\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_backward\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    567\u001b[0m )\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrap_compiler_debug\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compile_fx_inner\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minductor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_dynamo\\repro\\after_aot.py:102\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[1;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Call the compiler_fn - which is either aot_autograd or inductor\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;66;03m# with fake inputs\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     inner_compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# TODO: Failures here are troublesome because no real inputs,\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# need a different serialization strategy\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mrepro_after \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\compile_fx.py:685\u001b[0m, in \u001b[0;36m_compile_fx_inner\u001b[1;34m(gm, example_inputs, **graph_kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m TritonBundler\u001b[38;5;241m.\u001b[39mbegin_compile()\n\u001b[0;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 685\u001b[0m     mb_compiled_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfx_codegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgraph_kwargs\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mb_compiled_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    689\u001b[0m     mb_compiled_graph\u001b[38;5;241m.\u001b[39m_time_taken_ns \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\compile_fx.py:1129\u001b[0m, in \u001b[0;36mfx_codegen_and_compile\u001b[1;34m(gm, example_inputs, inputs_to_check, **graph_kwargs)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfx_codegen_and_compile\u001b[39m(\n\u001b[0;32m   1120\u001b[0m     gm: GraphModule,\n\u001b[0;32m   1121\u001b[0m     example_inputs: Sequence[InputType],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgraph_kwargs: Unpack[_CompileFxKwargs],\n\u001b[0;32m   1126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutputCode:\n\u001b[0;32m   1127\u001b[0m     scheme: FxCompile \u001b[38;5;241m=\u001b[39m _InProcessFxCompile()\n\u001b[1;32m-> 1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscheme\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_and_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_to_check\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\compile_fx.py:1044\u001b[0m, in \u001b[0;36m_InProcessFxCompile.codegen_and_compile\u001b[1;34m(self, gm, example_inputs, inputs_to_check, graph_kwargs)\u001b[0m\n\u001b[0;32m   1036\u001b[0m             compiled_fn \u001b[38;5;241m=\u001b[39m AotCodeCompiler\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m   1037\u001b[0m                 graph,\n\u001b[0;32m   1038\u001b[0m                 code,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m                 additional_files\u001b[38;5;241m=\u001b[39madditional_files,\n\u001b[0;32m   1042\u001b[0m             )\n\u001b[0;32m   1043\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1044\u001b[0m         compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m   1046\u001b[0m num_bytes, nodes_num_elem, node_runtimes \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcount_bytes()\n\u001b[0;32m   1047\u001b[0m metrics\u001b[38;5;241m.\u001b[39mnum_bytes_accessed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_bytes\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\graph.py:2027\u001b[0m, in \u001b[0;36mGraphLowering.compile_to_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2020\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModuleType:\n\u001b[0;32m   2021\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\n\u001b[0;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphLowering.compile_to_module\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2023\u001b[0m         phase_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_gen\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2024\u001b[0m         log_pt2_compile_event\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2025\u001b[0m         dynamo_compile_column_us\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minductor_code_gen_cumulative_compile_time_us\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2026\u001b[0m     ):\n\u001b[1;32m-> 2027\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compile_to_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\graph.py:2033\u001b[0m, in \u001b[0;36mGraphLowering._compile_to_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2029\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_compile_to_module\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ModuleType:\n\u001b[0;32m   2030\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcodecache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyCodeCache\n\u001b[0;32m   2032\u001b[0m     code, linemap \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 2033\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodegen_with_cpp_wrapper() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpp_wrapper \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2034\u001b[0m     )\n\u001b[0;32m   2035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mautotune_at_compile_time:\n\u001b[0;32m   2036\u001b[0m         tuning_code \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2038\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompile-time auto-tuning block: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2041\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2042\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\graph.py:1968\u001b[0m, in \u001b[0;36mGraphLowering.codegen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1965\u001b[0m V\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m.\u001b[39mdraw_orig_fx_graph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_gm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscheduler\u001b[38;5;241m.\u001b[39mnodes)\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper_code\u001b[38;5;241m.\u001b[39mpush_codegened_graph(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1970\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m   1971\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished codegen for all nodes. The list of kernel names available: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1972\u001b[0m     V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mall_codegen_kernel_names,\n\u001b[0;32m   1973\u001b[0m )\n\u001b[0;32m   1975\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrapper_code\u001b[38;5;241m.\u001b[39mgenerate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_inference)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\scheduler.py:3477\u001b[0m, in \u001b[0;36mScheduler.codegen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodegen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3476\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dynamo_timed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScheduler.codegen\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 3477\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codegen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\scheduler.py:3554\u001b[0m, in \u001b[0;36mScheduler._codegen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3552\u001b[0m     backend\u001b[38;5;241m.\u001b[39mcodegen_combo_kernel(node)\n\u001b[0;32m   3553\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, (FusedSchedulerNode, SchedulerNode)):\n\u001b[1;32m-> 3554\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3556\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, NopKernelSchedulerNode)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\codegen\\cuda_combined_scheduling.py:80\u001b[0m, in \u001b[0;36mCUDACombinedScheduling.codegen_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcodegen_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, node: Union[FusedSchedulerNode, SchedulerNode]):\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_triton_scheduling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\codegen\\simd.py:1219\u001b[0m, in \u001b[0;36mSIMDScheduling.codegen_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m   1216\u001b[0m node_schedule \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_node_schedule(nodes, numel, rnumel)\n\u001b[0;32m   1217\u001b[0m schedule_log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSchedule:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, node_schedule)\n\u001b[1;32m-> 1219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_node_schedule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mSIMDKernelFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrnumel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\codegen\\simd.py:1263\u001b[0m, in \u001b[0;36mSIMDScheduling.codegen_node_schedule\u001b[1;34m(self, kernel_features)\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m kernel \u001b[38;5;129;01min\u001b[39;00m kernels:\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_kernel_handler(kernel):\n\u001b[1;32m-> 1263\u001b[0m         src_code \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcodegen_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m     kernel_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefine_kernel(src_code, node_schedule, kernel)\n\u001b[0;32m   1265\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerating kernel code with kernel_name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, kernel_name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\codegen\\triton.py:3154\u001b[0m, in \u001b[0;36mTritonKernel.codegen_kernel\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3141\u001b[0m \u001b[38;5;66;03m# Skip memory optimization for forward of the training loop where we expect\u001b[39;00m\n\u001b[0;32m   3142\u001b[0m \u001b[38;5;66;03m# every new node will increase the peak memory and our greedy approach would\u001b[39;00m\n\u001b[0;32m   3143\u001b[0m \u001b[38;5;66;03m# introduce a lot of unnecessary cpu copies.\u001b[39;00m\n\u001b[0;32m   3144\u001b[0m optimize_mem \u001b[38;5;241m=\u001b[39m V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mis_inference \u001b[38;5;129;01mor\u001b[39;00m V\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mis_backward\n\u001b[0;32m   3146\u001b[0m inductor_meta \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   3147\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_hints\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautotune_hints),\n\u001b[0;32m   3148\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkernel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(Placeholder\u001b[38;5;241m.\u001b[39mDESCRIPTIVE_NAME),\n\u001b[0;32m   3149\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmutated_arg_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: mutated_args,\n\u001b[0;32m   3150\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize_mem\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimize_mem,\n\u001b[0;32m   3151\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_x_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_x_dim,\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_load\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_load,\n\u001b[0;32m   3153\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_reduction\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_reduction,\n\u001b[1;32m-> 3154\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minductor_meta_common\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3155\u001b[0m }\n\u001b[0;32m   3156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcooperative_reduction:\n\u001b[0;32m   3157\u001b[0m     inductor_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpersistent_reduction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_reduction\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_inductor\\codegen\\triton.py:3013\u001b[0m, in \u001b[0;36mTritonKernel.inductor_meta_common\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3010\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m   3011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minductor_meta_common\u001b[39m():\n\u001b[0;32m   3012\u001b[0m     inductor_meta \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m-> 3013\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_triton\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriton_hash_with_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3014\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare_deterministic_algorithms_enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mare_deterministic_algorithms_enabled(),\n\u001b[0;32m   3015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_indirect_indexing\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39massert_indirect_indexing,\n\u001b[0;32m   3016\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_local_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mautotune_local_cache,\n\u001b[0;32m   3017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_pointwise\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mautotune_pointwise,\n\u001b[0;32m   3018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautotune_remote_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mautotune_remote_cache,\n\u001b[0;32m   3019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_disable_caches\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mforce_disable_caches,\n\u001b[0;32m   3020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdynamic_scale_rblock\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mdynamic_scale_rblock,\n\u001b[0;32m   3021\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_autotune\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mmax_autotune,\n\u001b[0;32m   3022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_autotune_pointwise\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mmax_autotune_pointwise,\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_split_scan_rblock\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mmin_split_scan_rblock,\n\u001b[0;32m   3024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspill_threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mspill_threshold,\n\u001b[0;32m   3025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstore_cubin\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mtriton\u001b[38;5;241m.\u001b[39mstore_cubin,\n\u001b[0;32m   3026\u001b[0m     }\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mversion\u001b[38;5;241m.\u001b[39mhip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3028\u001b[0m         inductor_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_hip\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_triton.py:111\u001b[0m, in \u001b[0;36mtriton_hash_with_backend\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtriton_hash_with_backend\u001b[39m():\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m triton_key\n\u001b[1;32m--> 111\u001b[0m     backend \u001b[38;5;241m=\u001b[39m \u001b[43mtriton_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtriton_key()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;241m.\u001b[39mhash()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;66;03m# Hash is upper case so that it can't contain any Python keywords.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\utils\\_triton.py:103\u001b[0m, in \u001b[0;36mtriton_backend\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompiler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_backend\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m driver\n\u001b[1;32m--> 103\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_current_target\u001b[49m()\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m make_backend(target)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\runtime\\driver.py:23\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj, name)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\runtime\\driver.py:20\u001b[0m, in \u001b[0;36mLazyProxy._initialize_obj\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize_obj\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\runtime\\driver.py:9\u001b[0m, in \u001b[0;36m_create_driver\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(actives) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(actives)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m active drivers (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactives\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). There should only be one.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mactives\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\backends\\nvidia\\driver.py:414\u001b[0m, in \u001b[0;36mCudaDriver.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mutils \u001b[38;5;241m=\u001b[39m \u001b[43mCudaUtils\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# TODO: make static\u001b[39;00m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlauncher_cls \u001b[38;5;241m=\u001b[39m CudaLauncher\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\backends\\nvidia\\driver.py:92\u001b[0m, in \u001b[0;36mCudaUtils.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 92\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_module_from_src\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver.c\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda_utils\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_binary \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mload_binary\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_device_properties \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mget_device_properties\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\backends\\nvidia\\driver.py:69\u001b[0m, in \u001b[0;36mcompile_module_from_src\u001b[1;34m(src, name)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     68\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(src)\n\u001b[1;32m---> 69\u001b[0m so \u001b[38;5;241m=\u001b[39m \u001b[43m_build\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmpdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibrary_dirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlibraries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(so, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     71\u001b[0m     cache_path \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mput(f\u001b[38;5;241m.\u001b[39mread(), so_name, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\triton\\runtime\\build.py:75\u001b[0m, in \u001b[0;36m_build\u001b[1;34m(name, src, srcdir, library_dirs, include_dirs, libraries)\u001b[0m\n\u001b[0;32m     73\u001b[0m     library_dirs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m msvc_winsdk_lib_dirs\n\u001b[0;32m     74\u001b[0m cc_cmd \u001b[38;5;241m=\u001b[39m _cc_cmd(cc, src, so, include_dirs, library_dirs, libraries)\n\u001b[1;32m---> 75\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc_cmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m so\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:413\u001b[0m, in \u001b[0;36mcheck_call\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m         cmd \u001b[38;5;241m=\u001b[39m popenargs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 413\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[0;32m    414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mBackendCompilerFailed\u001b[0m: backend='inductor' raised:\nCalledProcessError: Command '['C:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\MYSYS2\\\\ucrt64\\\\bin\\\\gcc.EXE', 'C:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Temp\\\\tmpp4mqv5lq\\\\main.c', '-O3', '-shared', '-fPIC', '-Wno-psabi', '-o', 'C:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Temp\\\\tmpp4mqv5lq\\\\cuda_utils.cp311-win_amd64.pyd', '-lcuda', '-LC:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\triton\\\\backends\\\\nvidia\\\\lib', '-LC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\lib\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-LC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\libs', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\ucrt\\\\x64', '-LC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Lib\\\\10.0.26100.0\\\\um\\\\x64', '-IC:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python311\\\\site-packages\\\\triton\\\\backends\\\\nvidia\\\\include', '-IC:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\v12.8\\\\include', '-IC:\\\\Users\\\\maxge\\\\AppData\\\\Local\\\\Temp\\\\tmpp4mqv5lq', '-IC:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\\\Include', '-IC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.26100.0\\\\shared', '-IC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.26100.0\\\\ucrt', '-IC:\\\\Program Files (x86)\\\\Windows Kits\\\\10\\\\Include\\\\10.0.26100.0\\\\um']' returned non-zero exit status 1.\n\nSet TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    import torch._dynamo\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nLoading training data...\")\n",
    "    train_df = pd.read_csv(cfg.train_csv)\n",
    "\n",
    "    # Load soundscape data if external pseudolabels are enabled\n",
    "    soundscape_df = None\n",
    "    if cfg.use_external_pseudolabels:\n",
    "        print(f\"Will use external pseudolabels from: {cfg.external_pseudolabels}\")\n",
    "        soundscape_df = pd.read_csv(cfg.external_pseudolabels)\n",
    "\n",
    "    print(\"\\nStarting training...\")\n",
    "    print(f\"LOAD_DATA is set to {cfg.LOAD_DATA}\")\n",
    "\n",
    "    run_training(train_df, cfg, soundscape_df=soundscape_df)\n",
    "    print(\"\\nTraining complete!\")\n",
    "    cfg.save_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f32d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 6886569,
     "sourceId": 11053663,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.861675,
   "end_time": "2025-03-17T14:02:15.686871",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-17T14:00:29.825196",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0fa836ee22b04b368008c3690b558e46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "114dd08c70bd4b1c9eca37e27bf08897": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1300468cac164026a61e5e60b05b005d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "158d32467f5247c983eb8907b6f5436f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ad27b2a5cded4c23a3f72be3cee7c158",
        "IPY_MODEL_2d82fd9a33be40a19b68a6b37ee2375c",
        "IPY_MODEL_8720627fe38240cb88edd61a2fa45481"
       ],
       "layout": "IPY_MODEL_8eca206926bb44e9b42a5170bf4b1492",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1ad6a9d60ae24934ae355801b4992850": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1be8903e7c5d424abe30c82905dfa291",
        "IPY_MODEL_beceebaa8bef4939a3027e1756c820ca",
        "IPY_MODEL_65c613e48ff14d02b91adbeae536f703"
       ],
       "layout": "IPY_MODEL_7d38c7c32ff24563ae51248957aac76a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1be8903e7c5d424abe30c82905dfa291": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fbd77392c5e94748a19ab6adc204c0f0",
       "placeholder": "​",
       "style": "IPY_MODEL_5c8f99997b3d447cb7664e6c8213d5af",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation: 100%"
      }
     },
     "1e6784d317664982818c369ec64d4375": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b325002c114fb6801da1f6f7e2a2eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23b951c7b2c847bbaf9c066b7f932c12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f808eb60489b4ef2bc76b055d5c477ff",
       "placeholder": "​",
       "style": "IPY_MODEL_ed26d5cb2ff3426a9449e0166b68afbf",
       "tabbable": null,
       "tooltip": null,
       "value": " 31/31 [00:05&lt;00:00,  5.70it/s, train_loss=0.0308, lr=0.000488]"
      }
     },
     "2b7b0d3f79504d87a8dbfb2f7893399a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_527982470da345c590c47f26ce1f9ccf",
       "max": 31,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ddf272308e664d24820c9ca6e917e456",
       "tabbable": null,
       "tooltip": null,
       "value": 31
      }
     },
     "2d82fd9a33be40a19b68a6b37ee2375c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4cc700caf0949c5bf39d8f7539ba2d2",
       "max": 21355344,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_925afd9abcc74142bd88971863bb345b",
       "tabbable": null,
       "tooltip": null,
       "value": 21355344
      }
     },
     "35b20f9b2e8746c68e234fcb6d29f047": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_23b325002c114fb6801da1f6f7e2a2eb",
       "max": 31,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_926aa065fa4f40b4b623fd079ba7cd0f",
       "tabbable": null,
       "tooltip": null,
       "value": 31
      }
     },
     "527982470da345c590c47f26ce1f9ccf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "546a352a5f6d48bd9769e2dff67a1419": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "577df72f0ce349d8988b16f4429c3116": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6314d51e57944ca399dd8819d2c5c214",
       "placeholder": "​",
       "style": "IPY_MODEL_c4ccd0e9a85348d4a50bda1dc66d9658",
       "tabbable": null,
       "tooltip": null,
       "value": "Training: 100%"
      }
     },
     "5c8f99997b3d447cb7664e6c8213d5af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "60623af9dc82439fbac9dce1bb4a9d90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6314d51e57944ca399dd8819d2c5c214": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65c613e48ff14d02b91adbeae536f703": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_114dd08c70bd4b1c9eca37e27bf08897",
       "placeholder": "​",
       "style": "IPY_MODEL_f8e3ad286a374d558e61627ba3a67d26",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:02&lt;00:00, 22.08it/s]"
      }
     },
     "66d95ea040244824b4f188b4985e8cb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "690250bf83464a7f91cd587a5f56d48e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7036c511c9b34e76837009a371c58be9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1300468cac164026a61e5e60b05b005d",
       "placeholder": "​",
       "style": "IPY_MODEL_690250bf83464a7f91cd587a5f56d48e",
       "tabbable": null,
       "tooltip": null,
       "value": " 32/32 [00:01&lt;00:00, 22.00it/s]"
      }
     },
     "74c1cd7782554123a2d89d46d13808b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d995347d83ec40e2b0c1db58a78e3dde",
        "IPY_MODEL_dcdaa701c23b4a1697b18ae319e036f6",
        "IPY_MODEL_7036c511c9b34e76837009a371c58be9"
       ],
       "layout": "IPY_MODEL_dc55c130999847b6a7460d8d68f31668",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7d38c7c32ff24563ae51248957aac76a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "871d479608024b77bb2db8278e3f659d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8720627fe38240cb88edd61a2fa45481": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_934ed224b7fd4de3ab54a89a789f0e3a",
       "placeholder": "​",
       "style": "IPY_MODEL_a42ef4d205e74949b7fb2dee1039c2d8",
       "tabbable": null,
       "tooltip": null,
       "value": " 21.4M/21.4M [00:00&lt;00:00, 86.8MB/s]"
      }
     },
     "8e978a7645e7420fb2e452a3e2e7f69d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ab2f0fc298124ff685860a158b2ec252",
       "placeholder": "​",
       "style": "IPY_MODEL_9366d6929e0c44408fb54456fff6c241",
       "tabbable": null,
       "tooltip": null,
       "value": " 31/31 [00:06&lt;00:00,  5.75it/s, train_loss=0.0344, lr=0.0005]"
      }
     },
     "8eca206926bb44e9b42a5170bf4b1492": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9193f88c4b9842c4a73d33b86e2a79b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "925afd9abcc74142bd88971863bb345b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "926aa065fa4f40b4b623fd079ba7cd0f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "934ed224b7fd4de3ab54a89a789f0e3a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9366d6929e0c44408fb54456fff6c241": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "93a38cd64b7e457082b679b1aace02df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a17d437eca184c35ae51d6ddf160ad00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b3d1cca7cebb47ee9a5fb1281ffa00bb",
       "placeholder": "​",
       "style": "IPY_MODEL_546a352a5f6d48bd9769e2dff67a1419",
       "tabbable": null,
       "tooltip": null,
       "value": "Training: 100%"
      }
     },
     "a337ff0d214a41d1a7314a4ca229bfd3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a42ef4d205e74949b7fb2dee1039c2d8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab2f0fc298124ff685860a158b2ec252": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ac1a06c6ab024f11a1a52431788f6823": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ad27b2a5cded4c23a3f72be3cee7c158": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_93a38cd64b7e457082b679b1aace02df",
       "placeholder": "​",
       "style": "IPY_MODEL_fb003526535b4cba8efa507d3f92a66b",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "b3d1cca7cebb47ee9a5fb1281ffa00bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "beceebaa8bef4939a3027e1756c820ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ac1a06c6ab024f11a1a52431788f6823",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0fa836ee22b04b368008c3690b558e46",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "c4ccd0e9a85348d4a50bda1dc66d9658": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cafb1e5ee8af47dc9a8813cdb7dad1b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_577df72f0ce349d8988b16f4429c3116",
        "IPY_MODEL_2b7b0d3f79504d87a8dbfb2f7893399a",
        "IPY_MODEL_23b951c7b2c847bbaf9c066b7f932c12"
       ],
       "layout": "IPY_MODEL_a337ff0d214a41d1a7314a4ca229bfd3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d995347d83ec40e2b0c1db58a78e3dde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1e6784d317664982818c369ec64d4375",
       "placeholder": "​",
       "style": "IPY_MODEL_66d95ea040244824b4f188b4985e8cb2",
       "tabbable": null,
       "tooltip": null,
       "value": "Validation: 100%"
      }
     },
     "dc55c130999847b6a7460d8d68f31668": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcdaa701c23b4a1697b18ae319e036f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_871d479608024b77bb2db8278e3f659d",
       "max": 32,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60623af9dc82439fbac9dce1bb4a9d90",
       "tabbable": null,
       "tooltip": null,
       "value": 32
      }
     },
     "ddf272308e664d24820c9ca6e917e456": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e80cbc93209642a8bbe28877b257eab6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a17d437eca184c35ae51d6ddf160ad00",
        "IPY_MODEL_35b20f9b2e8746c68e234fcb6d29f047",
        "IPY_MODEL_8e978a7645e7420fb2e452a3e2e7f69d"
       ],
       "layout": "IPY_MODEL_9193f88c4b9842c4a73d33b86e2a79b8",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ed26d5cb2ff3426a9449e0166b68afbf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f4cc700caf0949c5bf39d8f7539ba2d2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f808eb60489b4ef2bc76b055d5c477ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8e3ad286a374d558e61627ba3a67d26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fb003526535b4cba8efa507d3f92a66b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fbd77392c5e94748a19ab6adc204c0f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
