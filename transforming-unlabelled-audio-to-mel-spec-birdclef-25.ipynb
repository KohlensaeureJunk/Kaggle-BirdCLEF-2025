{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**\n",
    "This notebook demonstrates how we can transform audio data into mel-spectrogram data. This transformation is essential for training 2D Convolutional Neural Networks (CNNs) on audio data, as it converts the one-dimensional audio signals into two-dimensional image-like representations.\n",
    "I run this public notebook in debug mode(only a few sample processing). You can find the fully preprocessed mel spectrogram training dataset here --> [BirdCLEF'25 | Mel Spectrograms](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.815250Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    " \n",
    "    DEBUG_MODE = False\n",
    "    \n",
    "    OUTPUT_DIR = 'archive/'\n",
    "    DATASET_NAME = 'train_soundscapes_melspec_12x5_256_256'\n",
    "    SOUNDSCAPE_DIR = \"birdclef-2025/train_soundscapes\"\n",
    "    FS = 32000\n",
    "    \n",
    "    # Mel spectrogram parameters\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    WINDOW_SIZE = 5\n",
    "    \n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)  \n",
    "    \n",
    "    N_MAX = 50 if DEBUG_MODE else None  \n",
    "\n",
    "config = Config()\n",
    "\n",
    "os.makedirs(f\"{config.OUTPUT_DIR}{config.DATASET_NAME}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.555260Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: OFF\n",
      "Max samples to process: ALL\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if config.DEBUG_MODE else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples to process: 9726 out of 9726 available\n"
     ]
    }
   ],
   "source": [
    "filepaths = [f\"{config.SOUNDSCAPE_DIR}\"+\"/\"+f\"{name}\" for name in os.listdir(config.SOUNDSCAPE_DIR)]\n",
    "working_df = pd.DataFrame({\"filepath\":filepaths})\n",
    "working_df['samplename'] = working_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "with open('sample_list.csv', 'w') as f:\n",
    "    working_df.to_csv(f)\n",
    "print(f'Total samples to process: {total_samples} out of {len(working_df)} available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_segment(audio_data):\n",
    "    \"\"\"Process audio segment to get mel spectrogram\"\"\"\n",
    "    if len(audio_data) < config.FS * config.WINDOW_SIZE:\n",
    "        audio_data = np.pad(audio_data, \n",
    "                          (0, config.FS * config.WINDOW_SIZE - len(audio_data)), \n",
    "                          mode='constant')\n",
    "    \n",
    "    mel_spec = audio2melspec(audio_data)\n",
    "    \n",
    "    if mel_spec.shape != config.TARGET_SHAPE:\n",
    "        mel_spec = cv2.resize(mel_spec, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    return mel_spec.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:18:01.589636Z",
     "iopub.status.busy": "2025-03-17T13:18:01.589211Z",
     "iopub.status.idle": "2025-03-17T13:18:25.526712Z",
     "shell.execute_reply": "2025-03-17T13:18:25.525599Z",
     "shell.execute_reply.started": "2025-03-17T13:18:01.589604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting audio processing...\n",
      "FULL MODE - Processing all samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4201542be3c6424fa69b4a0ec128795b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Starting audio processing...\")\n",
    "print(f\"{'DEBUG MODE - Processing only 50 samples' if config.DEBUG_MODE else 'FULL MODE - Processing all samples'}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Dictionary to track processed files (metadata only, not the actual spectrograms)\n",
    "all_bird_metadata = {}\n",
    "errors = []\n",
    "processed_count = 0\n",
    "\n",
    "# Instead of one big H5 file, save individual numpy files\n",
    "# Create a metadata CSV to keep track of all files\n",
    "metadata_df = pd.DataFrame(columns=['filepath', 'samplename'])\n",
    "\n",
    "try:\n",
    "    # Process and save each spectrogram individually\n",
    "    for i, row in tqdm(working_df.iterrows(), total=total_samples):\n",
    "        if config.N_MAX is not None and i >= config.N_MAX:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "            total_segments = int(len(audio_data) / (config.FS * config.WINDOW_SIZE))\n",
    "            \n",
    "            for segment_idx in range(total_segments):\n",
    "                start_sample = segment_idx * config.FS * config.WINDOW_SIZE\n",
    "                end_sample = start_sample + config.FS * config.WINDOW_SIZE\n",
    "                segment_audio = audio_data[start_sample:end_sample]\n",
    "                \n",
    "                end_time_sec = (segment_idx + 1) * config.WINDOW_SIZE\n",
    "                row_id = f\"{row.samplename}_{end_time_sec}\"\n",
    "                \n",
    "                # Process the audio segment\n",
    "                mel_spec = process_audio_segment(segment_audio)\n",
    "                \n",
    "                # Save each spectrogram as a separate numpy file\n",
    "                spec_filepath = f\"{config.OUTPUT_DIR}{config.DATASET_NAME}/{row_id}.npy\"\n",
    "                np.save(spec_filepath, mel_spec)\n",
    "                \n",
    "                # Add to metadata\n",
    "                metadata_df.loc[len(metadata_df)] = [spec_filepath, row_id]\n",
    "                \n",
    "                # Track metadata only (not the actual data)\n",
    "                all_bird_metadata[row_id] = True\n",
    "                processed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row.filepath}: {e}\")\n",
    "            errors.append((row.filepath, str(e)))\n",
    "    \n",
    "    # Save metadata to CSV\n",
    "    metadata_filepath = f\"{config.OUTPUT_DIR}{config.DATASET_NAME}_metadata.csv\"\n",
    "    metadata_df.to_csv(metadata_filepath)\n",
    "    print(f\"Metadata saved to {metadata_filepath}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during processing: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Processing completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Successfully processed {processed_count} segments out of {total_samples*12} total\")\n",
    "print(f\"Failed to process {len(errors)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:18:40.390482Z",
     "iopub.status.busy": "2025-03-17T13:18:40.389921Z",
     "iopub.status.idle": "2025-03-17T13:18:42.364716Z",
     "shell.execute_reply": "2025-03-17T13:18:42.363415Z",
     "shell.execute_reply.started": "2025-03-17T13:18:40.390449Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "samples = []\n",
    "max_samples = min(4, len(all_bird_metadata))\n",
    "\n",
    "for i, row in working_df.iterrows():\n",
    "    if i >= (config.N_MAX or len(working_df)):\n",
    "        break\n",
    "        \n",
    "    samplename = f\"{row['samplename']}\" \n",
    "    if samplename in all_bird_metadata:\n",
    "        samples.append(samplename)\n",
    "        if len(samples) >= max_samples:  \n",
    "            break\n",
    "\n",
    "if samples:\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    \n",
    "    for i, samplename in enumerate(samples):\n",
    "        spec_filepath = f\"{config.OUTPUT_DIR}{config.DATASET_NAME}/{samplename}.npy\"\n",
    "        if os.path.exists(spec_filepath):\n",
    "            mel_spec = np.load(spec_filepath)\n",
    "            plt.subplot(2, 2, i+1)\n",
    "            plt.imshow(mel_spec, aspect='auto', origin='lower', cmap='viridis')\n",
    "            plt.title(f\"{samplename}\")\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    debug_note = \"debug_\" if config.DEBUG_MODE else \"\"\n",
    "    #plt.savefig(f'{debug_note}melspec_examples.png')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".birdclef_env (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
