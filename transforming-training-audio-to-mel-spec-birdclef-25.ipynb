{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook - Combined**\n",
    "This notebook demonstrates how we can transform audio data into mel-spectrogram data. This transformation is essential for training 2D Convolutional Neural Networks (CNNs) on audio data, as it converts the one-dimensional audio signals into two-dimensional image-like representations.\n",
    "\n",
    "This combined notebook can process:\n",
    "- Training audio (labeled data) AND soundscape audio (unlabeled data) in sequence\n",
    "- Center segments only or all segments\n",
    "- Save to single file or individual files\n",
    "\n",
    "If you run this public notebook in debug mode, only a few samples will be processed. You can find the fully preprocessed mel spectrogram training and soundscape dataset here --> [BirdCLEF'25 | Mel Spectrograms](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.815250Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    DEBUG_MODE = True\n",
    "    \n",
    "    # Data source configuration - will process both types\n",
    "    DATA_TYPES = ['train_audio', 'train_soundscapes']  # Process both in sequence\n",
    "    DATA_ROOT = 'birdclef-2025'\n",
    "    \n",
    "    # Processing mode configuration\n",
    "    USE_CENTER_ONLY = True  # True: extract center segment only, False: extract all segments\n",
    "    SAVE_INDIVIDUAL_FILES = False  # True: save as individual .npy files, False: save as single dictionary\n",
    "    \n",
    "    # Output configuration\n",
    "    OUTPUT_DIR = 'archive/'\n",
    "    DATASET_NAME = 'combined'  # Used for individual files or as filename prefix\n",
    "    \n",
    "    # Audio processing parameters\n",
    "    FS = 32000\n",
    "    WINDOW_SIZE = 5\n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)\n",
    "    \n",
    "    # Mel spectrogram parameters\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    \n",
    "    # Debug and extension options\n",
    "    N_MAX = 50 if DEBUG_MODE else None\n",
    "    ADD_TO_EXISTING = False  # Only used when SAVE_INDIVIDUAL_FILES=False\n",
    "    \n",
    "    def get_audio_dir(self, data_type):\n",
    "        if data_type == 'train_audio':\n",
    "            return f\"{self.DATA_ROOT}/train_audio/\"\n",
    "        elif data_type == 'train_soundscapes':\n",
    "            return f\"{self.DATA_ROOT}/train_soundscapes/\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown DATA_TYPE: {data_type}\")\n",
    "    \n",
    "    def get_output_filename(self, data_type):\n",
    "        mode = \"center\" if self.USE_CENTER_ONLY else \"all\"\n",
    "        return f\"{self.DATASET_NAME}_{data_type}_{mode}_{self.WINDOW_SIZE}_{self.TARGET_SHAPE[0]}_{self.TARGET_SHAPE[1]}.npy\"\n",
    "    \n",
    "    def save_config(self, filepath):\n",
    "        \"\"\"Save configuration to JSON file\"\"\"\n",
    "        config_dict = {attr: getattr(self, attr) for attr in dir(self) if not attr.startswith('__') and not callable(getattr(self, attr))}\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(config_dict, f, indent=2)\n",
    "        print(f\"Configuration saved to {filepath}\")\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Create output directory\n",
    "if config.SAVE_INDIVIDUAL_FILES:\n",
    "    for data_type in config.DATA_TYPES:\n",
    "        os.makedirs(f\"{config.OUTPUT_DIR}{config.DATASET_NAME}_{data_type}\", exist_ok=True)\n",
    "else:\n",
    "    os.makedirs(config.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Save configuration\n",
    "config_filename = f\"{config.OUTPUT_DIR}config_{config.DATASET_NAME}.json\"\n",
    "config.save_config(config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data_for_type(data_type):\n",
    "    \"\"\"Load data based on type and return working dataframe\"\"\"\n",
    "    if data_type == 'train_audio':\n",
    "        print(f\"Loading training data with labels...\")\n",
    "        taxonomy_df = pd.read_csv(f'{config.DATA_ROOT}/taxonomy.csv')\n",
    "        species_class_map = dict(zip(taxonomy_df['primary_label'], taxonomy_df['class_name']))\n",
    "        \n",
    "        train_df = pd.read_csv(f'{config.DATA_ROOT}/train.csv')\n",
    "        \n",
    "        label_list = sorted(train_df['primary_label'].unique())\n",
    "        label_id_list = list(range(len(label_list)))\n",
    "        label2id = dict(zip(label_list, label_id_list))\n",
    "        \n",
    "        print(f'Found {len(label_list)} unique species')\n",
    "        working_df = train_df[['primary_label', 'rating', 'filename']].copy()\n",
    "        working_df['target'] = working_df.primary_label.map(label2id)\n",
    "        working_df['filepath'] = config.get_audio_dir(data_type) + working_df.filename\n",
    "        working_df['samplename'] = working_df.filename.map(lambda x: x.split('/')[0] + '-' + x.split('/')[-1].split('.')[0])\n",
    "        working_df['class'] = working_df.primary_label.map(lambda x: species_class_map.get(x, 'Unknown'))\n",
    "        \n",
    "        print(f'Samples by class:')\n",
    "        print(working_df['class'].value_counts())\n",
    "        \n",
    "    elif data_type == 'train_soundscapes':\n",
    "        print(f\"Loading soundscape data (unlabeled)...\")\n",
    "        audio_dir = config.get_audio_dir(data_type)\n",
    "        filepaths = [f\"{audio_dir}{name}\" for name in os.listdir(audio_dir)]\n",
    "        working_df = pd.DataFrame({\"filepath\": filepaths})\n",
    "        working_df['samplename'] = working_df.filepath.map(lambda x: os.path.basename(x).split('.')[0])\n",
    "        working_df['class'] = 'soundscape'  # All soundscapes get same class\n",
    "        working_df['target'] = 0  # Dummy target for consistency\n",
    "    \n",
    "    total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "    print(f'Total files to process: {total_samples} out of {len(working_df)} available')\n",
    "    \n",
    "    return working_df, total_samples\n",
    "\n",
    "# Load data for both data types\n",
    "all_working_dfs = {}\n",
    "all_total_samples = {}\n",
    "\n",
    "for data_type in config.DATA_TYPES:\n",
    "    print(f\"\\n=== Loading {data_type} ===\")\n",
    "    working_df, total_samples = load_data_for_type(data_type)\n",
    "    all_working_dfs[data_type] = working_df\n",
    "    all_total_samples[data_type] = total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_segment(audio_data):\n",
    "    \"\"\"Process audio segment to get mel spectrogram\"\"\"\n",
    "    target_samples = int(config.WINDOW_SIZE * config.FS)\n",
    "    \n",
    "    if len(audio_data) < target_samples:\n",
    "        audio_data = np.pad(audio_data, \n",
    "                          (0, target_samples - len(audio_data)), \n",
    "                          mode='constant')\n",
    "    \n",
    "    mel_spec = audio2melspec(audio_data)\n",
    "    \n",
    "    if mel_spec.shape != config.TARGET_SHAPE:\n",
    "        mel_spec = cv2.resize(mel_spec, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    return mel_spec.astype(np.float32)\n",
    "\n",
    "def process_center_audio(audio_data):\n",
    "    \"\"\"Process center portion of audio for single segment extraction\"\"\"\n",
    "    target_samples = int(config.TARGET_DURATION * config.FS)\n",
    "\n",
    "    if len(audio_data) < target_samples:\n",
    "        n_copy = math.ceil(target_samples / len(audio_data))\n",
    "        if n_copy > 1:\n",
    "            audio_data = np.concatenate([audio_data] * n_copy)\n",
    "\n",
    "    start_idx = max(0, int(len(audio_data) / 2 - target_samples / 2))\n",
    "    end_idx = min(len(audio_data), start_idx + target_samples)\n",
    "    center_audio = audio_data[start_idx:end_idx]\n",
    "\n",
    "    if len(center_audio) < target_samples:\n",
    "        center_audio = np.pad(center_audio, \n",
    "                             (0, target_samples - len(center_audio)), \n",
    "                             mode='constant')\n",
    "\n",
    "    return process_audio_segment(center_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:18:01.589636Z",
     "iopub.status.busy": "2025-03-17T13:18:01.589211Z",
     "iopub.status.idle": "2025-03-17T13:18:25.526712Z",
     "shell.execute_reply": "2025-03-17T13:18:25.525599Z",
     "shell.execute_reply.started": "2025-03-17T13:18:01.589604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Starting audio processing for both data types...\")\n",
    "mode_desc = \"center segment\" if config.USE_CENTER_ONLY else \"all segments\"\n",
    "save_desc = \"individual files\" if config.SAVE_INDIVIDUAL_FILES else \"single file per type\"\n",
    "print(f\"Mode: {mode_desc}, Save: {save_desc}\")\n",
    "print(f\"{'DEBUG MODE - Processing only 50 samples per type' if config.DEBUG_MODE else 'FULL MODE - Processing all samples'}\")\n",
    "\n",
    "total_start_time = time.time()\n",
    "all_results = {}\n",
    "\n",
    "# Process each data type\n",
    "for data_type in config.DATA_TYPES:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"PROCESSING {data_type.upper()}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    working_df = all_working_dfs[data_type]\n",
    "    total_samples = all_total_samples[data_type]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    all_bird_data = {}\n",
    "    errors = []\n",
    "    processed_count = 0\n",
    "    \n",
    "    # Load existing data if needed\n",
    "    if not config.SAVE_INDIVIDUAL_FILES and config.ADD_TO_EXISTING:\n",
    "        try:\n",
    "            existing_file = f\"{config.OUTPUT_DIR}{config.get_output_filename(data_type)}\"\n",
    "            if os.path.exists(existing_file):\n",
    "                all_bird_data = np.load(existing_file, allow_pickle=True).item()\n",
    "                print(f\"Loaded {len(all_bird_data)} existing samples for {data_type}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not load existing file for {data_type}: {e}\")\n",
    "    \n",
    "    # Process each audio file\n",
    "    for i, row in tqdm(working_df.iterrows(), total=total_samples, desc=f\"Processing {data_type}\"):\n",
    "        if config.N_MAX is not None and i >= config.N_MAX:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "            \n",
    "            if config.USE_CENTER_ONLY:\n",
    "                # Process center segment only\n",
    "                sample_id = row.samplename\n",
    "                \n",
    "                # Skip if already exists and we're adding to existing\n",
    "                if not config.SAVE_INDIVIDUAL_FILES and config.ADD_TO_EXISTING and sample_id in all_bird_data:\n",
    "                    continue\n",
    "                \n",
    "                mel_spec = process_center_audio(audio_data)\n",
    "                \n",
    "                if config.SAVE_INDIVIDUAL_FILES:\n",
    "                    folder_name = f\"{config.DATASET_NAME}_{data_type}\"\n",
    "                    spec_filepath = f\"{config.OUTPUT_DIR}{folder_name}/{sample_id}.npy\"\n",
    "                    np.save(spec_filepath, mel_spec)\n",
    "                else:\n",
    "                    all_bird_data[sample_id] = mel_spec\n",
    "                    \n",
    "                processed_count += 1\n",
    "                \n",
    "            else:\n",
    "                # Process all segments\n",
    "                segment_samples = config.FS * config.WINDOW_SIZE\n",
    "                original_len = len(audio_data) / config.FS\n",
    "                \n",
    "                # Calculate padding needed to make audio divisible by segment size\n",
    "                remainder = original_len % config.WINDOW_SIZE\n",
    "                if remainder > 0:\n",
    "                    padding_size = int(segment_samples - remainder * config.FS)\n",
    "                    audio_data = np.pad(audio_data, (0, padding_size), mode='constant')\n",
    "                \n",
    "                # Process each segment\n",
    "                total_segments = len(audio_data) // segment_samples\n",
    "                \n",
    "                for segment_idx in range(total_segments):\n",
    "                    start_sample = segment_idx * segment_samples\n",
    "                    end_sample = start_sample + segment_samples\n",
    "                    segment_audio = audio_data[start_sample:end_sample]\n",
    "                    \n",
    "                    end_time_sec = (segment_idx + 1) * config.WINDOW_SIZE\n",
    "                    sample_id = f\"{row.samplename}_{end_time_sec}\"\n",
    "                    \n",
    "                    # Skip if already exists and we're adding to existing\n",
    "                    if not config.SAVE_INDIVIDUAL_FILES and config.ADD_TO_EXISTING and sample_id in all_bird_data:\n",
    "                        continue\n",
    "                    \n",
    "                    mel_spec = process_audio_segment(segment_audio)\n",
    "                    \n",
    "                    if config.SAVE_INDIVIDUAL_FILES:\n",
    "                        folder_name = f\"{config.DATASET_NAME}_{data_type}\"\n",
    "                        spec_filepath = f\"{config.OUTPUT_DIR}{folder_name}/{sample_id}.npy\"\n",
    "                        np.save(spec_filepath, mel_spec)\n",
    "                    else:\n",
    "                        all_bird_data[sample_id] = mel_spec\n",
    "                    \n",
    "                    processed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row.filepath}: {e}\")\n",
    "            errors.append((row.filepath, str(e)))\n",
    "    \n",
    "    # Save results for this data type\n",
    "    if not config.SAVE_INDIVIDUAL_FILES:\n",
    "        # Save single file\n",
    "        output_filepath = f\"{config.OUTPUT_DIR}{config.get_output_filename(data_type)}\"\n",
    "        with open(output_filepath, 'wb') as f:\n",
    "            np.save(f, all_bird_data)\n",
    "        print(f\"Processed data saved to {output_filepath}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"{data_type} processing completed in {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Successfully processed {processed_count} segments\")\n",
    "    print(f\"Failed to process {len(errors)} files\")\n",
    "    \n",
    "    if not config.SAVE_INDIVIDUAL_FILES:\n",
    "        print(f\"Total samples in {data_type} dataset: {len(all_bird_data)}\")\n",
    "    \n",
    "    # Store results for visualization\n",
    "    all_results[data_type] = {\n",
    "        'processed_count': processed_count,\n",
    "        'errors': len(errors),\n",
    "        'data': all_bird_data if not config.SAVE_INDIVIDUAL_FILES else {},\n",
    "        'working_df': working_df\n",
    "    }\n",
    "\n",
    "total_end_time = time.time()\n",
    "print(f\"Total processing time: {total_end_time - total_start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization for both data types\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"Creating visualization for both data types...\")\n",
    "\n",
    "fig, axes = plt.subplots(len(config.DATA_TYPES), 2, figsize=(16, 8 * len(config.DATA_TYPES)))\n",
    "if len(config.DATA_TYPES) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for data_type_idx, data_type in enumerate(config.DATA_TYPES):\n",
    "    result = all_results[data_type]\n",
    "    working_df = result['working_df']\n",
    "    \n",
    "    samples = []\n",
    "    displayed_classes = set()\n",
    "    max_samples = 2  # 2 samples per data type to fit in layout\n",
    "    \n",
    "    for i, row in working_df.iterrows():\n",
    "        if i >= (config.N_MAX or len(working_df)):\n",
    "            break\n",
    "        \n",
    "        if config.USE_CENTER_ONLY:\n",
    "            sample_id = row.samplename\n",
    "        else:\n",
    "            sample_id = f\"{row.samplename}_{config.WINDOW_SIZE}\"  # Use first segment for display\n",
    "        \n",
    "        # Check if sample exists\n",
    "        sample_exists = False\n",
    "        if config.SAVE_INDIVIDUAL_FILES:\n",
    "            folder_name = f\"{config.DATASET_NAME}_{data_type}\"\n",
    "            sample_path = f\"{config.OUTPUT_DIR}{folder_name}/{sample_id}.npy\"\n",
    "            sample_exists = os.path.exists(sample_path)\n",
    "        else:\n",
    "            sample_exists = sample_id in result['data']\n",
    "        \n",
    "        if sample_exists:\n",
    "            class_name = row.get('class', 'Unknown')\n",
    "            if class_name not in displayed_classes or len(displayed_classes) < max_samples:\n",
    "                samples.append((sample_id, class_name, row.get('primary_label', 'N/A'), data_type))\n",
    "                displayed_classes.add(class_name)\n",
    "            if len(samples) >= max_samples:\n",
    "                break\n",
    "    \n",
    "    # Plot up to 2 samples for this data type\n",
    "    for sample_idx in range(min(len(samples), 2)):\n",
    "        sample_id, class_name, species, _ = samples[sample_idx]\n",
    "        \n",
    "        ax = axes[data_type_idx][sample_idx] if len(config.DATA_TYPES) > 1 else axes[sample_idx]\n",
    "        \n",
    "        if config.SAVE_INDIVIDUAL_FILES:\n",
    "            folder_name = f\"{config.DATASET_NAME}_{data_type}\"\n",
    "            sample_path = f\"{config.OUTPUT_DIR}{folder_name}/{sample_id}.npy\"\n",
    "            mel_spec = np.load(sample_path)\n",
    "        else:\n",
    "            mel_spec = result['data'][sample_id]\n",
    "        \n",
    "        im = ax.imshow(mel_spec, aspect='auto', origin='lower', cmap='viridis')\n",
    "        ax.set_title(f\"{data_type}: {class_name} - {species}\")\n",
    "        plt.colorbar(im, ax=ax, format='%+2.0f dB')\n",
    "    \n",
    "    # If less than 2 samples, hide empty subplot\n",
    "    if len(samples) < 2:\n",
    "        ax = axes[data_type_idx][1] if len(config.DATA_TYPES) > 1 else axes[1]\n",
    "        ax.set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "debug_note = \"debug_\" if config.DEBUG_MODE else \"\"\n",
    "save_name = f'{debug_note}melspec_examples_combined.png'\n",
    "plt.savefig(save_name)\n",
    "plt.show()\n",
    "print(f\"Visualization saved as {save_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
