{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BirdCLEF 2025 Data Preprocessing Notebook**\n",
    "This notebook demonstrates how we can transform audio data into mel-spectrogram data. This transformation is essential for training 2D Convolutional Neural Networks (CNNs) on audio data, as it converts the one-dimensional audio signals into two-dimensional image-like representations.\n",
    "I run this public notebook in debug mode(only a few sample processing). You can find the fully preprocessed mel spectrogram training dataset here --> [BirdCLEF'25 | Mel Spectrograms](https://www.kaggle.com/datasets/kadircandrisolu/birdclef25-mel-spectrograms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:10:40.815250Z",
     "iopub.status.busy": "2025-03-17T13:10:40.814873Z",
     "iopub.status.idle": "2025-03-17T13:10:45.829114Z",
     "shell.execute_reply": "2025-03-17T13:10:45.828024Z",
     "shell.execute_reply.started": "2025-03-17T13:10:40.815215Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:15:45.762845Z",
     "iopub.status.busy": "2025-03-17T13:15:45.762471Z",
     "iopub.status.idle": "2025-03-17T13:15:45.768405Z",
     "shell.execute_reply": "2025-03-17T13:15:45.766979Z",
     "shell.execute_reply.started": "2025-03-17T13:15:45.762812Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    " \n",
    "    DEBUG_MODE = True\n",
    "    \n",
    "    OUTPUT_DIR = 'archive/'\n",
    "    DATASET_NAME = 'test'#train_audio_melspec_Xx5_256_256'\n",
    "    AUDIO_DIR = \"birdclef-2025/train_audio/\"\n",
    "    FS = 32000\n",
    "    \n",
    "    # Mel spectrogram parameters\n",
    "    N_FFT = 1024\n",
    "    HOP_LENGTH = 512\n",
    "    N_MELS = 128\n",
    "    FMIN = 50\n",
    "    FMAX = 14000\n",
    "    WINDOW_SIZE = 5\n",
    "    \n",
    "    TARGET_DURATION = 5.0\n",
    "    TARGET_SHAPE = (256, 256)  \n",
    "    \n",
    "    N_MAX = 50 if DEBUG_MODE else None  \n",
    "\n",
    "config = Config()\n",
    "\n",
    "os.makedirs(f\"{config.OUTPUT_DIR}{config.DATASET_NAME}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:15.414418Z",
     "iopub.status.busy": "2025-03-17T13:16:15.414035Z",
     "iopub.status.idle": "2025-03-17T13:16:15.555260Z",
     "shell.execute_reply": "2025-03-17T13:16:15.553984Z",
     "shell.execute_reply.started": "2025-03-17T13:16:15.414356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug mode: ON\n",
      "Max samples to process: 50\n"
     ]
    }
   ],
   "source": [
    "print(f\"Debug mode: {'ON' if config.DEBUG_MODE else 'OFF'}\")\n",
    "print(f\"Max samples to process: {config.N_MAX if config.N_MAX is not None else 'ALL'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:16:43.589257Z",
     "iopub.status.busy": "2025-03-17T13:16:43.588879Z",
     "iopub.status.idle": "2025-03-17T13:16:43.644396Z",
     "shell.execute_reply": "2025-03-17T13:16:43.643479Z",
     "shell.execute_reply.started": "2025-03-17T13:16:43.589225Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 50 out of 28579 available\n"
     ]
    }
   ],
   "source": [
    "filepaths = []\n",
    "for root, dirs, files in os.walk(config.AUDIO_DIR):\n",
    "    for file in files:\n",
    "        if file.endswith('.ogg'):\n",
    "            filepaths.append(os.path.join(root, file))\n",
    "\n",
    "working_df = pd.DataFrame({\"filepath\": filepaths})\n",
    "working_df['samplename'] = working_df.filepath.map(lambda x: os.path.basename(x).split('.')[0])\n",
    "total_samples = min(len(working_df), config.N_MAX or len(working_df))\n",
    "with open('sample_list.csv', 'w') as f:\n",
    "    working_df.to_csv(f)\n",
    "print(f'Total files to process: {total_samples} out of {len(working_df)} available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:17:07.823753Z",
     "iopub.status.busy": "2025-03-17T13:17:07.823361Z",
     "iopub.status.idle": "2025-03-17T13:17:07.829972Z",
     "shell.execute_reply": "2025-03-17T13:17:07.828954Z",
     "shell.execute_reply.started": "2025-03-17T13:17:07.823724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def audio2melspec(audio_data):\n",
    "    if np.isnan(audio_data).any():\n",
    "        mean_signal = np.nanmean(audio_data)\n",
    "        audio_data = np.nan_to_num(audio_data, nan=mean_signal)\n",
    "\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=audio_data,\n",
    "        sr=config.FS,\n",
    "        n_fft=config.N_FFT,\n",
    "        hop_length=config.HOP_LENGTH,\n",
    "        n_mels=config.N_MELS,\n",
    "        fmin=config.FMIN,\n",
    "        fmax=config.FMAX,\n",
    "        power=2.0\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    mel_spec_norm = (mel_spec_db - mel_spec_db.min()) / (mel_spec_db.max() - mel_spec_db.min() + 1e-8)\n",
    "    \n",
    "    return mel_spec_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio_segment(audio_data):\n",
    "    \"\"\"Process audio segment to get mel spectrogram\"\"\"\n",
    "    if len(audio_data) < config.FS * config.WINDOW_SIZE:\n",
    "        audio_data = np.pad(audio_data, \n",
    "                          (0, config.FS * config.WINDOW_SIZE - len(audio_data)), \n",
    "                          mode='constant')\n",
    "    \n",
    "    mel_spec = audio2melspec(audio_data)\n",
    "    \n",
    "    if mel_spec.shape != config.TARGET_SHAPE:\n",
    "        mel_spec = cv2.resize(mel_spec, config.TARGET_SHAPE, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "    return mel_spec.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-17T13:18:01.589636Z",
     "iopub.status.busy": "2025-03-17T13:18:01.589211Z",
     "iopub.status.idle": "2025-03-17T13:18:25.526712Z",
     "shell.execute_reply": "2025-03-17T13:18:25.525599Z",
     "shell.execute_reply.started": "2025-03-17T13:18:01.589604Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting audio processing...\n",
      "DEBUG MODE - Processing only 50 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ea844018254eddb847ff0e91d46f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing completed in 12.55 seconds\n",
      "Successfully processed 740 segments out of 50 audio files\n",
      "Failed to process 0 files\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting audio processing...\")\n",
    "print(f\"{'DEBUG MODE - Processing only 50 samples' if config.DEBUG_MODE else 'FULL MODE - Processing all samples'}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Dictionary to track processed files (metadata only, not the actual spectrograms)\n",
    "all_bird_metadata = {}\n",
    "errors = []\n",
    "processed_count = 0\n",
    "\n",
    "# Process and save each spectrogram individually\n",
    "for i, row in tqdm(working_df.iterrows(), total=total_samples):\n",
    "    if config.N_MAX is not None and i >= config.N_MAX:\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        audio_data, _ = librosa.load(row.filepath, sr=config.FS)\n",
    "        \n",
    "        # Calculate the number of complete segments\n",
    "        segment_samples = config.FS * config.WINDOW_SIZE\n",
    "        original_len = len(audio_data) / config.FS\n",
    "        \n",
    "        # Calculate padding needed to make audio divisible by segment size\n",
    "        remainder = original_len % config.WINDOW_SIZE\n",
    "        if remainder > 0:\n",
    "            padding_size = int(segment_samples - remainder * config.FS)\n",
    "            audio_data = np.pad(audio_data, (0, padding_size), mode='constant')\n",
    "        \n",
    "        # Recalculate total segments after padding\n",
    "        total_segments = len(audio_data) // segment_samples\n",
    "        \n",
    "        for segment_idx in range(total_segments):\n",
    "            start_sample = segment_idx * segment_samples\n",
    "            end_sample = start_sample + segment_samples\n",
    "            segment_audio = audio_data[start_sample:end_sample]\n",
    "            \n",
    "            end_time_sec = (segment_idx + 1) * config.WINDOW_SIZE\n",
    "            row_id = f\"{row.samplename}_{end_time_sec}\"\n",
    "            \n",
    "            # Process the audio segment\n",
    "            mel_spec = process_audio_segment(segment_audio)\n",
    "            \n",
    "            # Save each spectrogram as a separate numpy file\n",
    "            spec_filepath = f\"{config.OUTPUT_DIR}{config.DATASET_NAME}/{row_id}.npy\"\n",
    "            np.save(spec_filepath, mel_spec)\n",
    "            processed_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row.filepath}: {e}\")\n",
    "        errors.append((row.filepath, str(e)))\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Processing completed in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Successfully processed {processed_count} segments out of {total_samples} audio files\")\n",
    "print(f\"Failed to process {len(errors)} files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
